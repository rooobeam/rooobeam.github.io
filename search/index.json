[{"content":"摘要 RAG在特定corpus QA任务上有 成熟应用，然而 大量反例 仍存在。它们不仅仅是LLMs的局限性导致，相反，它们主要由检索不准确信息导致，检索不准的原因是 1 现在RAG技术分块不考虑语义。2 丢失必要信息 和 过多噪声 之间的权衡。\n本文提出一个RAG框架 SAGE。1 解决分块问题上，提出训练一个语义分块模型，能将corpus分成语义完整块。2 设计 一个chunk挑选算法，根据相似度的下降速度（delta）动态选择块。3 为进一步确保精度，提出让LLMs评估检索的块是excessive or lacking. 实验证明很牛逼。\nINTRUDUCTION bg of problem \u0026ndash; RAG: enhance a generation model\u0026rsquo;s ability answer questions. With the rise of LLMs, RAG demonstrated proficiency in QA.\nLimitions overview:\nL1:\nchallenge of addressing L1:\nL2:\nchallenge of addressing L2:\napproach overview:\ncontributions:\nPRELIMINARIES(预备知识) retrieval-augmented generation RAG system phases:\nvector DB construction: corpus is devided into chunks. Convert chunks into vector representations (embedding chunks). Stored these vectors. Convert the received question into vector. (embedding question). Caculate similarity with chunks in vector DB and then identifying the top N chunks which serve as the context for an LLM. The given question and context fixed into a prompt template forming a complete prompt. Feed the prompt to an LLM. It generates a response as the final answer. Cost of LLM inference:\n​\tThe matrix is the money required to obtain ansers from an LLM. Typically, RAG use LLM provided by LLM providers. The charges based on the volume of input and output tokens. OpenAI’s GPT-4 charge a lot.\n$$ Cost = I_t \\cdot c_i + O_t \\cdot c_o $$​\tI \u0026ndash; input tokens O \u0026ndash; output tokens c_i \u0026ndash; cost per input token o_i \u0026ndash; cost per output token\nCost efficeincy Metric in RAG:\n$$ f_{\\text{cost-efficiency}} = \\frac{Acc}{Cost} $$Acc -- metrics used to eval the quality of an answer, e.g. F1-Score, BELU-1, Accuracy; Cost -- money calcuated by the preceding equation. ","date":"2025-09-01T22:43:23+08:00","permalink":"https://rooobeam.github.io/p/sage_a_framework_for_rag/","title":"SAGE_A_Framework_for_RAG"},{"content":"第二章 寄存器 ✅\n8086cpu有14个寄存器：AX BX CX DS SI DI SP BP IP CS SS DS ES PSW。\n8086cpu寄存器都是16位的。\nABCD-X通常用来存放一般性数据，被成为通用寄存器。\n寄存器?X可被分为?H和?L，如AX分为AH AL，即分为AHigh ALow，前者是高八位，后者是第八位。\n所谓高位和数字的高位联想，都是左边是高位。\n✅\n几条汇编指令：mov add，用法一样。add ax,18H; add ax,8H。\n数字默认16进制。\nmov ax,bx; mov ax,7。\n两个操作对象位数一致，第一个位置要是变量，如mov ah,bl; mov bh, AA。\n✅\n物理地址即内存在统一的逻辑存储器中的地址。\n内存地址空间:cpu将系统中各类存储器看作一个逻辑存储器。\n物理地址=段地址*16+偏移地址，通常写作 段地址:偏移地址，如cpu指令读取开始地址CS:IP。\n由于十六进制，故其实即 “段地址0+偏移地址”，由一个地址加法器合成。\n段的概念：段地址固定，偏移地址连续的内存空间。故其最大范围0000~FFFF。实践发现，0-1会自动变成FFFF，FFFF+1变成0000。\n✅\n8086有四个段寄存器：CS DS SS ES。\nCS和IP：CS叫代码 段寄存器，IP 叫指令指针寄存器，CS存段地址IP存偏移量。\ncpu将从CS:IP单元开始读取一条指令并执行。\n取指执行过程：从CS:IP读取指令，该指令进入指令缓冲器；IP=IP+该指令长度，从而指向下一指令首单元；执行指令；从CS:IP读取指令\u0026hellip;\u0026hellip;.\n修改CS IP命令——jmp jmp 段地址:偏移地址\t段地址修改CS 偏移地址修改IP jmp “四位数” 仅修改IP jmp 某合法寄存器\t仅修改IP，IP=某合法寄存器的值\n第三章 寄存器（内存访问） ✅\n(⊙﹏⊙) 第四章 第一个程序 ✅\n源程序写出到执行简要过程，后文有实例： 编写源程序 —— 写一个文本文件 —— 使用edit、笔记本等。 编译连接 —— 用汇编语言编译程序对文本文件编译产生目标文件；再用连接程序对目标文件进行连接，生成可执行文件。 在操作系统中执行文件。 ✅\n源程序简单结构 1 2 3 4 5 6 7 8 9 10 11 12 13 assume 寄存器:某segment段, 寄存器:某segment段, 寄存器:某segment段 XXX segment : : : XXX ends YYY segment : mov ax,4c00H int 21H YYY ends end 伪指令：提供给编译器的，编译器根据伪指令进行编译工作。上面代码中assume，XXX segment……XXX ends 和 end。 标号，如segment段的名称 上面代码中的XXX、YYY，一个标号指代一个地址。 程序返回：将CPU的控制权还给 使他得以运行的程序（shell)。代码中的 mov ax,4C00H \\n int 21H 。 ✅\n实例\n编写源程序 svg\n​\t桌面右键新建txt命名123，记事本里写好源程序。\n编译 svg\nwin+R 输入command打开命令提示符，输入“cd masm”（masm.exe所在目录），输入“masm”启动masm.exe。 提示我们输入源文件名，txt文件放在了c:\\asm，且不是asm文件，输入c:\\asm\\123.txt。（注意此处的斜杠是和\\n\\t一样的） 询问生成obj文件名，我们选择默认，回车即可。 提示输入列表文件名，该文件为编译为目标文件的中间结果，我们不生成，回车即可。 提示输入交叉引用文件名，也是中间结果，不生成，回车即可。 无错误则masm.exe所在目录下生成123.obj 连接 svg\n进入DOS方式(win+R 输command)，进入c:/masm (Overlay Linker3.60，link.exe所在目录),输入link启动link.exe。 提示输入目标文件名，[.OBJ]提示默认扩展名为obj，正合我意，输入123即可。 提示生成的exe文件名，默认名就行，回车即可。 提示输入映像文件名，提示输入库文件名，我们都回车即可。 无error则当前目录下生成123.exe。 执行，命令行输入文件名就行了，masm.exe 或 masm 123.exe 或 123 。\ndebug跟踪程序的运行过程：debug 可以将程序载入内存，设置CS:IP指向程序的入口，但debug不放弃cpu的控制权\n具体方法：debug 123.exe svg 运用第二章的debug的使用方法 R命令查看、改变寄存器内容 D查看内存中内容 E改写内存内容 U将内存中机器指令(01\u0026hellip;)翻译以为汇编命令(mov\u0026hellip;) T执行一条机器指令 A以汇编指令格式往内存写入机器指令 P正常结束程序。 实操如下图： svg ✅\nexe执行过程与shell DOS中，123.exe若要运行，要有一个正在运行的程序p2将其载入内存，123.exe运行完后即将cpu控制权交还程序p2。 p2即command.com，被成为命令解释器，即DOS系统的shell。输入cd、dir、type等都由command执行。 提示符\u0026quot;c:\\masm“后输入123.exe，此时command.com运行。 输入123.3exe后，command根据文件名找到该可执行文件，将程序载入内存，设置CS:IP指向程序入口，随后执行程序。 执行完回到command。 dos中.exe的加载过程（上面第二步——载入内存） 找到SA:0000空闲内存区——\u0026gt;前256即偏移地址0-255创程序段前缀(PSP)，DOS要用它和.exe通信——\u0026gt;后面装入程序，即从SA+10H:0000——\u0026gt;CS:IP=SA+10H:0000 加载.svg ✅\n习题 习题.svg 第五、六章 ☝内存单元 、\u0026quot;()\u0026quot;、 loop 和 idata [bx]\n类似[0]，[bx]表示 ds:bx上的字节单元或字单元的内存内容，bx内的4位作为偏移地址\n[0] [bx] mov ax, [0] 将地址为ds:0 的内存字单元存入ax mov ax, [bx] 将地址为ds:bx的内存单元存入ax mov al, [0] 将地址为ds:0 的内存半字单元存入al mov al, [bx] 将地址为ds:bx的内存半字单元存入al 实例 问题5.1.svg\n1 忘了要写啥了 “()\u0026quot;，机组中“(地址)”——描述某地址上的内容\n()中的元素有三种类型： 寄存器名，段寄存器名 和 五位十六进制的物理地址\n如 (ax)、(al)、(ds)、(20000H)、**((ds)*16+(bx))**注意里面的ds、bx都有括号\nax=10000H，则(ax)=(10000H)即地址10000H上的字节单元或字单元\nloop 类似“goto”\n1 2 3 4 5 6 7 8 9 10 assume cs:code code segment cx=8 s:\tax=0 loop s mov ax,4c00h int 21 code ends end ​\t首先(cx)=(cx)-1，然后判断(cx)是否等于0，如果等于0则执行下一指令，如果不等于0则跳转到s处执行。\nloop 可能情境 cx初始化8，循环8次后继续执行 cx为人为初始化，然后为0，(cx)=(cx)-1变成大数(如65535) cx设置指令在循环体内，死循环 idata\n约定符号好idata表示常量，mov ax,[idata]代表mov ax,[1]、mov ax,[2]等。\n又如 mov ds,idata 都是非法指令\n☝实验四 程序 编程，向内存0:2000:23F依次传送数据063(3FH)，程序中只能使用9条指令，9条指令中包括‘mov ax,4c00h’和‘int 21h’。\n在常见的x86汇编语言（如MASM、NASM）中，分号 ; 是标准的行注释符号。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 assume cs:codesg codesg segment mov ax,020H\tmov ds,ax\t; 初始化ds，不能直接将数字传入段寄存器 mov bx,0H\t; 初始化bx因为从0 mov cx,40H\t; cx=40H即循环64次存入数据0~63 s:\t; 标记loop跳转位置 mov [bx],bl\t; 内存0:200~0:23F是40H个字节数据,要存入字节数据，bl存入cs:bx的字节单元，因为要对应bl的大小是1字节 inc bx\t; 把bx+=1 移动偏移地址 loop s\t; 减小cx, 检查判断是否跳转 mov ax,4c00H\tint 21H\t; 结束 codesg ends end ☝实验五倒二题 编写code段中的代码，将a段和b段中的数据依次相加，将结果保存到c段中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 assume cs:code a segment db 1,2,3,4,5,6,7,8 ; a 原始数据 a ends b segment db 1,2,3,4,5,6,7,8 ; b 原始数据 b ends c segment db 0,0,0,0,0,0,0,0 ; c 结果存储区 c ends code segment start: mov bx,0\t; 初始化偏移，从0开始 mov cx,8\t; 设置好循环次数 s:\tmov dx,a\tmov ds,dx\t; ds=a mov al,[bx]\t; al=a[bx] mov dx,b\tmov ds,dx\t; ds=b add al,[bx]\t; al= mov dx,c\tmov ds,dx\t; ds=c mov [bx],al\t; c[bx]=al=a[bx]+b[bx] inc bx\t;bx++ loop s\t;跳转 mov ax,4c00h\tint 21h\t; 程序退出 code ends end start\t# 指明程序的开始结尾，start处设置cs=start 创建txt，将上述代码写入，保存。 win+R进入DOS，输入\u0026quot;cd masm5\u0026quot;，再输入\u0026quot;masm\u0026quot;启动。 源文件输入 \u0026ldquo;file_name.txt\u0026rdquo; 然后四个回车 没有error后，输入\u0026quot;link\u0026quot;，obj文件输入file_name，然后回车回车回车 输入\u0026quot;debug file_name.exe\u0026quot;，进入对该exe的debug模式 输入\u0026quot;u\u0026quot;查看当前能看到的指令，看不到\u0026quot;mov ax,4c00H\u0026quot;就输入t执行一条指令，输入个三四个再输入\u0026quot;u\u0026quot;查看，总之看到结束指令的偏移地址bx 输入\u0026quot;g bx\u0026quot;，直接执行到bx处 输入\u0026quot;r\u0026quot;，查看DS，因为它是c段的首地址，因为最后一次设置DS就是用的c 实验中ds=0c25，输入“d 0c25:0\u0026quot;便能查看c处的值是不是2 4 6 8\u0026hellip;，或者输入\u0026quot;d 0c23:0\u0026quot;能对比a、b、c段的内容。 db、dw：定义数据，db即define bytes，dw即define words， ☝实验五最后一题 编写code段代码，用push指令将a段中的前8个字型数据，逆序存储到b段。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 assume cs:code a segment ; 数据段a dw 1,2,3,4,5,6,7,8,0ah,0bh,0ch,0dh,0fh,0ffh a ends b segment ; 数据段b dw 0,0,0,0,0,0,0,0 b ends code segment start: mov ax, a ; 赋值ds为a段的段地址 mov ds, ax mov ax, b ; 赋值堆栈段ss为b段的段地址 mov ss, ax mov sp,10h\t;偏移到堆栈最后的字型数据后，8个字，16个字节，0c24:0~0c24:0f，ss:sp指向0c24:10，即前者加一。 mov bx, 0 ; 初始化偏移量 mov cx, 8 ; 循环次数 s: push [bx] ; 将a段第i个字型数据存入b段倒数第i个字单元内 add bx, 2h ; 按字 (word) 处理数据，故+2 loop s mov ax, 4c00h ; 退出程序 int 21h code ends end start 读代码代码后思考：各种段是如何安排的，怎么让CPU会把dode段当作代码段\n❌\ncode data stack等段名如何设置只是为了方便阅读，不能起到修改cs ds ss的作用\nassume cs:code,ds:data,ss:stack 也不能\n✅\n程序末尾end start可以设置程序入口CS:IP\n✅\nmov ax,stack\nmov ss,ax\nmov sp,20h\n设置堆栈段，stacK是你设置的作为堆栈段的段名，可以是a、c what ever you want 符合一定命名规范即可。\n✅\nmov ax,data\nmov ds,ax\n设置数据段\n每个段势必占据N行，即：\n前一个段最后一个字节单元为所在行被前一个段占有，当前段从下一行开始，每行16字节。\n前一个段最后一个字节单元 a:b，则当前段的第一个字节单元为a+[b/10h]+1:0，[ ]取整数，10h十六个字节\na:b=2:34h\ta+[34h/10h]+1:0=2+3+1:0=6:0\n第七、八章 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 assume cs:codesg data segment db \u0026#39;1975\u0026#39;,\u0026#39;1976\u0026#39;,\u0026#39;1977\u0026#39;,\u0026#39;1978\u0026#39;,\u0026#39;1979\u0026#39;,\u0026#39;1980\u0026#39;,\u0026#39;1981\u0026#39;,\u0026#39;1982\u0026#39;,\u0026#39;1983\u0026#39; db \u0026#39;1984\u0026#39;,\u0026#39;1985\u0026#39;,\u0026#39;1986\u0026#39;,\u0026#39;1987\u0026#39;,\u0026#39;1988\u0026#39;,\u0026#39;1989\u0026#39; dd 16,22,345,4567,6475,4567,12345,34526,65734,465436,234234 dd 123345,463654,867887,1567689 dw 4,13,76,89,99,345,567,789,890,1234,5467 dw 6789,12345,14357,16776 data ends table segment db 15 dup (\u0026#39;year summ ne ?? \u0026#39;) table ends codesg segment start: ;set sreg (segment register) mov ax,data mov ds,ax mov ax,table mov es,ax ;set reg (register) mov bx,0 ;bx add 4 bytes mov si,0 ;si add 2 bytes mov bp,0 ;bp add 16 bytes mov cx,0fh s: ;year mov ax,[bx] ;30th row mov es:[bp+0],ax mov ax,2[bx] mov es:[bp+2],ax ;sum of money mov ax,60[bx] ;low -\u0026gt; ax mov es:[bp+5],ax mov dx,62[bx] ;high -\u0026gt; dx mov es:[bp+7],dx ;n of employee mov di,120[si] mov es:[bp+10],di ;?? —— average money div di mov es:[bp+13],ax add bx,4h add bp,10h add si,2h loop s mov ax,4c00h int 21h codesg ends end start 第九章（转移指令原理） offset 获得标号的偏移地址\n大小为一个字\n性质相当于表示IP的idata\njmp 标号 jmp short s\t短转移 jmp near s\t近转移 jmp far s\t远转移 寄存器/idata jmp reg/一字idata\njmp sreg:reg/一字idata:一字idata\n内存单元 jmp word ptr 内存地址\njmp dword ptr 内存地址\njcxz jump if (cx) == zero\n等价于if((cx)==0) jmp short 标号\t短转移\nloop 短转移类型\n(cx)\u0026ndash;\nif((cx)!=0)jmp short 标号\n实验8 实验9 第十章 CALL 和 RET指令 ret、retf ret —— return\tretf —— return far\nret 出栈字单元 放入IP\n相当于 pop IP\nretf 第一次出栈 字单元 放入 IP，第二次出栈 字单元 放入CS，相当于\npop IP\npop CS\n栈里，CS总在IP底下\n|\t| | IP | | CS | |\u0026mdash;\u0026mdash;-|\n结合上地址来说，CS总在IP的右边（高地址），因为sp压栈会从高到低走。\nIP CS ​\t↑ ​\tsp\n出栈、压栈总是一个字单元\n实现从1000:0000处开始执行指令，谁知道1000:0000处有啥。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 assume cs:code stack segment db 16 dup (0) stack ends code segment start:\tmov ax, stack mov ss, ax mov sp, 16 mov ax, 1000h push ax mov ax, 00h push ax retf code ends call 标号型 call s (s是标号)（位移转移），将当前IP压入栈，然后近转移到s，相当于\npush IP\njmp near ptr s(标号)\n1000:3处指令为call s，s处内容为s:pop ax\n执行完这两条指令后，ax数值为 3\ncall far ptr s（标号），先将CS压入栈，再将IP压栈，然后远转移到s，相当于\npush CS\npush IP\njmp far ptr s(标号)\n寄存器型 call 16位reg，压栈IP，IP=(reg)\npush IP\njmp 16位reg\n内存单元型 call word ptr 内存单元地址，地址取出内容大小为字单元，仅压栈IP，相当于\npush IP\njmp word ptr 如es:[bx]\ncall dword ptr 内存单元地址，地址取出内容大小为双字，先压栈CS再压栈IP，相当于\npush CS\npush IP\njmp dword ptr 如es:[bx]\ncall和ret实现模块化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 assume cs:code stack segment db 8 dup (0) db 8 dup (0) stack ends code segment start: mov ax, stack mov ss, ax mov sp, 16 mov ax, 1000h call s mov ax, 4c00h int 21h s: add ax,ax ret code ends end start mul指令 实验10 1.显示字符串 我的错误❌：\n外部的dl为3表示第三列，对应字节时要乘二，第6个字符 jcxz结合jmp使用，不要结合loop使用，loop会改变cx！，先减cx1再判断cx值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 assume cs:code data segment db \u0026#39;Welcome to masm!\u0026#39;,0 data ends code segment start: mov dh, 8h mov dl, 3h mov cl, 2h mov ax, data mov ds, ax mov si, 0 call show_str mov ax, 4c00h int 21h show_str: ;--------------------以上为给定，以下为作答------------------- ;===set print sreg=== mov ax, 0b800h mov es, ax ;===set print reg=== ;di=a0h*dh+dl*2 ;a0h*dh mov al, 0a0h mul dh ;+2*dl mov dh, 00h add ax, dx add ax, dx mov di, ax ;===print to es:di=== ;save cl mov bl, cl s: ;check if end mov cl, ds:[si] mov ch, 0h jcxz fin mov es:[di], cl mov es:[di+1], bl add di, 02h add si, 01h jmp s fin: ret code ends end start ","date":"2025-09-01T00:00:00Z","image":"https://rooobeam.github.io/p/%E7%8E%8B%E7%88%BD-%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/vglcjtiwyh9bnm0o_hu_b0d85bfc829806f3.webp","permalink":"https://rooobeam.github.io/p/%E7%8E%8B%E7%88%BD-%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/","title":"王爽 汇编语言"},{"content":"链表、二叉树与回溯 灵神题单：分享丨【算法题单】链表、二叉树与回溯（前后指针/快慢指针/DFS/BFS/直径/LCA/一般树） - 讨论 - 力扣（LeetCode）\n场景：链表，二叉树\n链表 回文链表 234. 回文链表 - 力扣（LeetCode）\n找中间结点模板、反转链表模板\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 876. 链表的中间结点 def middleNode(self, head: Optional[ListNode]) -\u0026gt; Optional[ListNode]: slow = fast = head while fast and fast.next: slow = slow.next fast = fast.next.next return slow # 206. 反转链表 def reverseList(self, head: Optional[ListNode]) -\u0026gt; Optional[ListNode]: pre, cur = None, head while cur: nxt = cur.next cur.next = pre pre = cur cur = nxt return pre # 作者：灵神 旋转链表 61. 旋转链表 - 力扣（LeetCode）\n特殊情况、临界情况分析 ","date":"2025-08-29T00:00:00Z","permalink":"https://rooobeam.github.io/p/%E9%93%BE%E8%A1%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%8E%E5%9B%9E%E6%BA%AF/","title":"链表、二叉树与回溯"},{"content":"位运算 灵神题单：分享丨【算法题单】位运算（基础/性质/拆位/试填/恒等式/思维） - 讨论 - 力扣（LeetCode）\n场景：\n2 的幂 231. 2 的幂 - 力扣（LeetCode）\n2的幂 n 的二进制特点：10 100 1000 -\u0026gt; 最高位为1，其他位为0，2的幂减一 (n−1) ：1 11 111，n\u0026amp;(n−1) 一定是 0 反之，如果 n 不是 2 的幂，那么 n 的二进制至少有两个 1，则把 n 减一后最高位必为 1，所以 n\u0026amp;(n−1) 必不为 0，例如： 1 2 9 = 1001 9−1 = 1000 4的幂 发现4^x = 2^2x，也就是如果是4的幂则必然是2的幂，前面知道如何判断 是否为2的幂，也就是要继续加条件限制即可。 1 2 3 4 5 6 7 8 9 10 11 4的幂的二进制： 1 100 10000 ⋮ 2的幂但不是4的幂的二进制： 10 1000 100000 ⋮ 直观特点：True 的情况为 位数为奇数，False 的情况为 位数为偶数。如何尝试用与或非体现这个区别？\u0026hellip;0101010\u0026hellip;.与即可。 tips：把二进制数前面也补0带入思考： 100-\u0026gt; \u0026hellip;00100。 ","date":"2025-08-15T00:00:00Z","permalink":"https://rooobeam.github.io/p/%E4%BD%8D%E8%BF%90%E7%AE%97/","title":"位运算"},{"content":"摘要 现代 NLP任务依赖稠密检索方法来获取上下文信息。动机：通过大小变化的chunk让内容语义独立性得以实现从而提高检索。LumberChunker，一个利用LLM动态分割文档的方法，说白了用prompt让LLM发现一组有序passages的分割点 当内容转移话题时。为了评估我们的方法，我们提出GutenQA，一个benchmark，大海捞针型记叙文问题。实验证明，LumberChnuker不仅比 强大基线们 在DCG@20上 多7.37%，而且把它结合到RAGpipeline里时，能强于其他分块方法和强大LLMs。\n介绍 LLMs 为解决大量任务提供思路，翻译、总结摘要和Q\u0026amp;A等。然而当缺少关键信息时会导致幻觉。会带来危害。\nQ\u0026amp;A领域，信息准确至关重要。RAG是个解决方案于抑制幻觉，通过让模型生成依赖于给定文本。\n一个在RAG流程中容易忽略的点是文本内容如何分割成文本块，它能严重影响检索质量。现实应用趋于简化这步，设置分割粒度为句子、段落或原子命题。\n我们提出LumberChunker，一个基于 “文本块越独立检索效果越好”的原则 的新的文本分块方法。独立性通过动态大小得以最好地实现。假定语言模型能够胜任文本分析工作，我们利用他们的能力来识别分割点（segementation points）。具体地，我们反复指导一个语言模型接收一系列连续的段落并确定出现主题转变的段落。该方法保障块内上下文上连贯但与相邻的块相互独立，从而提高检索。\n我们提出一个新基准 GutenQA，包含100 个公开领域记叙文书籍（从Project Gutenberg提取的）。我们创造了3000个高质量问答对。最终我们融入RAG进行下游QA任务测试准确率。\n背景 检索细粒度在文本分块又关键作用，因为差分块策略导致内容不完整或过多不相干信息降低检索模型表现。\n除了经典细粒度 句子或段落，还有其他高级方法。recursive character splitting基于层级分割符如段落分隔符、新行、空格和单个字符。缺少上下文理解。为解决这个问题，基于语义的分块方法(semantic-based splitting)使用embedding 来聚合语义相似的文本片段。通过识别文本间embedding距离的重大变化。\n最近的研究提出新的检索粒度术语 命题（propositions），最小化语义单元，每个命题以清晰、self-sufficient 自然语言方式 传达 独立事实。虽然该理念再 基于事实的 信息上很合理，但在记叙文不大行，因为上下文持续性有重要作用。\n检索粒度常常取文档级，但也可引入问题本身来调整。学者提出HyDE，通过LLM把问题转为一个可能的答案文档（或许利用它的长度来选择细粒度？）\n方法 LumberChunker 我们提出LumberChunker，它利用LLM动态分块。我们的方法基于 “动态分块更好地捕捉语义独立性 从而提高检索” 的原则。动态细粒度保证 文本块 有完整独立idea，增强\u0026hellip;。\n一个基于 “文本块越独立检索效果越好”的原则 的新的文本分块方法。独立性通过动态大小得以最好地实现。假定语言模型能够胜任文本分析工作，我们利用他们的能力来识别分割点（segementation points）。通过向LLM输入一组序列段落，自主确定最合适的分段点。\n图1展示了LumberChunker的整体流程。首先将原docs按 段 分割，每个段通过 递增编号 唯一标识。 每个 段 依次被拼接成 一个名为Gi的 段组，直到其总token数超过预设阈值θ。该阈值是基于实证研究经验（详见5.1节）设定的。我们的目标是 1 将θ值设置足够大，以防分割掉相关的内容；2 设置足够小，以免过多上下文压垮模型，影响推理准确性。这些Gi 段组 输给LLM（Gemini 1.0-Pro），通过prompt提示模型识别出Gi中与前序上下文存在显著偏离的具体段落，从而分块。文档会以循环方式持续被分割成新块，每个新Gi片段组的起始点均取自前次迭代中确定的段落位置（也就是前一个Gi-1分割点后半段文本和Gi拼接形成真正的新Gi）。 使用的提示见附录B。\nGutenQA 跳过\n实验 ","date":"2025-08-12T00:00:00Z","permalink":"https://rooobeam.github.io/p/lumberchunker%E8%A7%A3%E8%AF%BB/","title":"LumberChunker解读"},{"content":"滑动窗口与双指针 灵神题单：分享丨【算法题单】滑动窗口与双指针（定长/不定长/单序列/双序列/三指针/分组循环）- 讨论 - 力扣（LeetCode）\n场景：连续、遍历各情况\n尚未分类 两数之和 1. 两数之和 - 力扣（LeetCode）\n给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案，并且你不能使用两次相同的元素。\n你可以按任意顺序返回答案。\n示例\n1 2 输入：nums = [3,2,4], target = 6 输出：[1,2] 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution: def twoSum(self, nums: List[int], target: int) -\u0026gt; List[int]: # #遍历 # for i in range(len(nums)-1): # for j in range(i+1,len(nums)): # if nums[i]+nums[j]==target: # return [i,j] # 哈希表 python 字典最好 键不存在即0个，但是要存索引 dic=dict() for i,e in enumerate(nums): # if dic.get(target-e) is not None: # in方法就是用的哈希表查找 if target-e in dic: return [dic[target-e], i] dic[e]=i what I learn\n哈希表的查找用in方法可实现，用dict()或set()最好，用空间换时间。 集合、字典的 in 方法时间复杂度O(1)，列表和元组的 in 时间复杂度O(n)。 删除有序数组中的重复项 26. 删除有序数组中的重复项 - 力扣（LeetCode）\n给你一个 非严格递增排列 的数组 nums ，请你** 原地** 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。然后返回 nums 中唯一元素的个数。\n考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：\n更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。\n返回 k 。\n示例\n1 2 输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Solution: def removeDuplicates(self, nums: List[int]) -\u0026gt; int: # 哈希表 空间换时间 # dic=set() # for e in nums: # if e not in dic: # dic.add(e) # nums[len(dic)-1]=e # # print(dic) # # print(nums) # # print(\u0026#34;----\u0026#34;) # return len(dic) # 双指针 利用有序性 p=0 for e in nums: if e!=nums[p]: p+=1 nums[p]=e return p+1 what I learn\n快慢指针，数据需要有有序性。 搜索插入位置 35. 搜索插入位置 - 力扣（LeetCode）\n**（二分法）**记住就好了 T-T\n给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n请必须使用时间复杂度为 O(log n) 的算法。\n示例：\n1 2 输入: nums = [1,3,5,6], target = 5 输出: 2 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution: def searchInsert(self, nums: List[int], target: int) -\u0026gt; int: # 上下界限设置，target 最大时要放在“第len(nums)个位置”，最小时要放在“第0个位置” up=len(nums) low=0 while(True): # i为 正中（奇）或 偏上（偶） i=(low+up)//2 # 重合即为最终位置 if low==up: return low # 因为是向下取整的i，上界下移到i;下界上移到i+1。 # 比如low=0,up=5，则：mid=2.5,i=2，小的区域为0~2(i)，大的区域为3(i+1)~5 if target\u0026lt;nums[i]: up=i elif target\u0026gt;nums[i]: low=i+1 else: return i what I learn\n二分法框架： 上下界up=len(nums) low=0 取中间(low+up)//2 终止条件 low==up 上界降 up=mid 下界升 low=mid+1 加一 66. 加一 - 力扣（LeetCode）\n给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。\n最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。\n你可以假设除了整数 0 之外，这个整数不会以零开头。\n示例 1：\n1 2 3 输入：digits = [1,2,3] 输出：[1,2,4] 解释：输入数组表示数字 123。 示例 2： 1 2 3 4 5 输入：digits = [9] 输出：[1,0] 解释：输入数组表示数字 9。 加 1 得到了 9 + 1 = 10。 因此，结果应该是 [1,0]。 代码\n1 2 3 4 5 6 7 8 9 10 11 12 class Solution: def plusOne(self, digits: List[int]) -\u0026gt; List[int]: # 逆序，从低位开始，发现小于9的说明不用进位，加一退出，否则+1是10，当前位为0，进入下一位重复 for i in range(len(digits)-1,-1,-1): if digits[i]\u0026lt;9: digits[i]+=1 break digits[i]=0 # 如果最高位为0，说明进位了，前面插入1 if not digits[0]: digits.insert(0,1) return digits what I learn\n逆序索引 range(len(digits)-1,-1,-1) 从len(digits)-1开始，步长为-1(递减)，到-1，左闭右开[len(digits)-1, -1)。 定长滑动窗口 共性在于“一进一出” 记录变化计算、设置、边界值处理 逆向、排序、分组等特殊处理 半径为 k 的子数组平均值 2090. 半径为 k 的子数组平均值 - 力扣（LeetCode）\n给你一个下标从 0 开始的数组 nums ，数组中有 n 个整数，另给你一个整数 k 。\n半径为 k 的子数组平均值 是指：nums 中一个以下标 i 为 中心 且 半径 为 k 的子数组中所有元素的平均值，即下标在 i - k 和 i + k 范围（含 i - k 和 i + k）内所有元素的平均值。如果在下标 i 前或后不足 k 个元素，那么 半径为 k 的子数组平均值 是 -1 。\n构建并返回一个长度为 n 的数组 avgs ，其中 avgs[i] 是以下标 i 为中心的子数组的 半径为 k 的子数组平均值 。\nx 个元素的 平均值 是 x 个元素相加之和除以 x ，此时使用截断式 整数除法 ，即需要去掉结果的小数部分。\n例如，四个元素 2、3、1 和 5 的平均值是 (2 + 3 + 1 + 5) / 4 = 11 / 4 = 2.75，截断后得到 2 。\n1 2 输入：nums = [7,4,3,9,1,8,5,2,6], k = 3 输出：[-1,-1,-1,5,4,4,-1,-1,-1] 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution: def getAverages(self, nums: List[int], k: int) -\u0026gt; List[int]: # 我老想着动态得去判断加-1进result列表 avgs = [-1] * len(nums) s = 0 # 维护窗口元素和 for i, x in enumerate(nums): # 1. 进入窗口 s += x if i \u0026lt; k * 2: # 窗口大小不足 2k+1 continue # 2. 记录答案 avgs[i - k] = s // (k * 2 + 1) # 3. 离开窗口 s -= nums[i - k * 2] return avgs # 作者-灵神 what I learn\n观察问题的本质，不要被方法带着走。 问题的本质：待到要处理的索引时，得出平均值放入数组。 方法带偏：想着边遍历边append，开头去append -1，结束了再补充-1。 解决的关键：初始化nums长度的 -1数组，即 [-1] * len(nums)。 几乎唯一子数组的最大和 2841. 几乎唯一子数组的最大和 - 力扣（LeetCode）\n给你一个整数数组 nums 和两个正整数 m 和 k 。\n请你返回 nums 中长度为 k 的 几乎唯一 子数组的 最大和 ，如果不存在几乎唯一子数组，请你返回 0 。\n如果 nums 的一个子数组有至少 m 个互不相同的元素，我们称它是 几乎唯一 子数组。\n子数组指的是一个数组中一段连续 非空 的元素序列。\n示例\n1 2 3 输入：nums = [2,6,7,3,1,7], m = 3, k = 4 输出：18 解释：总共有 3 个长度为 k = 4 的几乎唯一子数组。分别为 [2, 6, 7, 3] ，[6, 7, 3, 1] 和 [7, 3, 1, 7] 。这些子数组中，和最大的是 [2, 6, 7, 3] ，和为 18 。 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Solution: def maxSum(self, nums: List[int], m: int, k: int) -\u0026gt; int: sum_n = max_sum = 0 dif_n=defaultdict(int) for i, element in enumerate(nums): dif_n[element] += 1 sum_n += element left = i-k+1\tif left \u0026lt; 0: continue if len(dif_n) \u0026gt;= m: max_sum = max(sum_n,max_sum) out=nums[left] sum_n -= out dif_n[out] -= 1 if dif_n[out] == 0: del dif_n[out] return max_sum what I learn\nsum_n = max_sum = 0 使用defaultdict 默认值为0，dif_n=defaultdict(int) 因为int()返回0（不如Counter） if dif_n[out] == 0: del dif_n[out] 删除其中值为0的键值对 max_sum = max(sum_n,max_sum) 而不用 if 条件判断 left = i-k+1 \u0026hellip;. out=nums[left] 使代码更简洁美观 找到字符串中所有字母异位词 438. 找到字符串中所有字母异位词 - 力扣（LeetCode）\nwhat I learn\nCounter 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from collections import Counter # 示例 1：统计字母频次 cnt_p = Counter(\u0026#34;aabbc\u0026#34;) print(cnt_p) # 输出：Counter({\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 1}) # 示例 2：访问不存在的键 print(cnt_p[\u0026#34;d\u0026#34;]) # 输出：0（不会报错！） # 改变值，类似字典 cnt_p[\u0026#34;a\u0026#34;]+=1 # 比较和集合操作 cnt_1 = Counter(\u0026#34;bcd\u0026#34;) cnt_2 = Counter(\u0026#34;abc\u0026#34;) print(cnt_1==cnt2) print(cnt_1-cnt_2) print(cnt_1+cnt_2) 重新安排会议得到最多空余时间 I 3439. 重新安排会议得到最多空余时间 I - 力扣（LeetCode）\n理解题目意思，转化问题（so called 建模）为某种方法解决，此题很明显，弄出所有时间差gap，然后求最大连续子数组即可。 注意一些变量的值需要变化，比如这题中的“可以移动k个”，转化为k+1个连续子数组 注意全面性，比如gap还包括“startTime-第一个会议开始时刻” “endTime-最后一个会议结束时刻”。 使二进制字符串字符交替的最少反转次数 1888. 使二进制字符串字符交替的最少反转次数 - 力扣（LeetCode）\n枚举法（s + s 上的滑动窗口），不要想当然得觉得 想出的算法能适应所有情况，当测试不通过时，大胆暴力，这里也就是 生成所有第一种操作而成的字符串，然后滑动遍历所有情况。 ans=min(cnt, k - cnt, ans)，在当前情况下的两种可能和全局最小 中 取最小。 查找给定哈希值的子串 2156. 查找给定哈希值的子串 - 力扣（LeetCode）\n第一个字母的 p 的幂次是最小的，这和通常字符串哈希中的定义是相反的。所以在计算哈希值时，要倒序遍历。 关键在于，此题正序遍历时，要在mod m下除以p，除法需要逆元，逆元不一定存在；逆序遍历时为乘p，无需逆元。 串联所有单词的子串（次定长滑窗） 30. 串联所有单词的子串 - 力扣（LeetCode）\n\u0026ldquo;barfoothefoobarman\u0026rdquo;，单个“词”长度3，本因3个3个检查，于是为遍历所有情况，起始位置需为0/1，对从0/1位置开始的字符串分别滑窗。 不定长滑动窗口 求最大最长（越短越合法或恰好合法）：内循环while使窗变小，一旦合法则无法继续循环，则此时为合法下的最长。 求最小最短（越长越合法或恰好合法）：内循环while使窗变小，预计算一步若不合法则无法继续循环，此时为合法下的最短。 求子数组 无重复字符的最长子串（最长最大） 3. 无重复字符的最长子串 - 力扣（LeetCode）\n基础模板：左指针while调整，右指针“+1移动”，cnt为int或defaultdict(int)记录信息，ans = max(ans, right-left+1)。 循环内呈现：right(进入的元素)处理，while循环调整左指针和记录变量，外围答案值是否需要改变。 找到最长的半重复子字符串 2730. 找到最长的半重复子字符串 - 力扣（LeetCode）\n稍作调整使用模板：ans的初始化(默认)值设置；记录变量的如何设置和如何变化 最高频元素的频数 1838. 最高频元素的频数 - 力扣（LeetCode）\n洞悉“滑窗”特性，主要在于它的只增性质。 先用在框架下暴力方法分析如何解出，再优化时间复杂度。 将 x 减到 0 的最小操作数 1658. 将 x 减到 0 的最小操作数 - 力扣（LeetCode）\n逆向思维+滑动窗口\n逆向思维 特殊情况分析 数组的最大美丽值 2779. 数组的最大美丽值 - 力扣（LeetCode）\n排序+滑动窗口\n审题，发现排序并不影响子序列的选择；排序后分析left的移动条件即可轻易解出。 毯子覆盖的最多白色砖块数 2271. 毯子覆盖的最多白色砖块数 - 力扣（LeetCode）\n排序+滑动窗口+特殊滑动单位\n模拟发现，毯子右端在白瓷内时，覆盖面积非递减，毯子右端在非白瓷内时，覆盖面积非递增。 相当于每次毯子右端在白瓷右端时，计算覆盖面积看是否大于ans，于是滑动单位为一个个白瓷（一个个区间） 长度最小的子数组（最短最小） 209. 长度最小的子数组 - 力扣（LeetCode）\nwhile total-nums[left] \u0026gt;= target: （\u0026ldquo;预计算一步\u0026rdquo;，即下一步不满足，现在是最短） 相向双指针 两数之和 II - 输入有序数组 167. 两数之和 II - 输入有序数组 - 力扣（LeetCode）\n关键在于利用“有序”进行排除，移动的指针 便是 排除“都小”或“都大”的数。 最终找到恰好 统计和小于目标的下标对数目 2824. 统计和小于目标的下标对数目 - 力扣（LeetCode）\n对大于/小于的统计，都是right-left，条件不同罢了，对称性：固定左指针，右指针往左，和都小；固定右指针，左指针往右，和都大。 ","date":"2025-07-25T00:00:00Z","permalink":"https://rooobeam.github.io/p/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E4%B8%8E%E5%8F%8C%E6%8C%87%E9%92%88/","title":"滑动窗口与双指针"},{"content":"摘要 RAG于QA是有效的。然而分块处理没有得到足够重视。这篇文章证明了分块的关键作用。并提出了LGMGC，一个新的分块框架，将长文档分成上下文关联、“自包含”的尺寸不一的块。实验结果在两个基准测试上进行，证明了提高检索并超过现存分块方法当应用于一个RAG流程时。\n介绍 开放领域QA，已经可见RAG是有作用的。模型利用LLM和retrieval system来增强答案生成。在经典RAG流程，文档被分为独立块，然后对query家安所相关chunk，然后二者以提提供给LLM。后续研究者集中在检索和生成/整合，很少集中于合理的分块。检索精度 受 信息粒度（granularity） 和 语义（semantics）影响。此外，上下文信息的缺失和过度不相干信息在同一个chunk会影响LLM从中准确提取关键信息。\n为此，提出LGMGC框架。它整合两个分块模型（一个是LG chunker，一个是MG chunker）于一个统一框架。过程始于 分为 语义和上下文关联的单元，通过利用从小规模LLM得到的 “logits information”。\n1 2 3 4 5 6 7 8 9 10 11 12 1. Logits 是什么？ 定义：Logits 是语言模型（LLM）输出的原始预测分数（未经过 Softmax 归一化的数值），表示模型对每个可能token的“置信度”。 示例： 当模型处理句子 \u0026#34;Paris is the capital of [MASK].\u0026#34; 时，[MASK] 位置的 logits 可能是： France: 8.2 Germany: 2.1 city: 1.5 较高的 logits 值（如 8.2）表示模型更倾向于选择 France。 2. 如何用于文档分割？ 文本遍历： 将文档输入小规模 LLM（如 DistilBERT），逐位置（如逐词/逐句）计算 logits。 检测语义突变点： 计算相邻文本单元的 logits 相似度（如余弦距离）。 若某位置的 logits 与前一单元差异显著（超过阈值），判定为语义边界。 ► 例如：从“科技”话题突然转向“政治”，logits 分布会剧烈变化。 分割文档： 在边界处切分文档，生成语义连贯的块（如话题一致的段落组）。 随后这些块视为父块，进一步被MG chunker分为尺寸不同的子块，当MG chunker响应不同类别的query时。我们的结果证明我们好。\n相关工作 递归分块（Recursive Chunking）使用一个分层分割器运用于单元基于一个预定义的结构。尽管它简单，他分的块内部缺少上下文关联。为解决这个问题，Small2-Big采取 检索小chunk然后扩展为大块来为LLM提供额外上下文。语义分块（Semantic Chunking）通过计算passage间的embedding距离来识别断点，以保证分的块有意义和内容“自相关”。但是，分处合理的块仍是挑战性任务。\n近期研究同样利用LLM提取有效的块。一种方法用LLM将doc转为“命题们”超过了传统的passage级或句子级分块技术。命题是一种表示表示，封装了不同的事实。\n1 2 3 原文：“巴黎是法国首都，也是欧洲人口最密集的城市之一。” → 命题1：“巴黎是法国首都。” → 命题2：“巴黎是欧洲人口最密集的城市之一。” LumberChunker通过迭代式向大语言模型（LLM）输入文本段落，自主识别最优分割点。一种方法方法通过提取LLM处理文档时产生的隐层状态向量作为文档表征，直接在模型内部实现相关性匹配与段落定位，从而跳过了显式的文档分块步骤。这些LLM驱动测率说明LLM的潜力，然而增加成本和时间。相比而言，我们的基于LLM的方法只用从一个单向传递得到logits信息，使得分块计算高效。\n方法 logits指导的分块器（Logits-Guided Chunker） 假定LLM有足够上下文理解，这里提出方法 识别 完全语义独立的单元之间的 边界。LLM能在已有一段序列后得到接下来的tokens的概率分布。因此，我们能得到[EOS] (End of Sequence)发生的概率（在每句后），假定有个prompt指导LLM持续写内容。直观而言，[EOS]标记的较高概率表明大型语言模型倾向于在该位置终止文本生成，这预示着前文已达到语义完整性。实践中，输入doc鲜卑转为 一连串的块，块由递归分块切分的 固定大小θ个词（递归它不考虑上下文）。我们然后计算块内每个句子后的[EOS]概率，然后选择最高概率那个作为 断点。公式如下\n1 2 3 4 5 b[EOS] = argmaxᵢ p([EOS] | ρ ⊕ s₁ ⊕ · · · ⊕ sᵢ) （其中： ⊕ 表示文本拼接 ρ 为续写指令提示 argmaxᵢ 表示取使概率最大化的索引位置 i ） 第一个块中，断点之前的作为一个独立块，断点之后的和第二个块进行连接，再进行分割，直到输入分割器的长度小于阈值。\n1 2 3 两种情况： 1 最后一个块和倒数第二个块断点后连接后的 文本 长度不够。 2 最后一个块和倒数第二个块断点后的 文本打断点后，剩余内容长度不够。 值得以提的是，尽管这样产生的块长度不一，但最大长度受到限制。\n多粒度分块器（Multi-Granular Chunker） 文献指出，将用于检索和生成的文本块解耦（分解）有益。该方法用较小的块检索然后将 小块所在大块提供给LLM。基于这个概念，我们引入多粒度分块器将文本切分成子块（child chunks）在不同的粒度上。起初doc用递归分块法分为父块(θ words)。每个父块然后再递归地再分块为两种子块，θ/2 words和θ/4 words，同时是保证句子不会因分块断开。计算相似度时，父块的相似度：父块、所有两种子块得分的最大值。将得分前k个的父块输给LLM。\nlogits指导的多粒度分块器（LGMGC） 多粒度分块器得到的输出作为父块输入给多粒度分块器，检索时参考多粒度分块器检索的检索方法。具体来说，第一个logits chunker得到的父块长为θ_1 words，然后\u0026hellip;，第二个 父块长为θ_2 words。\n实验设置 为评估Logits引导的多粒度分块器（Logits-Guided Multi-Granular Chunker）的影响，我们通过检索和下游问答任务测试其性能。 数据集与指标\n检索评估： 采用GutenQA基准数据集，该数据集包含源自叙事书籍的\u0026quot;大海捞针\u0026quot;（needle in a haystack）类问答对。因每个问题的证据仅由1-2个句子组成，证据不会分散在不同分块中。遵循其评估方案，我们使用DCG@k和Recall@k作为指标。 数据重标注： 观察到部分证据未直接出现在原始文本中（可能源于LLM合成生成），这种差异会降低匹配率并削弱检索块与查询相关性的评估价值。我们为每个证据计算其与各分块的ROUGE分数，并选择最高分分块作为查询关联块。 端到端RAG评估： 采用LongBench的三个单文档QA数据集： ▶ NarrativeQA：叙事文本问答 ▶ QasperQA：科研论文问答 ▶ MultifieldQA：多领域事实问答 这些任务旨在信息抽取，无需复杂推理。按标准，使用F1值作为评估指标： $$\\text{Precision} = \\frac{|\\text{BOW}(pred) \\cap \\text{BOW}(gt)|}{|\\text{BOW}(pred)|},\\quad \\text{Recall} = \\frac{|\\text{BOW}(pred) \\cap \\text{BOW}(gt)|}{|\\text{BOW}(gt)|},\\quad \\text{F1} = \\frac{2 \\cdot \\text{P} \\cdot \\text{R}}{\\text{P} + \\text{R}}$$ 其中： $\\text{BOW}(A)$ 表示预测答案($pred$)或真实答案($gt$)的词袋集合 $\\cap$ 运算对共有词取其最小词频 基线方法 评估对比以下主流方法：\n通用分块器 Recursive Chunker：递归分块 Semantic Chunker：语义分块 段落检索专用 Para Chunker：段落级分块 LumberChunker：LLM迭代分块 消融对照 MG Chunker：多粒度分块器（无Logits引导） LG Chunker：Logits引导分块器（无多粒度） ▶ 注：LG Chunker与LGMGC使用8位量化Llama3-8b ▶ 所有方法在θ={200, 300, 500}词的分块尺寸下测试超参数敏感性 实现细节\n架构： 采用独立检索器与合成器，不同分块策略接入统一框架 检索器： ▶ 稠密检索器：BGE-Large（段落检索） + E5-Large（下游QA） 合成器： ▶ LLama3-8b-Instruct（4位量化） ▶ LLama3-70b-Instruct（fp16） 控制变量： 生成答案采用贪心搜索降低随机性 为公平比较不同分块尺寸： 合成器输入上下文长度上限=1500词 Top k分块顺序拼接直至达上限 无检索基线：因算力限制截断文档至3500词/ ","date":"2025-07-23T00:00:00Z","permalink":"https://rooobeam.github.io/p/lgmgc%E8%A7%A3%E8%AF%BB/","title":"LGMGC解读"},{"content":"论文解读 摘要 场景是从长文档(long document)中找到相关片段(passage)，对SoTA分析发现错误主要源于错失了文档上下文内容，于是命名任务为DAPR——文档感知的片段检索（Document-Aware Passage Retrieval）。然后为此建立benchmark并进行实验。实验中对SoTA片段落检索器辅之以文档内容：（1）和BM25混合。（2）将文档信息掺和到段落信息里。实验结果：混合检索器法整体好，但是对于“需要文档级上下文信息”的问题完全失败；掺和法反之，整体较差但在上下文困难问题有进步。\n介绍 IR有用。传统BM25通过统计方法。近期方法应用神经网络进行向量化表示实现复杂语义匹配。神经方法受限于“短片段”(short passage 如512tokens)输入。在现实中遇到长文本如学科论文时，超出限制而无法利用完整上下文。近期工作实现长文档encode并实现了文档级检索。然而返回长文档对于用户仍不便于获取有效信息，如在标注维基百科页面中与用户查询相关的段落时，35.8%的查询所对应相关段落平均位于文档第7.6段(标准差12.7)。\n于是提出DAPR任务，就是在长文档中找到对应片段。举例解释“文档-感知” (Document-awared)，如指代关系会导致Query的关键信息出现在不同片段里，可能导致关键信息所在片段遗漏。为深入了解，测试SoTA片段检索器并分析错误，发现53.5%的错误源于未结合文档上下文解析指代或主题，导致漏检正确答案段落。于是创建一个基准测试，其中包含来自不同领域的5个数据集，这些数据集提供了在关联文档中对相关段落的标注(就是问题有标出相关片段)。\n实验中对SoTA片段落检索器辅之以文档内容：（1）和BM25混合。（2）将文档信息掺和到段落信息里。实验结果：混合检索器法整体好，但是对于“需要文档级上下文信息”的问题完全失败；掺和法反之，整体较差但在上下文困难问题有进步。这个基准测试对新的检索方法有意义。\n相关工作 DocQA： 需要模型回答关于输入文档的一个问题，它的问题的相关文档是给定的，而DAPR需要从文档集里找相关信息(doc)。基于给定文档这个假设，DocQA的问题通常是和文档内容关联的，比如“哪个检索系统用于这个baseline”，这个问题在DocQA中因为给定了文档所以有默认关联，而转换到DAPR就不行了，\u0026ldquo;这个baseline\u0026quot;不知道是啥。\n长文档检索：法1是MaxP，片段最高分作为文档分，法2是FirstP，第一片段得分作为文档分，法2不如法1。有学者比较了不同的“长距离注意力模型”的长文档检索。陈等人（2022年）提出了一种分层神经网络，并证明其优于基于MaxP。但这些工作相比DAPR，都没有研究 “考虑文档内容情况下的片段检索”。\n混合检索：涉及多检索系统。其中排名混合将排名合并\n实验复现代码 reproduce_bm25.sh （.sh4种算法都类似，但passage_only.bm25大不相同）\nexport：将变量提升为 环境变量（全局变量），使得所有子进程（如其他脚本、Python程序等）都能继承这个变量。\n直接设置：直接赋值定义的变量是 Shell变量（局部变量），仅在当前 Shell 会话中有效，子进程（如其他脚本、程序）无法访问。\n1 2 3 4 5 6 7 # scripts/dgx2/exps/passage_only/bm25.sh export NCCL_DEBUG=\u0026#34;INFO\u0026#34; export CUDA_VISIBLE_DEVICES=\u0026#34;0\u0026#34; # datasets=( \u0026#34;ConditionalQA\u0026#34; ) datasets=( \u0026#34;NaturalQuestions\u0026#34; ) # datasets=( \u0026#34;ConditionalQA\u0026#34; \u0026#34;MSMARCO\u0026#34; \u0026#34;NaturalQuestions\u0026#34; \u0026#34;Genomics\u0026#34; \u0026#34;MIRACL\u0026#34; ) for X in ${datasets[@]}： 遍历，取出每个元素到X\n$变量替换：获取变量的值 ${变量名}\n1 2 3 4 5 6 7 8 9 for dataset in ${datasets[@]} do export DATA_DIR=\u0026#34;data\u0026#34; export DATASET_PATH=\u0026#34;$DATA_DIR/$dataset\u0026#34; export CLI_ARGS=\u0026#34; --data_dir=$DATASET_PATH \u0026#34; # --data_dir=data/NaturalQuestions ... 命令替换：执行命令，并将输出结果作为字符串返回\n$(python -m dapr.exps.passage_only.args.bm25 $CLI_ARGS)：传入 CLI_ARGS 给dapr.exps.passage_only.args.bm25.py 并执行，捕获输出结果(如print的内容)，py脚本代码如下，传入 \u0026ndash;data_dir=data/NaturalQuestions，即py里有个变量data_dir=\u0026ldquo;data/NaturalQuestions\u0026rdquo;，BM25PassageOnlyArguments里的初始化会生成各种属性，包括output_dir。\n1 2 3 4 if __name__ == \u0026#34;__main__\u0026#34;: print( parse_cli(BM25PassageOnlyArguments).output_dir ) # For creating the logging path export OUTPUT_DIR=$(\u0026hellip;)： \u0026hellip; 即 bm25.py 里的输出被bash脚本捕获。\n**mkdir -p $OUTPUT_DIR：**确保OUTPUT_DIR存在\n**export LOG_PATH：**设置日志变量\n1 2 3 4 5 6 7 ... export OUTPUT_DIR=$(python -m dapr.exps.passage_only.args.bm25 $CLI_ARGS) mkdir -p $OUTPUT_DIR export LOG_PATH=\u0026#34;$OUTPUT_DIR/logging.log\u0026#34; echo \u0026#34;Logging file path: $LOG_PATH\u0026#34; ... **torchrun \u0026hellip; \u0026gt; $LOG_PATH：**PyTorch 的分布式训练启动器，自动设置多进程环境，将命令的 标准输出（stdout） 重定向到文件，错误输出（stderr）仍会打印到终端。\n\u0026ndash;nproc_per_node=1：使用当前机器的1个GPU \u0026ndash;master_port=295001：主进程的通信端口 -m dapr.exps.passage_only.bm25：执行的脚本文件 $CLI_ARGS：传入的参数 1 2 3 ... torchrun --nproc_per_node=1 --master_port=29501 -m dapr.exps.passage_only.bm25 $CLI_ARGS \u0026gt; $LOG_PATH done dragon_plus (passage_only) ​\tpassage_only下的dragon_plus（类似上面的passage_only.bm25），即“仅段落检索使用dragon_plus检索器”，由以下 调用 实现。\n​\treproduce_cp相当于main，其中主要执行了\u0026hellip;passage_only.args.dragon_plus.py和\u0026hellip;passage_only.dragon_plus_cp.py，前者用于配置一些参数，参数会传入后者，后者是实现功能和评估。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 |——reproduce_cp.py |——dapr.exps.passage_only.args.dragon_plus.py |\t|——dapr.exps.passage_only.args.base.py |\t|——clddp.args.base | |——dapr.exps.passage_only.dragon_plus_cp.py |——dapr.dataloader.py |——dapr.retrievers.dense.py |——dapr.dataloader.py |——clddp.dm |——clddp.search |——clddp.evaluation |——clddp.evaluation |——clddp.dm ​\t后文中，以下简称，其他一致。\n​\tdapr.exps.passage_only.args.dragon_plus.py 简称为 \u0026hellip;args.dragon_plus.py\n​\tdapr.exps.passage_only.dragon_plus_cp.py 简称为 \u0026hellip;passage_only.dragon_plus_cp.py\nreproduce_cp.py 1 |——reproduce_cp.py\t替换原本的.sh，实现模拟命令行传参 ​\treproduce_cp.py的功能为，替换原本的.sh，实现模拟命令行传参，而不用每次都在pycharm新建 运行/调试配置，大致流程和 reproduce_bm25.sh一样：\n设置全局/局部变量 执行 dapr.exps.passage_only.args.dragon_plus，生成args 再构造一些变量 执行 dapr.exps.passage_only.dragon_plus_cp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import os import subprocess from pathlib import Path import sys def main(): project_root = \u0026#34;/root/autodl-tmp/DAPR\u0026#34; # 替换为你的项目路径 os.environ[\u0026#34;PYTHONPATH\u0026#34;] = f\u0026#34;{project_root}:{os.environ.get(\u0026#39;PYTHONPATH\u0026#39;, \u0026#39;\u0026#39;)}\u0026#34; # 环境变量设置（对子进程生效） os.environ[\u0026#34;NCCL_DEBUG\u0026#34;] = \u0026#34;INFO\u0026#34; os.environ[\u0026#34;CUDA_VISIBLE_DEVICES\u0026#34;] = \u0026#34;0\u0026#34; datasets = [\u0026#34;ConditionalQA\u0026#34;] data_dir = \u0026#34;data\u0026#34; for dataset in datasets: dataset_path = Path(data_dir) / dataset cli_args = f\u0026#34;--data_dir={dataset_path}\u0026#34; try: # 获取输出目录（需传递环境变量） output_dir = subprocess.check_output( [sys.executable, \u0026#34;-m\u0026#34;, \u0026#34;dapr.exps.passage_only.args.dragon_plus\u0026#34;, cli_args], text=True, env=os.environ # 关键！确保子进程继承环境变量 ).strip() # 创建目录 output_path = Path(output_dir) output_path.mkdir(parents=True, exist_ok=True) # 日志路径 log_path = output_path / \u0026#34;logging.log\u0026#34; print(f\u0026#34;Logging to: {log_path}\u0026#34;) # 运行训练（合并 stdout 和 stderr） subprocess.run( [sys.executable, \u0026#34;-m\u0026#34;, \u0026#34;dapr.exps.passage_only.dragon_plus_cp\u0026#34;, cli_args], text=True, env=os.environ # 关键！确保子进程继承环境变量 ) except subprocess.CalledProcessError as e: print(f\u0026#34;Error for {dataset}: {e}\u0026#34;) continue if __name__ == \u0026#34;__main__\u0026#34;: main() \u0026hellip;args.dragon_plus.py 1 2 |——reproduce_cp.py\t替换原本的.sh，实现模拟命令行传参 |——...args.dragon_plus.py\t定义类 BM25PassageOnlyArguments，输出output_dir 定义类 BM25PassageOnlyArguments 继承自 PassageOnlyArguments，重要属性如下：\nrun_name: str = XXX （自动生成的实验运行的唯一名称，见PassageOnlyArguments） data_dir: str = os.path.join(\u0026quot;exps/passage_only/bm25\u0026quot;, self.run_name) # 数据集路径 split: Split = Split.test # 哪个数据部分（测试集 test 或训练集 train） topk: int = 1000 # 返回最相关的1000个结果 per_device_eval_batch_size: int = 32 # 每个GPU一次处理32条数据 fp16: bool = True # 用半精度浮点数（节省显存，加快计算） 不同点在于获取 parse_cli(BM25PassageOnlyArguments).output_dir 时使用的方法build_output_dir被重写为 os.path.join(\u0026ldquo;exps/passage_only/bm25\u0026rdquo;, self.run_name)\nreproduce_cp执行该文件，进入if __name__ == \u0026ldquo;__main__\u0026quot;，print(\u0026hellip;.output_dir)，执行完reproduce_cp捕获该内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from dataclasses import dataclass import os from clddp.utils import parse_cli from dapr.exps.passage_only.args.base import PassageOnlyArguments @dataclass class BM25PassageOnlyArguments(PassageOnlyArguments): def build_output_dir(self) -\u0026gt; str: return os.path.join(\u0026#34;exps/passage_only/bm25\u0026#34;, self.run_name) if __name__ == \u0026#34;__main__\u0026#34;: print( parse_cli(BM25PassageOnlyArguments).output_dir ) # For creating the logging path args.base.py 1 2 3 |——reproduce_cp.py\t替换原本的.sh，实现模拟命令行传参 |——...args.dragon_plus.py\t定义类 BM25PassageOnlyArguments，输出output_dir |\t|——args.base.py\t定义类 PassageOnlyArguments和一些重要参数 定义类 PassageOnlyArguments，采用MixIn机制继承两个混入类(Mixin)（可插拔组件） ——AutoRunNameArgumentsMixIn, DumpableArgumentsMixIn，从clddp.args.base里import，继承前者能自动生成一次运行唯一名词（属性），继承后者获得输出目录和写入输出目录的方法。\n设置了一些属性(见代码)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from dataclasses import dataclass from typing import Optional from clddp.args.base import AutoRunNameArgumentsMixIn, DumpableArgumentsMixIn from clddp.dm import Split @dataclass class PassageOnlyArguments(AutoRunNameArgumentsMixIn, DumpableArgumentsMixIn): data_dir: Optional[str] = None # 数据集路径 split: Split = Split.test # 哪个数据部分（测试集 test 或训练集 train） topk: int = 1000 # 返回最相关的1000个结果 per_device_eval_batch_size: int = 32 # 每个GPU一次处理32条数据 fp16: bool = True # 用半精度浮点数（节省显存，加快计算） def __post_init__(self) -\u0026gt; None: # 继承AutoRunNameArgumentsMixIn, DumpableArgumentsMixIn的初始化 # 如self.output_dir = self.build_output_dir() run_name: str = \u0026#34;auto_run_name\u0026#34; super().__post_init__() clddp.args.base 定义两个类\nAutoRunNameArgumentsMixIn：自动生成实验运行的唯一名称 DumpableArgumentsMixIn：设置output_dir和保存一些运行参数设置 1 2 3 4 |——reproduce_cp.py\t替换原本的.sh，实现模拟命令行传参 |——...args.dragon_plus.py\t定义类 BM25PassageOnlyArguments，输出output_dir |\t|——...args.base.py\t定义类 PassageOnlyArguments和一些重要参数 |\t|——clddp.args.base 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 from __future__ import annotations from dataclasses import asdict, dataclass import json import logging import os from typing import List, Optional, Set, Type from abc import ABC, abstractmethod @dataclass class AutoRunNameArgumentsMixIn: run_name: Optional[str] = None @property def escaped_args(self) -\u0026gt; Set[str]: \u0026#34;\u0026#34;\u0026#34;Escaped items for building the run_name.\u0026#34;\u0026#34;\u0026#34; return set() def get_arguments_from(self) -\u0026gt; List[type]: \u0026#34;\u0026#34;\u0026#34;Return the classes which the auto_run_name will get the arguments from.\u0026#34;\u0026#34;\u0026#34; return [self.__class__] @property def auto_run_name(self) -\u0026gt; str: arguments = [ k for from_class in self.get_arguments_from() for k in from_class.__annotations__.keys() if k not in self.escaped_args ] items = [f\u0026#34;{argument}_{getattr(self, argument)}\u0026#34; for argument in arguments] # 用/连接每个\u0026#34;属性名_属性值\u0026#34; return \u0026#34;/\u0026#34;.join(items) def __post_init__(self) -\u0026gt; None: if self.run_name is None: self.run_name = self.auto_run_name # 进行父类的__post_init__ if hasattr(super(), \u0026#34;__post_init__\u0026#34;): super().__post_init__() # Needed as a MixIn @dataclass class DumpableArgumentsMixIn(ABC): output_dir: Optional[str] = None def __post_init__(self) -\u0026gt; None: if self.output_dir is None: self.output_dir = self.build_output_dir() if hasattr(super(), \u0026#34;__post_init__\u0026#34;): super().__post_init__() # Needed as a MixIn @abstractmethod def build_output_dir(self) -\u0026gt; str: pass def dump_arguments(self, fname: str = \u0026#34;arguments.json\u0026#34;) -\u0026gt; None: os.makedirs(self.output_dir, exist_ok=True) fargs = os.path.join(self.output_dir, fname) with open(fargs, \u0026#34;w\u0026#34;) as f: json.dump(asdict(self), f, indent=4) logging.info(f\u0026#34;Dumped arguments to {fargs}\u0026#34;) \u0026hellip;passage_only.dragon_plus_cp.py 1 2 3 4 5 6 |——reproduce_cp.py\t替换原本的.sh，实现模拟命令行传参 |——...args.dragon_plus.py\t定义类 BM25PassageOnlyArguments，输出output_dir |\t|——...args.base.py\t定义类 PassageOnlyArguments和一些重要参数 |\t|——clddp.args.base 定义两个MixIn ---------|----------------------------------------------------------后面省略上面内容 |——...passage_only.dragon_plus_cp.py 其代码单步执行会顺序进出如下模块。\n1 2 3 4 5 6 7 8 9 10 |——...args.dragon_plus\t加载参数和保存参数到json文件 |——clddp.utils\t初始化ddp |——dapr.dataloader.py\tDAPRDataConfig, DAPRDataLoader实现数据加载 |——dapr.retrievers.dense.py\t引入检索器 |——dapr.dataloader.py\t获取标注好的问题 |——clddp.dm\t|——clddp.search |——clddp.evaluation |——clddp.evaluation |——clddp.dm 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 import json import logging import os from clddp.dm import LabeledQuery, RetrievedPassageIDList from clddp.utils import initialize_ddp, is_device_zero, parse_cli, set_logger_format from dapr.retrievers.dense import DRAGONPlus from dapr.exps.passage_only.args.dragon_plus import DRAGONPlusPassageOnlyArguments from clddp.search import search from dapr.dataloader import DAPRDataConfig, DAPRDataLoader from clddp.evaluation import RetrievalEvaluator import torch def is_device_zero(): return True def main(): set_logger_format(logging.INFO if is_device_zero() else logging.WARNING) # ...args.dragon_plus =============================== args = parse_cli(DRAGONPlusPassageOnlyArguments) # 加载参数 args.dump_arguments()\t# 记录参数到arguments.json # 设置环境变量 =============================== if not torch.distributed.is_initialized(): os.environ[\u0026#34;MASTER_ADDR\u0026#34;] = \u0026#34;localhost\u0026#34; os.environ[\u0026#34;MASTER_PORT\u0026#34;] = \u0026#34;29501\u0026#34; os.environ[\u0026#34;WORLD_SIZE\u0026#34;] = \u0026#34;1\u0026#34; os.environ[\u0026#34;RANK\u0026#34;] = \u0026#34;0\u0026#34; os.environ[\u0026#34;LOCAL_RANK\u0026#34;] = \u0026#34;0\u0026#34; torch.distributed.init_process_group(backend=\u0026#34;nccl\u0026#34;) # clddp.utils =============================== initialize_ddp() # 初始化 dstributed data process # dapr.dataloader =============================== dataset = DAPRDataLoader(DAPRDataConfig(args.data_dir)).load_data( progress_bar=is_device_zero() ) # dapr.retrievers.dense ================================ retriever = DRAGONPlus() # dapr.dataloader =============================== labeled_queries = dataset.get_labeled_queries(args.split) # clddp.dm ================================== queries = LabeledQuery.get_unique_queries(labeled_queries) # clddp.search retrieved = search( retriever=retriever, collection_iter=dataset.collection_iter, collection_size=dataset.collection_size, queries=queries, topk=args.topk, per_device_eval_batch_size=args.per_device_eval_batch_size, fp16=args.fp16, ) # clddp.evaluation evaluator = RetrievalEvaluator(eval_dataset=dataset, split=args.split) report = evaluator(retrieved) freport = os.path.join(args.output_dir, \u0026#34;metrics.json\u0026#34;) with open(freport, \u0026#34;w\u0026#34;) as f: json.dump(report, f, indent=4) logging.info(f\u0026#34;Saved evaluation metrics to {freport}.\u0026#34;) franked = os.path.join(args.output_dir, \u0026#34;ranking_results.txt\u0026#34;) RetrievedPassageIDList.dump_trec_csv( retrieval_results=retrieved, fpath=franked, system=\u0026#34;dragon_plus\u0026#34; ) logging.info(f\u0026#34;Saved ranking results to {franked}.\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() clddp.utils 1 2 3 4 ----|---------------------上面省略 |——...passage_only.dragon_plus_cp.py |——...args.dragon_plus\t加载参数和保存参数到json文件 |——clddp.utils\t初始化ddp dapr.dataloader.py 1 2 3 4 5 ----|---------------------上面省略 |——...passage_only.dragon_plus_cp.py |——...args.dragon_plus\t加载参数和保存参数到json文件 |——clddp.utils\t初始化ddp |——dapr.dataloader.py\tDAPRDataConfig, DAPRDataLoader实现数据加载 dragon_plus_cp中语句：\n1 2 3 4 # dapr.dataloader =============================== dataset = DAPRDataLoader(DAPRDataConfig(args.data_dir)).load_data( progress_bar=is_device_zero() ) 分两步：\nDAPRDataConfig(args.data_dir)\nDAPRDataLoader(\u0026hellip;).load_data( progress_bar=is_device_zero() )\nwhere is_device_zero()==True 单卡模式\n1 2 3 4 5 6 7 8 # DAPRDataConfig(args.data_dir) @dataclass class DAPRDataConfig: data_name_or_path: str # 路径字符串\u0026#34;os.path.join(\u0026#34;exps/passage_only/dragon_plus\u0026#34;, self.run_name)\u0026#34; titled: bool = False # 类RetrievalLevel和ParagraphSeparator其实就是C中结构体，静态的 retrieval_level: RetrievalLevel = RetrievalLevel.paragraph # \u0026#34;paragraph\u0026#34; paragraph_separator: ParagraphSeparator = ParagraphSeparator.blank # \u0026#34;blank\u0026#34; （DAPRDataLoader只列出用到的内容）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class DAPRDataLoader: def __init__(self, config: DAPRDataConfig) -\u0026gt; None: self.config = config ... def load_data(self, progress_bar: bool) -\u0026gt; RetrievalDataset: data = LoadedData.from_dump(self.config.data_name_or_path, pbar=progress_bar) assert data.meta_data is not None retrieval_level = self.config.retrieval_level if retrieval_level is RetrievalLevel.document: collection_size = data.meta_data[\u0026#34;ndocs\u0026#34;] else: collection_size = ( data.meta_data[\u0026#34;nchunks\u0026#34;] if data.meta_data.get(\u0026#34;nchunks_candidates\u0026#34;) is None else data.meta_data[\u0026#34;nchunks_candidates\u0026#34;] ) dataset = RetrievalDataset( collection_iter_fn=partial(self.collection_iter_fn, data=data), collection_size=collection_size, train_labeled_queries=self.build_labeled_queries( labeled_queries=data.labeled_queries_train ), dev_labeled_queries=self.build_labeled_queries( labeled_queries=data.labeled_queries_dev ), test_labeled_queries=self.build_labeled_queries( labeled_queries=data.labeled_queries_test ), ) return dataset dapr.datasets.dm 1 2 3 4 5 6 ----|---------------------上面省略 |——...passage_only.dragon_plus_cp.py |——...args.dragon_plus\t加载参数和保存参数到json文件 |——clddp.utils\t初始化ddp |——dapr.dataloader.py\tDAPRDataConfig, DAPRDataLoader实现数据加载 |——dapr.datasets.dm\t1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 @dataclass class LoadedData: # data: corpus_iter_fn: Optional[Callable[[], Iterable[Document]]] = None labeled_queries_train: Optional[List[LabeledQuery]] = None labeled_queries_dev: Optional[List[LabeledQuery]] = None labeled_queries_test: Optional[List[LabeledQuery]] = None # meta data: meta_data: Optional[MetaDataJson] = None ... @staticmethod def build_corpus_iter_fn(fpath: str) -\u0026gt; Iterable[Document]: with open(fpath) as f: for line in f: doc_json: DocumentJson = ujson.loads(line) document = Document.from_json(doc_json) document.set_default_candidates() # Also for compatibility with the older version yield document @staticmethod def load_labeled_queries( fpath: str, total: int, pbar: bool ) -\u0026gt; Optional[List[LabeledQuery]]: # fpath 文件路径 total 问答对个数 pbar对于device 0 是true if not os.path.exists(fpath): return None labeled_queries: List[LabeledQuery] = [] with open(fpath) as f: for line in tqdm.tqdm( f, total=total, desc=f\u0026#34;Loading from {fpath}\u0026#34;, disable=not pbar ): lq_json: LabeledQueryJson = ujson.loads(line) query_json = lq_json[\u0026#34;query\u0026#34;] query = Query(query_id=query_json[\u0026#34;id\u0026#34;], text=query_json[\u0026#34;text\u0026#34;]) judged_chunk_jsons = lq_json[\u0026#34;judged_chunks\u0026#34;] judged_chunks = [] for jchk_json in judged_chunk_jsons: document = Document.from_json(jchk_json[\u0026#34;belonging_doc\u0026#34;]) chunk_json: ChunkJson = jchk_json[\u0026#34;chunk\u0026#34;] chunk = Chunk( chunk_id=chunk_json[\u0026#34;id\u0026#34;], text=chunk_json[\u0026#34;text\u0026#34;], doc_summary=None, belonging_doc=document, ) jchk = JudgedChunk( query=query, chunk=chunk, judgement=jchk_json[\u0026#34;judgement\u0026#34;] ) judged_chunks.append(jchk) labeled_query = LabeledQuery(query=query, judged_chunks=judged_chunks) labeled_queries.append(labeled_query) return labeled_queries @classmethod def from_dump( cls: Type[LoadedData], dump_dir: str, pbar: bool = True ) -\u0026gt; LoadedData: # dump_dir=\u0026#34;.../ConditionalQA\u0026#34; # 加载meta_data.json里的数据 with open(os.path.join(dump_dir, \u0026#34;meta_data.json\u0026#34;)) as f: meta_data: MetaDataJson = ujson.load(f) meta_data[\u0026#34;chunk_separator\u0026#34;] = Separator(meta_data[\u0026#34;chunk_separator\u0026#34;]) # 实例化并传出 loaded_data = cls( corpus_iter_fn=partial( cls.build_corpus_iter_fn, os.path.join(dump_dir, \u0026#34;corpus.jsonl\u0026#34;) ), labeled_queries_train=cls.load_labeled_queries( fpath=os.path.join(dump_dir, \u0026#34;train.jsonl\u0026#34;), total=meta_data[\u0026#34;nqueries_train\u0026#34;], pbar=pbar, ), labeled_queries_dev=cls.load_labeled_queries( fpath=os.path.join(dump_dir, \u0026#34;dev.jsonl\u0026#34;), total=meta_data[\u0026#34;nqueries_dev\u0026#34;], pbar=pbar, ), labeled_queries_test=cls.load_labeled_queries( fpath=os.path.join(dump_dir, \u0026#34;test.jsonl\u0026#34;), total=meta_data[\u0026#34;nqueries_test\u0026#34;], pbar=pbar, ), meta_data=meta_data, ) return loaded_data 总结 屎一样的代码\n","date":"2025-07-22T16:50:01+08:00","permalink":"https://rooobeam.github.io/p/dapr/","title":"DAPR"},{"content":"Baselines Vanilla RAG 分块100tokens，边界处保留完整句子，也就是说100+tokens，用Snowflake Arctic-embed-m 1.5 embdding 文本块和query，查询时计算 cosine similarity，排序，取排名靠前的块，直到到达最大输入tokens，最后按降序方式和query给LLM。\nFull-Document Baseline 仅在 QuALITY 上测试（其doc都在最大input范围内），保证无keyinf丢失。\nDOS RAG 与Vanilla RAG不同之处在于，最后按原文档集里出现的顺序和query提交给LLM。\n","date":"2025-07-21T18:04:13+08:00","permalink":"https://rooobeam.github.io/p/%E6%96%AF%E5%9D%A6%E7%A6%8F%E9%87%8D%E8%AE%BErag%E6%96%B0%E5%9F%BA%E7%BA%BF%E4%B9%8Bdos_rag/","title":"斯坦福重设RAG新基线之DOS_RAG"},{"content":"大学生LaTeX 报告模板 本模板适用于撰写大作业报告，基于成都理工大学（CDUT）的报告格式规范进行修改，包含完整的文档结构（标题页、摘要、目录、章节、参考文献、附录等），页面和英文字体设置遵循一个英国项目规范Research_Project_Guide.pdf，并提供了详细的使用说明。\n📁 文件结构 以下是模板的文件结构及各文件用途说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ├── main.tex # 主文档文件（整合所有子文件，编译入口） ├── titlepage.tex # 标题页模板（包含标题、作者、日期等） ├── abstract.tex # 摘要部分（中英文摘要） ├── chapter1.tex # 第一章内容（可扩展为chapter2.tex、chapter3.tex等） ├── reference.tex # 参考文献部分（引用bib数据库） ├── appendix.tex # 附录部分（补充数据、代码等） ├── backpage.tex # 封底页（可选） ├── manual.tex # 使用手册（详细说明公式、图片、表格等插入方法） ├── ref.bib # 参考文献数据库（BibTeX格式，需与reference.tex关联） ├── Research_Project_Guide.pdf # 一个英国项目的规范指导书 ├── configuration/ # 配置文件夹（格式、字体、自定义命令） │ ├── CDUTReport.cls # 核心类文件（定义页面布局、章节格式等） │ ├── Mycommand.sty # 自定义命令（快捷插入图片、表格等） │ ├── Font set.tex # 字体设置（使用Fandol系列中文字体） │ ├── Title set.tex # 标题格式设置（标题页、章节标题样式） │ └── Fandol*.otf # Fandol字体文件（黑体、宋体、楷体，需安装或保留） ├── figs/ # 图片文件夹（存放文档中使用的所有图片） └── README.md # 本说明文件 🚀 使用说明 1. 环境要求 LaTeX 编译器：需使用 XeLaTeX。 字体依赖：configuration文件夹中的Fandol字体（FandolHei-Bold.otf、FandolSong-Regular.otf等）需保留，或安装到系统字体目录。 2. 编译步骤 克隆仓库： 1 git clone https://github.com/rooobeam/General-LaTeX-Template-for-College-Students.git 编译主文档（需多次运行以确保交叉引用和参考文献正确）： 第一步：xelatex main.tex（生成辅助文件） 第二步：bibtex main（编译参考文献，若使用ref.bib数据库） 第三步：xelatex main.tex（更新参考文献引用） 第四步：xelatex main.tex（确保所有交叉引用正确） 3. 内容填充 标题页：修改titlepage.tex中的标题、作者、日期等信息。 摘要：在abstract.tex中填写中英文摘要。 章节内容：在chapter1.tex、chapter2.tex等文件中撰写章节内容，可通过\\input{chapter1}在main.tex中引用。 参考文献：将文献条目添加到ref.bib文件中，使用\\cite{key}在文档中引用，reference.tex会自动生成参考文献列表。 图片：将图片放在figs文件夹中，使用\\includegraphics{figs/figure1.png}引用（需加载graphicx包，模板已包含）。 ⚙️ 配置说明 1. 类文件（CDUTReport.cls） 定义了报告的核心格式，包括：\n页面布局（A4纸、页边距、页眉页脚）； 章节样式（标题字体、编号格式）； 目录生成（自动提取章节标题）。 如需修改格式，可编辑此类文件，但建议先备份。 2. 自定义命令（Mycommand.sty） 提供了快捷命令，简化重复操作，例如：\n\\fig{path}{caption}：插入图片并添加说明； \\tab{label}{caption}{table content}：插入表格并添加标签； \\code{language}{code content}：插入代码块（使用listings包）。 可根据需要添加或修改自定义命令。 3. 字体设置（Font_set.tex） Font_set.tex 是模板的核心字体配置文件，定义了中文、西文、章节标题及表格的字体样式，确保文档符合学术规范且显示清晰。以下是关键配置说明（详细使用示例请参考 manual.tex 中的 1.8 字体 章节，第3页）：\n（1）基础字体选择 模板使用常见西文字体(Arial)并搭配Fandol系列中文字体（需保留 configuration 文件夹中的 .otf 字体文件），具体如下：\n中文字体： 主字体（默认正文）：FandolSong-Regular.otf（宋体），加粗时自动切换为 FandolSong-Bold.otf，斜体时使用 FandolKai-Regular.otf（楷体）； 无衬线字体（用于标题/强调）：FandolHei-Regular.otf（黑体），加粗时使用 FandolHei-Bold.otf； 等宽字体（用于代码/数据）：FandolHei-Regular.otf（黑体），加粗时使用 FandolHei-Bold.otf。 西文字体： 主字体/无衬线字体：Arial（系统默认安装，确保西文显示清晰）； 正式西文字体（用于表格/公式）：Times New Roman（通过 \\timesnewroman 命令调用）。 （2）自定义字体快捷命令 为方便切换字体，模板定义了以下常用命令（在 manual.tex 中有详细示例）：\n\\songti：切换为宋体（中文正文默认字体，适合大段文字）； \\heiti：切换为黑体（用于章节标题、重点内容，增强视觉层次感）； \\kaishu：切换为楷体（用于引用、注释或需要区分的内容，风格更正式）。 （3）章节标题字体设置 通过 titlesec 包优化了章节标题的格式，确保层级清晰：\n章节（section）：黑体、16pt、加粗、居中显示，标题前自动添加“第X章”（如“2. Problem Restatement”）； 小节（subsection）：黑体、14pt、加粗，左侧显示小节编号（如“2.1 Problem Background”）； 子小节（subsubsection）：黑体、12pt、加粗，左侧显示子小节编号（如“1.1.1 abcd”）。 （4）表格字体配置 表格内容默认使用Times New Roman 10pt字体（符合学术文档的严谨风格），通过重定义 tabular 和 tabularx 环境实现，无需手动设置。\n（5）注意事项 字体安装：若系统未安装Fandol字体，需将 configuration 文件夹中的字体文件（如 FandolHei-Bold.otf、FandolSong-Regular.otf 等）复制到系统字体目录（如 Windows 的 C:\\Windows\\Fonts）； 西文字体依赖：Arial 是大多数系统的默认字体，若未安装需手动添加； 修改字体：若需调整字体样式（如增大标题字体），可编辑 Font_set.tex 中的 \\titleformat 或 \\setCJKmainfont 命令，但建议先备份原文件。 通过以上配置，模板确保了文档的字体一致性和学术规范性，同时提供了灵活的字体切换功能，满足不同场景的需求。如需更详细的字体使用说明，请参考 manual.tex 中的 1.8 字体 章节（第3页）。\n📖 示例与手册 manual.tex是详细的使用手册，包含以下内容：\n文件结构 插入公式 插入图片 插入表格 插入伪代码 粘贴代码 引用 字体 添加脚注并设置链接 建议用户先查看manual.tex，学习如何使用模板的各项功能。\n⚠️ 注意事项 编译环境：必须使用XeLaTeX编译，否则中文字体可能无法正确显示。 图片路径：所有图片请放在figs文件夹中，使用相对路径引用（如figs/figure1.png），避免绝对路径导致的问题。 参考文献：ref.bib文件需为BibTeX格式，并在reference.tex中使用\\bibliography{ref}引用。 自定义命令：修改Mycommand.sty前请备份，避免误操作导致模板无法编译。 交叉引用：使用\\label{chapter1}为章节添加标签，使用\\ref{chapter1}引用，编译时需多次运行XeLaTeX以确保引用正确。 📞 联系方式 若有问题或建议，可通过以下方式联系作者：\nGitHub Issues：https://github.com/rooobeam/General-LaTeX-Template-for-College-Students.git/issues Email：rooobeam@uir.edu.cn LaTeX Template for College Students\u0026rsquo; Reports This template is suitable for writing term paper reports. It is modified based on the report format specifications of Chengdu University of Technology (CDUT) and includes a complete document structure (title page, abstract, table of contents, chapters, references, appendices, etc.). The page and English font settings adhere to the British project specification Research_Project_Guide.pdf, and detailed usage instructions are provided.\n📁 File Structure The following is the file structure of the template and explanations of each file\u0026rsquo;s purpose:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ├── main.tex # Main document file (integrates all subfiles, compilation entry point) ├── titlepage.tex # Title page template (includes title, author, date, etc.) ├── abstract.tex # Abstract section (Chinese and English abstracts) ├── chapter1.tex # Chapter 1 content (can be extended to chapter2.tex, chapter3.tex, etc.) ├── reference.tex # References section (cites the bib database) ├── appendix.tex # Appendix section (supplementary data, code, etc.) ├── backpage.tex # Back cover page (optional) ├── manual.tex # User manual (details on inserting equations, images, tables, etc.) ├── ref.bib # Bibliography database (BibTeX format, must be linked to reference.tex) ├── Research_Project_Guide.pdf # British project specification guide ├── configuration/ # Configuration folder (format, fonts, custom commands) │ ├── CDUTReport.cls # Core class file (defines page layout, chapter styles, etc.) │ ├── Mycommand.sty # Custom commands (quick insertion of images, tables, etc.) │ ├── Font set.tex # Font settings (uses Fandol series Chinese fonts) │ ├── Title set.tex # Title format settings (title page, chapter title styles) │ └── Fandol*.otf # Fandol font files (Hei, Song, Kai; must be retained or installed) ├── figs/ # Image folder (stores all images used in the document) └── README.md # This instruction file 🚀 Usage Instructions 1. Environment Requirements LaTeX Compiler: XeLaTeX is required. Font Dependencies: Fandol fonts in the configuration folder (e.g., FandolHei-Bold.otf, FandolSong-Regular.otf) must be retained or installed to the system font directory (e.g., C:\\Windows\\Fonts for Windows). 2. Compilation Steps Clone the Repository: 1 git clone https://github.com/rooobeam/General-LaTeX-Template-for-College-Students.git Compile the Main Document (run multiple times to ensure correct cross-references and references): Step 1: xelatex main.tex (generate auxiliary files) Step 2: bibtex main (compile references if using ref.bib) Step 3: xelatex main.tex (update reference citations) Step 4: xelatex main.tex (ensure all cross-references are correct) 3. Content Filling Title Page: Modify the title, author, date, and other information in titlepage.tex. Abstract: Fill in the Chinese and English abstracts in abstract.tex. Chapter Content: Write chapter content in chapter1.tex, chapter2.tex, etc., and reference them in main.tex using \\input{chapter1}. References: Add bibliographic entries to ref.bib and cite them in the document using \\cite{key}. The reference.tex file will automatically generate the references list. Images: Place images in the figs folder and reference them using \\includegraphics{figs/figure1.png} (the graphicx package is included in the template). ⚙️ Configuration Instructions 1. Class File (CDUTReport.cls) Defines the core format of the report, including:\nPage layout (A4 paper, margins, header/footer); Chapter styles (title fonts, numbering format); Table of contents generation (automatically extracts chapter titles).\nTo modify the format, edit this file, but backup first. 2. Custom Commands (Mycommand.sty) Provides shortcut commands to simplify repetitive operations, e.g.:\n\\fig{path}{caption}: Insert an image with a caption; \\tab{label}{caption}{table content}: Insert a table with a label; \\code{language}{code content}: Insert a code block (uses the listings package).\nAdd or modify custom commands as needed. 3. Font Settings (Font_set.tex) Font_set.tex is the core font configuration file of the template, defining the font styles for Chinese, Western text, chapter titles, and tables to ensure the document complies with academic standards and displays clearly. Below are key configuration explanations (for detailed usage examples, refer to Section 1.8 Fonts in manual.tex, Page 3):\n(1) Basic Font Selection The template uses common Western fonts (Arial) paired with Fandol series Chinese fonts (retain the .otf files in the configuration folder):\nChinese Fonts: Main font (default body text): FandolSong-Regular.otf (SimSun), automatically switches to FandolSong-Bold.otf when bold, and uses FandolKai-Regular.otf (KaiTi) for italics; Sans-serif font (for titles/emphasis): FandolHei-Regular.otf (HeiTi), switches to FandolHei-Bold.otf when bold; Monospace font (for code/data): FandolHei-Regular.otf (HeiTi), switches to FandolHei-Bold.otf when bold. Western Fonts: Main/sans-serif font: Arial (preinstalled on most systems, ensures clear Western text display); Formal Western font (for tables/equations): Times New Roman (called via \\timesnewroman). (2) Custom Font Shortcut Commands To facilitate font switching, the template defines the following common commands (examples in manual.tex):\n\\songti: Switch to SimSun (default Chinese body text, suitable for long passages); \\heiti: Switch to HeiTi (for chapter titles, key content, enhances visual hierarchy); \\kaishu: Switch to KaiTi (for quotes, annotations, or differentiated content, more formal style). (3) Chapter Title Font Settings Optimizes chapter title formats using the titlesec package for clear hierarchy:\nSection: HeiTi, 16pt, bold, centered, automatically adds \u0026ldquo;Chapter X\u0026rdquo; before the title (e.g., \u0026ldquo;2. Problem Restatement\u0026rdquo;); Subsection: HeiTi, 14pt, bold, left-aligned with subsection number (e.g., \u0026ldquo;2.1 Problem Background\u0026rdquo;); Subsubsection: HeiTi, 12pt, bold, left-aligned with subsubsection number (e.g., \u0026ldquo;1.1.1 abcd\u0026rdquo;). (4) Table Font Configuration Table content uses Times New Roman 10pt by default (complies with academic document rigor), implemented by redefining the tabular and tabularx environments—no manual setting required.\n(5) Notes Font Installation: If Fandol fonts are not installed, copy the font files (e.g., FandolHei-Bold.otf, FandolSong-Regular.otf) from the configuration folder to the system font directory (e.g., C:\\Windows\\Fonts for Windows); Western Font Dependencies: Arial is a default font on most systems—install manually if missing; Modifying Fonts: To adjust font styles (e.g., increase title font size), edit the \\titleformat or \\setCJKmainfont commands in Font_set.tex, but backup first. Through the above configurations, the template ensures font consistency and academic规范性 (academic standardization) while providing flexible font switching to meet different needs. For more detailed font usage instructions, refer to Section 1.8 Fonts in manual.tex (Page 3).\n📖 Examples and Manual manual.tex is a detailed user manual covering the following content:\nFile Structure Insert Equations Insert Images Insert Tables Insert Pseudocode Paste Code Citations Fonts Add Footnotes and Set Links It is recommended to read manual.tex first to learn how to use the template\u0026rsquo;s features.\n⚠️ Notes Compilation Environment: XeLaTeX must be used for compilation—otherwise, Chinese fonts may not display correctly. Image Path: All images must be placed in the figs folder and referenced using relative paths (e.g., figs/figure1.png) to avoid issues with absolute paths. References: The ref.bib file must be in BibTeX format and referenced in reference.tex using \\bibliography{ref}. Custom Commands: Backup Mycommand.sty before modifying to avoid template compilation failures due to incorrect operations. Cross-References: Use \\label{chapter1} to add labels to chapters and \\ref{chapter1} to cite them—run XeLaTeX multiple times to ensure correct cross-references. 📞 Contact Information For questions or suggestions, contact the author via:\nGitHub Issues: https://github.com/rooobeam/General-LaTeX-Template-for-College-Students.git/issues Email: rooobeam@uir.edu.cn ","date":"2025-07-02T12:36:24+08:00","permalink":"https://rooobeam.github.io/p/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%8A%A5%E5%91%8Alatex%E6%A8%A1%E6%9D%BF/","title":"大学生报告LaTeX模板"},{"content":"用法理解 从0到1，手把手教你如何使用哈工大NLP工具——PyLTP-腾讯云开发者社区-腾讯云\n在线演示 语言技术平台（ Language Technology Plantform | LTP ）\n代码实现 语言技术平台（ Language Technology Plantform | LTP ）\n本地下载模型到\u0026quot;./ltp_models/small\u0026quot;，下载内容：LTP/small at main\n1 2 3 4 5 6 7 8 from ltp import LTP import os MODEL_DIR = \u0026#34;./ltp_models/small\u0026#34; os.makedirs(MODEL_DIR, exist_ok=True) ltp = LTP(MODEL_DIR) result = ltp.pipeline([\u0026#34;他叫汤姆去拿外衣。\u0026#34;], tasks = [\u0026#34;cws\u0026#34;,\u0026#34;dep\u0026#34;]) print(result.dep) 云计算背景\n五大特征 资源池化\u0026hellip;按需\u0026hellip; 云服务应用的四种部署模型：公有 私有 社区 混合 三种服务模式：SAS PAS IAS 大数据三V特征 云数据面临的威胁：数据泄露、损坏、冗余 门限安全去重\n云存储的优势 数据去重策略分类哪几种，文件级块级，优缺点 攻击者 两大特征重要：客户端去重特性，目标端去重特性 攻击者 如何判断去重是否发生：观察流量判断去重是否发生，伪装成用户遍历所有版本 随机阈值方案：为什么要分配随机阈值，为什么是随机阈值，假如设置一个全局阈值会有什么问题 随机冗余块方案\n数据去重中LRI攻击带来的挑战是？CE或MAIR的局限性是？ 现有解决LRI的模型 通用模型 RRCS的基本思路是？ RRCS包括三个关键功能模块是什么，分别有什么作用：范围生成、边界设置，安全无关消除 一般情况下的LRI攻击，有附加块的LRI攻击，分别给出隐私泄露的概率，以课上讲的为准，课件有误。 请求合并方案\n流量混淆的局限性：无法确定敏感块具体位置，无法抵抗附加块攻击 描述请求合并方案的系统模型和威胁模型：系统-有那几个参与方，怎么交互，上传前切块，计算哈希\u0026hellip;。威胁-只有一个敏感块，其他都公开块，存在什么安全威胁 分析请求合并方案在有附加块下的安全性，分多种情况，情况课件上。 宙斯+IARE\n区分 存在性隐私、弱存在性隐私、不存在性隐私保护\nZOUS方案三大优点是？\nZOUS包含的三种技术是什么：？、sor混合、脏块列表\nZOUS在单次去重检查 多次去重检查 的 安全性分析，要求给出概率分析，对应到三种隐私保护\nRARE相对ZOUS的改进在哪里\n编码客户端去重\n跨用户的客户端数据去重面临的问题是什么？云端透露一些数据的存在性状态确保去重发生以及节省带宽，另一方面，又希望数据信息存在性隐私得到保护。 CIDER的返回值区间为什么要这样设置，能否更改返回值区间 每次都要求上传100个会有什么问题 返回值不是连续递增的话会怎么样 8 9 10没命中，要求上传11 12，提到过的上传的问题 断层问题 理解各种情况，理解CIDER响应表为什么这样设计 CIDER的安全性分析：攻击者不同，不同响应值的分析 广义去重\n就是把这个分为..，分为基和偏移量，对基开展跨用户，会偏移量开展云端去重 为什么这样能抵抗侧信道攻击 对基的提取有什么样的要求：对基泛化，要用较大的概率提取相同的基，然后\u0026hellip;，从相似数据提取相同基 挂昂以去除安全性分析：证明对于 单一模板的 第最小上文件，对于重复模板文件（数据库文件） 异或策略\n异或策略的威胁模型是？用M_r表示随机生成的，调皮M_r和M？的比例可以，怎么去调配来窃取存在性隐私 异或策略增强方案核心策略，基础方案中P大于1的时候才会有块需要被抑或两次，增强方案，无论攻击者，..推测块的隐私 增强方案里 设置pmin pmax，防止攻击者观察异或两次的块的数量窃取隐私 DCE技术（唯一对应密文）\nDCE方案的主要优势？在减少云端存储前提下减少侧信道攻击 k匿名的概念，只有当k个用户都拥有..才聚合，几个大C，才能解出c 掌握基础方案 增强方案 各个组件和功能，看看课件上的两个例子，两个方案怎么做的，回头看懂每个形式化的表述 基础方案缺点是，增强方案的改进是？ 完整性审计PDP\n解决云数据 损坏或篡改的发现\n损坏、篡改原因有哪些？课件上有，第三方攻击，云保障声誉\n数据完整性审计的目标是？公开验证/审计 什么意思：允许第三方协助、不限次数、数据动态更新操作：课件为准\npdp为代表的完整性审计流程是怎样的，分块、标签\nPDP是基于RSA签名构造的完整性审计方法\nRSA加解密算法流程、签名原理\nPDP流程和详细推导，如何验证签名的\n云端数据损坏率为t的情况下，一次挑战C个块，就可以以不小于P的概率发现，如何推导的，从实际t推导，当时那个259的计算。（计算器）\n基础方案优缺点分析，最后一次课 课件上讲的两个基础方案支持隐私保护的三方\n支持公开审计的三方审计模型的基本原理，要求明确每一方的任务是什么\n怎么去支持无限次挑战防止重放攻击\n要知道支持批量审计的，推导不用\n隐私泄露的问题在哪里，如何防止隐私泄露的？\n这个方法完整的推导过程，双线性等式是如何推导的\n这个方法存在什么样的安全性问题。\n备注：\n基本所有知识点涵盖了，选择填空以PPT原始表述为准，知识点位置、概念、原理搞懂，机制怎么工作的、安全性、另外形式上的几个定义 几个密钥生成 有几个算法。\n判断 对错难\n主观题多写，计算题，写文字步骤，然后列计算的式子。\n大题，会有一点细节的地方\n","date":"2025-06-03T20:27:49+08:00","permalink":"https://rooobeam.github.io/p/ltp/","title":"Ltp"},{"content":"ssh密钥进行github身份验证，ssh公私密钥使用详解，github密钥配置与使用，git密钥使用详解，git入门教程_哔哩哔哩_bilibili\nGit 常见错误 之 error: src refspec xxx does not match any / error: failed to push some refs to 简单解决方法_error: src refspec master does not match any-CSDN博客\n手把手教你用git上传项目到GitHub（图文并茂，这一篇就够了），相信你一定能成功！！ - 知乎\n更改默认分支 - GitHub 文档\n云和本地ssh密钥配置 见第一个链接视频\n本地文件夹上传到main 在项目文件夹右键然后找到git bash点击打开 输入以下命令： 1 2 3 4 5 git init git add . git commit -m \u0026#34;first\u0026#34; git remote add healthrag git@github.com:rooobeam/HealthRAG.git # 关联远程仓库 healrag是远程名，本地名会显示在输入上一行末尾蓝色字体。 git push -u healthrag master # master是本地名，即蓝色字体 然后到github上仓库页面，找到右上角setting，进入setting找到Default branch，更改然后可以把旧的删掉，然后添加README.md如果原本没有的话。\n如果不想用master这一默认本地名，输入以下命令可以改为新名（mmm），但是不要与原本远程仓库已有branch否则要merge。\n1 git branch -m master mmm ","date":"2025-05-25T18:48:08+08:00","permalink":"https://rooobeam.github.io/p/git/","title":"Git"},{"content":"python asyncio 如何获取当前的协程 id 编号 - SegmentFault 思否\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import asyncio import contextvars # 申明Context变量 request_id = contextvars.ContextVar(\u0026#39;Id of request\u0026#39;) async def main(): # 设置并发数 max_concurrent = 5 semaphore = asyncio.Semaphore(max_concurrent) # 内部函数，不显式传参 async def get(): # Get Value print(f\u0026#39;Request ID (Inner): {request_id.get()}\u0026#39;) # 协程 async def limited_task_lq(task_id: int): async with semaphore: request_id.set(task_id) await get() print(f\u0026#39;Request ID (Outer): {request_id.get()}\u0026#39;) await asyncio.gather( *[limited_task_lq(task_id=i % max_concurrent) for i in range(15)]) if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(main()) ","date":"2025-05-23T09:42:02+08:00","permalink":"https://rooobeam.github.io/p/asyncio/","title":"Asyncio"},{"content":"Loss是最终的，你要让它最小，就要调整它下面的变量。\n某个变量它变化一定的值会导致loss也变化一定的值，如果是1元也就是一维，没有方向可选，变化率也一定，但是到了多维比如二维就不是了。\n对不同变量求得的各种偏导是 当前位置下 要使loss变小最快的 方向，方向很好理解，各种偏导值不一样呈现一定比例，最快的话看图，方向变一下走单位距离，z增大的幅度都不是最大（在xyz三维情况下）。\n所以output和实际值y共同构造了Loss，而且Loss值本身只是反映一下差异，这个值并没有参与反向传播。\n但是实际值y会，它相当于一个参数，不是变量，要知道计算偏导时，其他变量也会被当作参数，共同作用于某个变量的偏导。\n比如说求词向量偏导，偏置都不会去影响它（我没记错的话），当前的权重和实际值y会。\n损失函数得出的值不会参与反向传播，但是函数的形式即 如何加工output和实际值y，会影响实际值y对变量偏导的影响。\n如1/2*(y^-y)^2，对y^（即output/估计值）求导得出 y^的偏导 = y^-y，这里可以体现实际值y对y^偏导的影响，即式子中的“-y”。\n而y^的偏导由链式法则会影响w、b、x的偏导，所以y也以“-y”的方式影响他们。\n如果是softmax后交叉熵\n参考下文理解\n小白零基础学习：详解梯度下降算法：完整原理+公式推导+视频讲解_标准梯度下降算法 损函数-CSDN博客\n导数，偏导数，方向导数，梯度的理解\u0026mdash;微积分数学基础_u对法向量求偏导是什么-CSDN博客\n","date":"2025-05-18T18:51:54+08:00","permalink":"https://rooobeam.github.io/p/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/","title":"梯度下降法"},{"content":"OS os.path.join() os.path.exists() os.listdir() os.path.isdir() open with open(\u0026hellip;) as f\n1 2 3 4 5 # 例子 with open(\u0026#39;_20_data.txt\u0026#39;, \u0026#39;r\u0026#39;) as file: # 读取数据 N\\n1 2 3 n = int(file.readline().strip()) data = list(map(int, file.read().split())) 参数1：文件地址 参数2：读写方式 w从头写 r只读 a追加\n读写方式 是否为 二进制 是否为 可读可写 r 空 空 w b + a 共\t3*2*2=12种\n模式对照表 和 f.seek(n)\n模式 描述 文件存在 文件不存在 指针位置 r+ 读写（文件必须存在） 不清空，从指针位置“覆盖写” 报错 开头 w+ 写读（清空后读写） 必定清空，从指针位置写 创建 开头 a+ 追加读写 必定从末尾写 创建 末尾 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 创建文件 with open(\u0026#39;test_r+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;旧内容\u0026#39;) # r+ try:\t# 不存在改文件会报错 with open(\u0026#39;test_r+.txt\u0026#39;, \u0026#39;r+\u0026#39;) as f: print(f.read()) # 输出: 旧内容^ （^指针位置） f.seek(0)\t# ^旧内容\t（移动指针位置到开头） f.write(\u0026#39;新\u0026#39;) # 新^内容\t（从指针位置覆盖写入） f.seek(0)\t# ^新内容 print(f.read()) # 输出: 新内容 except FileNotFoundError: print(\u0026#34;文件不存在\u0026#34;) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 创建文件 with open(\u0026#39;test_w+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;原始内容\u0026#39;) # w+ with open(\u0026#39;test_w+.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;全新内容\u0026#39;) # 清空后写入 全新内容^ f.seek(0)\t# 移动指针到开头\t^全新内容 print(f.read()) # 输出: 全新内容 # 文件不存在时 import os with open(\u0026#39;new_w+.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;创建内容\u0026#39;)\tf.seek(0) print(os.path.abspath(\u0026#39;new_w+.txt\u0026#39;)) # 输出: 创建的文件的绝对路径 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建文件 with open(\u0026#39;test_a+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;初始行\\n\u0026#39;) # a+ with open(\u0026#39;test_a+.txt\u0026#39;, \u0026#39;a+\u0026#39;) as f: f.write(\u0026#39;追加行\\n\u0026#39;) # 追加行\\n^ f.seek(0) # ^初始行\\n追加行\\n print(f.read()) # 输出: 初始行\\n追加行\\n # 验证指针特性 f.seek(5) # 初始行\\n追^加行\\n f.write(\u0026#39;中间插入\u0026#39;) # 仍然追加到文件末尾！ f.seek(0) print(f.read()) # 输出: 初始行\\n追加行\\n中间插入 ","date":"2025-05-11T23:17:20+08:00","permalink":"https://rooobeam.github.io/p/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/","title":"文件读写"},{"content":"Tree Search 目录结构 - - - - 一、翻转树 二、相同树 三、层序遍历并标序 四、对称树 五、二叉树的最大深度 六、二叉树的最小深度 七、路径总和 八、二叉树层序遍历无标序号 九、岛屿的周长 十、左叶子之和 十一、二叉搜索树的最小绝对差 十二、二叉树层序遍历II 十三、合并二叉树 十四、二叉树的层平均值 十五、找出克隆二叉树中的相同节点 十六、图像渲染 [十七、N叉树的最大深度](#十七N 叉树的最大深度) 十八、单值二叉树 十九、二叉树的堂兄弟节点 二十、寻找图中是否存在路径 二十一、另一棵树的子树 二十二、二叉树中第二小的节点 二十三、二叉搜索树中的众数 二十四、表格里单词搜索 二十五、二叉树化单链表 二十六、找到所有的农场组 [二十七、路径总和 II](#二十七路径总和 II) 二十八、二叉树展开为链表 队列的运用：一、二、\n一、翻转树 给你一棵二叉树的根节点 root ，翻转这棵二叉树，并返回其根节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def invertTree(self, root: Optional[TreeNode]) -\u0026gt; Optional[TreeNode]: # 排除root为空的情况 if not root: return root # 队列 \u0026lt;——\u0026gt; list que=[root]\t# 循环条件：队列不为空 while que: # 出队 tnode=que.pop(0) # 如果左子树存在，入队 if tnode.left: que.append(tnode.left) # 如果右子树存在，入队 if tnode.right: que.append(tnode.right) # 将开头出队的左右子树换位 a=tnode.right tnode.right=tnode.left tnode.left=a return root #关键在于，队列初始化、出入队操作，以及存在才入队。 二、相同树 给你两棵二叉树的根节点 p 和 q ，编写一个函数来检验这两棵树是否相同。\n如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def isSameTree(self, p: Optional[TreeNode], q: Optional[TreeNode]) -\u0026gt; bool: p_ls=[p] q_ls=[q] while(p_ls): p_n=p_ls.pop(0) q_n=q_ls.pop(0) if (p_n is None and q_n is not None or q_n is None and p_n is not None): return False if p_n and q_n: if p_n.val!=q_n.val: return False p_ls.append(p_n.left) p_ls.append(p_n.right) q_ls.append(q_n.left) q_ls.append(q_n.right) return True 三、层序遍历并标序（自定义）（通解性） 此题为自定义的，具有通解性质，可暴力解决很多题目。\n给你一个二叉树的根节点 root ，一层一层地打印并标明位置，包括空结点。\n关键是通过上层序号，向左子树走+0，向右子树走+1\n打印类似：\n(root,0)\n(left,0) (right,1)\n(left_left,0) (left_right,1) (none,2) (right_right,3)\n(?,0) (?,1) (?,2) (?,3) (?,6) (?,7)\n1 2 3 4 5 6 7 8 9 10 11 12 # 在 104. 二叉树的最大深度 测试的 class Solution: def maxDepth(self, root: Optional[TreeNode]) -\u0026gt; int: que=[(root,0)] while que: for _ in range(len(que)): tnode, pos=que.pop(0) print(f\u0026#34;{tnode.val if tnode else None},{pos}\\t\u0026#34;, end=\u0026#39;\u0026#39;) if tnode: que.append((tnode.left,pos*2)) que.append((tnode.right,pos*2+1)) print() 四、对称树 给你一个二叉树的根节点 root ， 检查它是否轴对称。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # 暴力标出行点位 # 变量说明 # q: que 队列\tcnt: 记录某层存在的结点的个数\tn_lay: 当前层总位置数，即2^k个，k=0,1,2... # n: 当前层未分析的结点个数，初始为cnt，然后-1-1-1... # cp_cnt: 记录当前层的结点总个数，初始和n一样，只不过不会变化 # stack: 栈，进栈一半结点后，开始分析对称性时，通过出栈互消除 class Solution: def isSymmetric(self, root: Optional[TreeNode]) -\u0026gt; bool: if not root: return True q=[(root,0)]\t# 队列 cnt=1 # 初始化第一层要分析的结点数 n_lay=1 # 当前层的位置总个数 while(q): n=cnt # 该层 还要 分析结点数，不停地减一 cp_cnt=cnt # 该层 结点总数 cnt=0 # 清零保存下层结点数 stack=[] # 遍历当前层 while (n): tnode=q.pop(0) if n\u0026lt;=cp_cnt/2: # 出栈 pop_node=stack.pop(-1) # 都是真，核对位置和值 if tnode[0] and pop_node[0]: if tnode[0].val!=pop_node[0].val: print(\u0026#39;A\u0026#39;) return False if (tnode[1]+pop_node[1])!=n_lay-1: print(\u0026#39;B\u0026#39;) return False # 排除了都是真，但不都None，则必为一真一None elif tnode[0] or pop_node[0]: print(\u0026#39;C\u0026#39;) return False else: # 都是None，核对位置 if (tnode[1]+pop_node[1])!=n_lay-1: print(\u0026#39;D\u0026#39;) return False # 都是None则已经出栈完成互消 else: stack.append(tnode) if tnode[0]: q.append((tnode[0].left,tnode[1]*2+0)) q.append((tnode[0].right,tnode[1]*2+1)) cnt+=2 n-=1 n_lay*=2 return True 1 2 3 4 5 6 7 8 9 # 递归 class Solution: def isSymmetric(self, root: Optional[TreeNode]) -\u0026gt; bool: def recur(L, R): if not L and not R: return True if not L or not R or L.val != R.val: return False return recur(L.left, R.right) and recur(L.right, R.left) return not root or recur(root.left, root.right) 五、二叉树的最大深度 104. 二叉树的最大深度 - 力扣（LeetCode）\n给定一个二叉树 root ，返回其最大深度。\n二叉树的 最大深度 是指从根节点到最远叶子节点的最长路径上的节点数。\n两种思路：自顶向下 和 自底向上\n自顶向下：顶层为1，向下加一并取最大返回 1 2 3 4 5 6 7 8 9 10 # 自顶向下 class Solution: def recur(self,tnode:Optional[TreeNode],dep:int)-\u0026gt;int: if not tnode: return dep-1 else: return max(self.recur(tnode.left, dep+1), self.recur(tnode.right, dep+1)) def maxDepth(self, root: Optional[TreeNode]) -\u0026gt; int: return self.recur(root,1) 自底向上：最底空结点为0，一直向上加，太惊艳了 “我在网上看到一种理解递归的说法：「在写递归函数时，可以假设递归返回的结果一定是正确的」。其实这种说法本质上就是数学归纳法。”——作者\n代码中 max(l_depth, r_depth) + 1 就是假设l_depth 和 r_depth是正确的，然后本层则为 max(l_depth, r_depth) + 1\n​\tif root is None: ​ return 0 ​ l_depth = self.maxDepth(root.left) ​ r_depth = self.maxDepth(root.right) 则保证了初始状况也是正确的，刚才的假设便成立，就能得到正确结果。\nhttps://leetcode.cn/problems/maximum-depth-of-binary-tree/solutions/2010612/kan-wan-zhe-ge-shi-pin-rang-ni-dui-di-gu-44uz/\n1 2 3 4 5 6 # 自底向上 class Solution: def maxDepth(self, root: Optional[TreeNode]) -\u0026gt; int: if not root: return 0 return max(self.maxDepth(root.left),self.maxDepth(root.right))+1 六、二叉树的最小深度 给定一个二叉树，找出其最小深度。\n最小深度是从根节点到最近叶子节点的最短路径上的节点数量。\n说明：叶子节点是指没有子节点的节点。\n111. 二叉树的最小深度 - 力扣（LeetCode）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def minDepth(self, root: Optional[TreeNode]) -\u0026gt; int: if not root: return 0 # root此时必为True return self.recur(root) def recur(self, root: Optional[TreeNode]) -\u0026gt; int: # 俩子节点都为False if not (root.left or root.right): return 1 # 俩子节点都为True elif root.left and root.right: return min(self.recur(root.left),self.recur(root.right))+1 # 1 True 1 False else: return self.recur(root.left)+1 if root.left else self.recur(root.right)+1 七、路径总和 给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。\n叶子节点 是指没有子节点的节点。\n112. 路径总和 - 力扣（LeetCode）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def hasPathSum(self, root: Optional[TreeNode], targetSum: int) -\u0026gt; bool: if not root:return False def dfs(node, target, s): if not node:return False s+=node.val if not node.left and not node.right: if s==target: return True else: return False return dfs(node.left, target, s) or dfs(node.right, target, s) return dfs(root, targetSum, 0) 八、二叉树层序遍历无标序号 给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访问所有节点）。\n“三、层序遍历并标序”的简单版。\n102. 二叉树的层序遍历 - 力扣（LeetCode）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def levelOrder(self, root: Optional[TreeNode]) -\u0026gt; List[List[int]]: # 保证root有val if not root: return [] q=[root] nodes=[] # 全部遍历（相对层内而言） while(q): tmp=[] # 层内遍历 for _ in range(len(q)): tnode=q.pop(0) tmp.append(tnode.val) if(tnode.left): q.append(tnode.left) if(tnode.right): q.append(tnode.right) nodes.append(tmp) return nodes 九、岛屿的周长 岛屿的周长\n给定一个 row x col 的二维网格地图 grid ，其中：grid[i][j] = 1 表示陆地， grid[i][j] = 0 表示水域。\n网格中的格子 水平和垂直 方向相连（对角线方向不相连）。整个网格被水完全包围，但其中恰好有一个岛屿（或者说，一个或多个表示陆地的格子相连组成的岛屿）。\n岛屿中没有“湖”（“湖” 指水域在岛屿内部且不和岛屿周围的水相连）。格子是边长为 1 的正方形。网格为长方形，且宽度和高度均不超过 100 。计算这个岛屿的周长。\n1 2 3 输入：grid = [[0,1,0,0],[1,1,1,0],[0,1,0,0],[1,1,0,0]] 输出：16 解释：它的周长是上面图片中的 16 个黄色的边 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 不用检查每个土格四周是否也是土格子，因为a格子右边是b格子， # 则b格子左边必然是a格子，只需检查每个格子的左上即可 class Solution: def islandPerimeter(self, grid: List[List[int]]) -\u0026gt; int: # 定义行数、列数和周长 row=len(grid) col=len(grid[0]) sum=0 # row_ls: row list\te: element for i,row_ls in enumerate(grid): for j,e in enumerate(row_ls): # 如果是地 if e: sum+=4 # 检查左方格是否为土，首先排除向左超边界 if j!=0 and grid[i][j-1]: sum-=2 # 检查上方格是否为土，首先排除向上超边界 if i!=0 and grid[i-1][j]: sum-=2 return sum 十、左叶子之和 404. 左叶子之和 - 力扣（LeetCode）\n给定二叉树的根节点 root ，返回所有左叶子之和。\n1 2 3 输入: root = [3,9,20,null,null,15,7] 输出: 24 解释: 在这个二叉树中，有两个左叶子，分别是 9 和 15，所以返回 24 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def sumOfLeftLeaves(self, root: Optional[TreeNode]) -\u0026gt; int: if not root: return 0 l_c=root.left r_c=root.right l_cnt=r_cnt=0 if l_c: if not l_c.left and not l_c.right: l_cnt+=l_c.val else: l_cnt=self.sumOfLeftLeaves(l_c) # 右孩子非空且非叶子结点 if r_c and r_c.left or r_c.right: r_cnt=self.sumOfLeftLeaves(r_c) return l_cnt+r_cnt 十一、二叉搜索树的最小绝对差 530. 二叉搜索树的最小绝对差 - 力扣（LeetCode）\n给你一个二叉搜索树的根节点 root ，返回 树中任意两不同节点值之间的最小差值 。\n差值是一个正数，其数值等于两值之差的绝对值。\nWhat I learn:\n类里的全局变量——类属性（见 十九 ，嵌套函数里声明外部变量 nonelocal） 调用类的属性、方法都要“self.” “self.” “self.” !!! 二叉搜索树 \u0026mdash; 中序遍历可得由小到大的序列，其他题见 二十三、二叉搜索树中的众数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def __init__(self): self.dif=inf self.pre=-inf def getMinimumDifference(self, root: Optional[TreeNode]) -\u0026gt; int: if root.left: self.getMinimumDifference(root.left) self.dif=min(self.dif, root.val-self.pre) self.pre=root.val if root.right: self.getMinimumDifference(root.right) return self.dif 十二、二叉树层序遍历II 107. 二叉树的层序遍历 II - 力扣（LeetCode）\n给你二叉树的根节点 root ，返回其节点值 自底向上的层序遍历 。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def levelOrderBottom(self, root: Optional[TreeNode]) -\u0026gt; List[List[int]]: if not root: return [] q=[root] nodes=[] while(q): tmp=[] for _ in range(len(q)): tnode=q.pop(0) tmp.append(tnode.val) if tnode.left: q.append(tnode.left) if tnode.right: q.append(tnode.right) nodes.append(tmp) return nodes[::-1] 十三、合并二叉树 617. 合并二叉树 - 力扣（LeetCode）\n**递归：1. 假定往下传一些参数，他能返回理想值，2. 当前层，接收了上层参数，确保能返回理想值。**具体看代码注释，关键是 “处理好当前层内容，正确返回上层”\n给你两棵二叉树： root1 和 root2 。\n想象一下，当你将其中一棵覆盖到另一棵之上时，两棵树上的一些节点将会重叠（而另一些不会）。你需要将这两棵树合并成一棵新二叉树。合并的规则是：如果两个节点重叠，那么将这两个节点的值相加作为合并后节点的新值；否则，不为 null 的节点将直接作为新二叉树的节点。\n返回合并后的二叉树。\n注意: 合并过程必须从两个树的根节点开始。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution: def mergeTrees(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -\u0026gt; Optional[TreeNode]: # ===== 当前层，接收了上层参数，确保能返回理想值 ===== # 都为空传回空 if root1 is None and root2 is None: return None # 否则必有一个非空 # 一个非空传回 非空那个 if root1 is None: return root2 if root2 is None: return root1 # 否则必然都非空 # 都非空，不return，加和当前结点值，继续往下执行 root1.val+=root2.val # ===== 假定往下传一些参数，他能返回理想值 ===== root1.left=self.mergeTrees(root1.left,root2.left) root1.right=self.mergeTrees(root1.right,root2.right) return root1 十四、二叉树的层平均值 637. 二叉树的层平均值 - 力扣（LeetCode）\n给定一个非空二叉树的根节点 root , 以数组的形式返回每一层节点的平均值。与实际答案相差 10-5 以内的答案可以被接受。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution: def averageOfLevels(self, root: Optional[TreeNode]) -\u0026gt; List[float]: if not root: return [] q=[root] ave=[] while(q): tmp=0.0\t#当前层的和 q_len=len(q)\t# 当前层长度 for _ in range(q_len): tnode=q.pop(0) tmp+=tnode.val if tnode.left: q.append(tnode.left) if tnode.right: q.append(tnode.right) ave.append(tmp/q_len) return ave 十五、找出克隆二叉树中的相同节点 1379. 找出克隆二叉树中的相同节点 - 力扣（LeetCode）\n给你两棵二叉树，原始树 original 和克隆树 cloned，以及一个位于原始树 original 中的目标节点 target。\n其中，克隆树 cloned 是原始树 original 的一个 副本 。\n请找出在树 cloned 中，与 target 相同 的节点，并返回对该节点的引用（在 C/C++ 等有指针的语言中返回 节点指针，其他语言返回节点本身）。\nWhat I have leaned:\n声明全局变量 未必比 传形参要好，因为python都是传引用，除非对其修改 才可能 创建副本 TreeNode可以直接进行比较，实际比较的是 物理内存地址（指针），target和original指到同一处时，original is target才为True，cloned is target永远为False 1 2 3 4 5 6 7 8 class Solution: def getTargetCopy(self, original: TreeNode, cloned: TreeNode, target: TreeNode) -\u0026gt; TreeNode: if original is None or original is target: return cloned return self.getTargetCopy(original.left, cloned.left, target) or \\ self.getTargetCopy(original.right, cloned.right, target) 作者：灵茶山艾府 十六、图像渲染 733. 图像渲染 - 力扣（LeetCode）\n有一幅以 m x n 的二维整数数组表示的图画 image ，其中 image[i][j] 表示该图画的像素值大小。你也被给予三个整数 sr , sc 和 color 。你应该从像素 image[sr][sc] 开始对图像进行上色 填充 。\n为了完成 上色工作：\n从初始像素开始，将其颜色改为 color。 对初始坐标的 上下左右四个方向上 相邻且与初始像素的原始颜色同色的像素点执行相同操作。 通过检查与初始像素的原始颜色相同的相邻像素并修改其颜色来继续 重复 此过程。 当 没有 其它原始颜色的相邻像素时 停止 操作。 最后返回经过上色渲染 修改 后的图像 。\nwhat you learn:\n初始像素与目标颜色相同。不会对图像进行任何更改。 找一种中序遍历的感觉 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Solution: def floodFill(self, image: List[List[int]], sr: int, sc: int, color: int) -\u0026gt; List[List[int]]: q=[(sr,sc)] r_len=len(image) c_len=len(image[0]) # original color ori_c=image[sr][sc] if ori_c==color: return image while(q): # element e=q.pop(0) # current block\u0026#39;s color image[e[0]][e[1]]=color # 上:行不为0 if e[0] and image[e[0]-1][e[1]] == ori_c: q.append((e[0]-1, e[1])) # 左：列不为0 if e[1] and image[e[0]][e[1]-1] == ori_c: q.append((e[0], e[1]-1)) # 下：行不为r_len-1 if e[0]!=r_len-1 and image[e[0]+1][e[1]] == ori_c: q.append((e[0]+1, e[1])) # 右：列不为c_len-1 if e[1]!=c_len-1 and image[e[0]][e[1]+1] == ori_c: q.append((e[0], e[1]+1)) return image 十七、N 叉树的最大深度 559. N 叉树的最大深度 - 力扣（LeetCode）\n给定一个 N 叉树，找到其最大深度。\n最大深度是指从根节点到最远叶子节点的最长路径上的节点总数。\nWhat I learn:\n不要掉入惯性思维的坑，仔细看它定义的类（结构体）是怎样的，此题没有空结点（对比 二叉树最大深度 的 定义，它不是子树结点为None而是存子树的list为None，因此，无法实现 “当前结点为None”这种做法。 这就引出在递归结尾处的两种处理，一种是“如果子树不为空，才进入递归函数”，另一种是“子树结点传进递归函数，函数开头判断是否为空”，我称前者为“预判处理”，后者为“当前层处理”。二者看情况用，通常用“当前层处理”，但这里不行，因为没有 空结点。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026#34;\u0026#34;\u0026#34; # Definition for a Node. class Node: def __init__(self, val: Optional[int] = None, children: Optional[List[\u0026#39;Node\u0026#39;]] = None): self.val = val self.children = children \u0026#34;\u0026#34;\u0026#34; class Solution: def maxDepth(self, root: \u0026#39;Node\u0026#39;) -\u0026gt; int: if not root: # 注意函数返回值限制为int类型 return 0 # 注意不是从空结点层向上返回的，故不是从0开始 return \\ max([self.maxDepth(node) for node in root.children])+1 \\ if root.children else 1 十八、单值二叉树 965. 单值二叉树 - 力扣（LeetCode）\n如果二叉树每个节点都具有相同的值，那么该二叉树就是单值二叉树。\n只有给定的树是单值二叉树时，才返回 true；否则返回 false。\nWhat I learn:\n方法里定义的临时变量（代码里的 v ），对于方法里的函数（哪怕递归了）是全局的。\n—— 当dfs被定义为嵌套函数时，它可以访问外部函数isUnivalTree中的变量v（闭包机制）\n—— 如果将dfs改为实例方法（如self.dfs），不能访问外部函数的变量v\n—— 还要看是访问的变量类型，不可变类型：可读，要写需nonlocal；\n​\t可变类型：可读可写\n如果有多个、多重if else，看看能不能用 or and 代替\n定义参数时不要和外边变量重名，如：def dfs(node): 而非 def dfs(root):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def isUnivalTree(self, root: TreeNode) -\u0026gt; bool: # 变量v对于dfs是全局的 v = root.val def dfs(node): return node is None or \\ (node.val == v and dfs(node.left) and dfs(node.right)) return dfs(root) 作者：Benhao \u0026#39;\u0026#39;\u0026#39; return node is None or \\ (node.val == v and dfs(node.left) and dfs(node.right)) ===== 等价于 ===== if not root: return True if root.val==self.n: return self.recur(root.left) and self.recur(root.right) else: return False \u0026#39;\u0026#39;\u0026#39; 十九、二叉树的堂兄弟节点 993. 二叉树的堂兄弟节点 - 力扣（LeetCode）\n在二叉树中，两个节点深度相同，但 父节点不同 ，则它们是一对堂兄弟节点。\n我们给出了具有唯一值的二叉树的根节点 root ，以及树中两个不同节点的值 x 和 y 。\n只有与值 x 和 y 对应的节点是堂兄弟节点时，才返回 true 。否则，返回 false。\nWhat I learn:\n当你想得清楚当前层的处理时，发现要上层数据，想想能不能传递上层数据下去\n嵌套函数 对 外部作用域变量的访问 的关键区别：读取和修改。\n只要函数内部存在对不可变类型变量 pre_dep 的 修改（如 pre_dep = dep），Python 默认将其视为 局部变量。\n仅读取，则会视为外部变量（见 十八 的 v）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 当你想得清楚当前层的处理时，发现要上层数据，想想能不能传递上层数据下去 class Solution: def isCousins(self, root: Optional[TreeNode], x: int, y: int) -\u0026gt; bool: if root.val==x or root.val==y: return False pre_dep=0 pre_par=None def recur(root, dep, par): nonlocal pre_dep, pre_par if not root: return False # 如果有一个值对上了，说明遇上了一个结点 if root.val==x or root.val==y: # 如果pre_dep不为0，前者已找到，必须深度一样且父节点不同 if pre_dep: return dep==pre_dep and par is not pre_par else: pre_dep=dep pre_par=par return recur(root.left, dep+1, root) or\\ recur(root.right, dep+1, root) return recur(root.left, 1, root) or \\ recur(root.right, 1, root) 二十、寻找图中是否存在路径 1971. 寻找图中是否存在路径 - 力扣（LeetCode）\n有一个具有 n 个顶点的 双向 图，其中每个顶点标记从 0 到 n - 1（包含 0 和 n - 1）。图中的边用一个二维整数数组 edges 表示，其中 edges[i] = [ui, vi] 表示顶点 ui 和顶点 vi 之间的双向边。 每个顶点对由 最多一条 边连接，并且没有顶点存在与自身相连的边。\n请你确定是否存在从顶点 source 开始，到顶点 destination 结束的 有效路径 。\n存在 有效路径 ，则返回 true，否则返回 false 。\n1 2 输入：n = 3, edges = [[0,1],[1,2],[2,0]], source = 0, destination = 2 输出：true What I learn:\ndefaultdict(list)将“边数据”转为“点数据”，复杂度由 n^2 变 n，边=n(n-1)/2=n^2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution: def validPath(self, n: int, edges: List[List[int]], source: int, destination: int) -\u0026gt; bool: def dfs(i): if i == destination: return True vis.add(i) for j in g[i]: if j not in vis and dfs(j): return True return False g = defaultdict(list) for a, b in edges: g[a].append(b) g[b].append(a) vis = set() return dfs(source) 作者：ylb 二十一、另一棵树的子树 572. 另一棵树的子树 - 力扣（LeetCode）\n给你两棵二叉树 root 和 subRoot 。检验 root 中是否包含和 subRoot 具有相同结构和节点值的子树。如果存在，返回 true ；否则，返回 false 。\n二叉树 tree 的一棵子树包括 tree 的某个节点和这个节点的所有后代节点。tree 也可以看做它自身的一棵子树。\nWhat I learn:\n探索必要条件：如果是子树，那就有相同树，则二者深度必然相等，也就是深度相等的结点才需判断是不是相同树。 此必要条件能大幅减小复杂度。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def isSubtree(self, root: Optional[TreeNode], subRoot: Optional[TreeNode]) -\u0026gt; bool: # 检查是否为相同树\tdef check(node1,node2): if node1 is None and node2 is None: return True elif node1 and node2: if node1.val==node2.val: return check(node1.left, node2.left) and check(node1.right, node2.right) return False # 排除根节点为空的情况 if not subRoot: return True elif not root: return False # 计算子树深度 def cal_sub(node): if not node: return 0 return max(cal_sub(node.left),cal_sub(node.right))+1 sub_dep=cal_sub(subRoot) # 子树根节点值 sub_v=subRoot.val # 遍历树，深度相同 且 值相同 时检查 def dfs(node)-\u0026gt;(int, bool): if not node: return 0, False l_dep, l_issub = dfs(node.left) r_dep, r_issub = dfs(node.right) dep=max(l_dep,r_dep)+1 if l_issub or r_issub: return 0, True if dep==sub_dep and node.val==sub_v: if check(node,subRoot): return 0, True return dep, False return dfs(root)[1] 二十二、二叉树中第二小的节点 671. 二叉树中第二小的节点 - 力扣（LeetCode）\n给定一个非空特殊的二叉树，每个节点都是正数，并且每个节点的子节点数量只能为 2 或 0。如果一个节点有两个子节点的话，那么该节点的值等于两个子节点中较小的一个。\n更正式地说，即 root.val = min(root.left.val, root.right.val) 总成立。\n给出这样的一个二叉树，你需要输出所有节点中的 第二小的值 。\n如果第二小的值不存在的话，输出 -1 。\n1 2 3 输入：root = [2,2,5,null,null,5,7] 输出：5 解释：最小的值是 2 ，第二小的值是 5 。 What I learn\n假设递归终点正确返回，处理中间过程：\n我们知道root.val是最小值，那么\n第二小的值为 较小的子节点那一边的子树的第二小的值 或 更大的子节点 之中\n即min(get_sec_min(较小结点), 较大结点.val)\n因为当前层是考虑了子节点的，所以是“预判式递归”\n处理末尾情况，使“数学归纳法”成立：\n“预判式递归”考虑倒数两层，1. 最底一层因为有空叶子而需要特殊处理。2. 倒数第二层（中间过程）要看看最底一层的返回是否兼容（即min(get_sec_min(较小结点), 较大结点.val)是否合理）\n这里就是：\n​\tchild有返回-1时要取max，或者\n新写一个函数，叶子返回inf，外部再处理返回inf的情况。\n“限制性递归”就不是每个子节点都进入，需要“预判处理”，见 [十七、N叉树的最大深度](#十七N 叉树的最大深度)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: # 会从沿着值为root.val的路线往下走，总共考虑 是/否为叶子、较大/较小子树方向 # 如果当前是值为root.val的叶子返回-1，如果当前是值为不为root.val的叶子的情况不存在 def findSecondMinimumValue(self, root: TreeNode) -\u0026gt; int: # 必然不存在第二小的值 if not root or not root.left: return -1 # 我们知道root.val是最小值，那么 # 第二小的值存在于 更小的子节点那一边的子树的第二小的值 或 更大的子节点 之中 left = root.left.val if root.left.val != root.val \\ else self.findSecondMinimumValue(root.left) right = root.right.val if root.right.val != root.val \\ else self.findSecondMinimumValue(root.right) return min(left, right) if left != -1 and right != -1 else max(left, right) 二十三、二叉搜索树中的众数 501. 二叉搜索树中的众数 - 力扣（LeetCode）\n给你一个含重复值的二叉搜索树（BST）的根节点 root ，找出并返回 BST 中的所有 众数（即，出现频率最高的元素）。\n如果树中有不止一个众数，可以按 任意顺序 返回。\n假定 BST 满足如下定义：\n结点左子树中所含节点的值 小于等于 当前节点的值 结点右子树中所含节点的值 大于等于 当前节点的值 左子树和右子树都是二叉搜索树 What the hell did I learn:\n二叉搜索树 \u0026mdash; 中序遍历可得由小到大的序列，相当于将树拍平在数轴上，\n如 1, 2, 2, 4, 6, 6, 9，递归每层相当于指针指到某处\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right # 左-\u0026gt;当前-\u0026gt;右 # v=[] v_n=0 n_max=0 pre=前一结点值，初始inf则都不相等 class Solution: def findMode(self, root: Optional[TreeNode]) -\u0026gt; List[int]: pre=inf v=[] v_n=0 n_max=0 def dfs(node): if not node: return dfs(node.left) nonlocal v_n, pre, n_max # 与前一值的关系，等则累加，不等则置1 if node.val!=pre: pre=node.val v_n = 1 else: v_n += 1 # 个数情况，小于最大值不处理 if v_n\u0026lt;n_max: None elif v_n==n_max: v.append(node.val) else: n_max=v_n v.clear() v.append(node.val) dfs(node.right) dfs(root) return v 二十四、表格里单词搜索 79. 单词搜索 - 力扣（LeetCode）\n给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。\n单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。\n1 2 输入：board = [[\u0026#34;A\u0026#34;,\u0026#34;B\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;E\u0026#34;],[\u0026#34;S\u0026#34;,\u0026#34;F\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;S\u0026#34;],[\u0026#34;A\u0026#34;,\u0026#34;D\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;E\u0026#34;]], word = \u0026#34;ABCCED\u0026#34; 输出：true What I learn:\n变量作用域和函数传参总结：\n函数传参传 指针/别名，一定是。 对于外部不可修改变量： 若传参了 函数内若修改变量，复制生成局部变量，不影响外部变量，读取读局部变量。 函数内若只读取变量，不生成局部变量，指针方式读。 若没传参 函数内若修改变量，报错不存在该局部变量。 函数内若只读取变量，自动指针方式读外部变量。 对于外部可修改变量： 无论传没传参，修不修改，一律别名方式读取或修改外部变量。 树型标表示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 graph TD A[外部变量] --\u0026gt; B[不可修改变量] A --\u0026gt; C[可修改变量] B --\u0026gt; D[传参] B --\u0026gt; E[不传参] D --\u0026gt; F[（函数内）修改变量] D --\u0026gt; G[只读变量] F --\u0026gt; F1[复制生成局部变量] G --\u0026gt; G1[指针方式读外部变量] E --\u0026gt; H[函数内修改变量] E --\u0026gt; I[函数内只读变量] H --\u0026gt; H1[报错：不存在该局部变量] I --\u0026gt; I1[指针方式读外部变量] C --\u0026gt; J[无论传参与否] J --\u0026gt; K[无论修改与否] K --\u0026gt; L[别名方式读取或修改外部变量] 不可改-传参-修改-复制生成局部变量 不可改-传参-只读-指针方式读 不可改-不传参-修改-报错 不可改-不传参-只读-指针方式读 可改 - 传参/不传参 - 修改/不修改 - 别名方式 遍历各方向 并 进入各方向的递归函数：\n1 2 3 4 # 相邻格子 for x, y in (i, j - 1), (i, j + 1), (i - 1, j), (i + 1, j): if 0 \u0026lt;= x \u0026lt; m and 0 \u0026lt;= y \u0026lt; n and dfs(x, y, k + 1): return True 注意这题里 由于访问可修改变量，一定是别名访问，需要“恢复现场”，即回溯\nany 是否存在True all 是否都为True\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution: def exist(self, board: List[List[str]], word: str) -\u0026gt; bool: m, n = len(board), len(board[0]) def dfs(i: int, j: int, k: int) -\u0026gt; bool: if board[i][j] != word[k]: # 匹配失败 return False if k == len(word) - 1: # 匹配成功！ return True board[i][j] = \u0026#39;\u0026#39; # 标记访问过 for x, y in (i, j - 1), (i, j + 1), (i - 1, j), (i + 1, j): # 相邻格子 if 0 \u0026lt;= x \u0026lt; m and 0 \u0026lt;= y \u0026lt; n and dfs(x, y, k + 1): return True # 搜到了！ board[i][j] = word[k] # 恢复现场 return False # 没搜到 return any(dfs(i, j, 0) for i in range(m) for j in range(n)) 作者：灵茶山艾府 二十五、二叉树化单链表 面试题 17.12. BiNode - 力扣（LeetCode）\n二叉树数据结构TreeNode可用来表示单向链表（其中left置空，right为下一个链表节点）。实现一个方法，把二叉搜索树转换为单向链表，要求依然符合二叉搜索树的性质，转换操作应是原址的，也就是在原始的二叉搜索树上直接修改。\n返回转换后的单向链表的头节点。\nWhat I learn:\n创建单链表思想：设置头结点，pre初始=头结点，创建当前结点，pre内指针 指向 当前结点，pre=当前结点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def convertBiNode(self, root: Optional[TreeNode]) -\u0026gt; Optional[TreeNode]: ini_node=TreeNode() pre=ini_node def dfs(node): if not node: return dfs(node.left) nonlocal pre pre.right=node node.left=None pre=node dfs(node.right) dfs(root) return ini_node.right 二十六、找到所有的农场组 1992. 找到所有的农场组 - 力扣（LeetCode）\n给你一个下标从 0 开始，大小为 m x n 的二进制矩阵 land ，其中 0 表示一单位的森林土地，1 表示一单位的农场土地。\n为了让农场保持有序，农场土地之间以矩形的 农场组 的形式存在。每一个农场组都 仅 包含农场土地。且题目保证不会有两个农场组相邻，也就是说一个农场组中的任何一块土地都 不会 与另一个农场组的任何一块土地在四个方向上相邻。\nland 可以用坐标系统表示，其中 land 左上角坐标为 (0, 0) ，右下角坐标为 (m-1, n-1) 。请你找到所有 农场组 最左上角和最右下角的坐标。一个左上角坐标为 (r1, c1) 且右下角坐标为 (r2, c2) 的 农场组 用长度为 4 的数组 [r1, c1, r2, c2] 表示。\n请你返回一个二维数组，它包含若干个长度为 4 的子数组，每个子数组表示 land 中的一个 农场组 。如果没有任何农场组，请你返回一个空数组。可以以 任意顺序 返回所有农场组。\n1 2 输入：land = [[1,0,0],[0,1,1],[0,1,1]] 输出：[[0,0,0,0],[1,1,2,2]] what I learn:\n试探性 行为\u0026quot;x1+1\u0026quot; \u0026ldquo;y1+1\u0026rdquo;,不满足则x1 y1抵达边界 多变量时，分清楚“域内变量”是什么？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution: def findFarmland(self, land: List[List[int]]) -\u0026gt; List[List[int]]: result=[] m=len(land) n=len(land[0]) # 检测从此出发的矩形有多大 def check(x0,y0,x1,y1): # 试探性 行为\u0026#34;x1+1\u0026#34; \u0026#34;y1+1\u0026#34;,不满足则x1 y1抵达边界 while(x1+1\u0026lt;m and land[x1+1][y1]): x1+=1 while(y1+1\u0026lt;n and land[x1][y1+1]): y1+=1 for i in range(x0,x1+1): for j in range(y0,y1+1): land[i][j]=0 return (x0,y0,x1,y1) # 遍历所有点 for i in range(m): for j in range(n): if land[i][j]==1: result.append(check(i,j,i,j)) return result 二十七、路径总和 II 113. 路径总和 II - 力扣（LeetCode）\n给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子节点 路径总和等于给定目标和的路径。\n叶子节点 是指没有子节点的节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def pathSum(self, root: Optional[TreeNode], targetSum: int) -\u0026gt; List[List[int]]: result=[] def dfs(node,Sum,targetSum,route): if not node: return route.append(node.val) Sum+=node.val if Sum==targetSum and node.left is None and node.right is None: result.append(deepcopy(route)) dfs(node.left,Sum,targetSum,route) dfs(node.right,Sum,targetSum,route) route.pop(-1) dfs(root,0,targetSum,[]) return result what I learn:\npython里的 可修改变量 和 不可修改变量 的赋值，可修改-创建新变量，不可修改-别名 1 2 3 4 5 6 7 8 9 ls=[1,2,3] cp=ls cp.append(4) print(ls) # [1,2,3,4] a=1 cp=a cp=2 print(a) # 1 copy.deepcopy实现 不可修改变量的 “创建变量赋值” 1 2 3 4 5 ls=[1,2,3] import copy cp=copy.deepcopy(ls) cp.append(4) print(ls) # [1,2,3,4] 二十八、二叉树展开为链表 114. 二叉树展开为链表 - 力扣（LeetCode）\n给你二叉树的根结点 root ，请你将它展开为一个单链表：\n展开后的单链表应该同样使用 TreeNode ，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null 。 展开后的单链表应该与二叉树 先序遍历 顺序相同。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def flatten(self, root: Optional[TreeNode]) -\u0026gt; None: # 尾插法 # ini_node=TreeNode() # pre=ini_node # def dfs(node): # if not node: # return # nonlocal pre # pre.right=node # lc, rc=node.left, node.right # node.left=None # pre=node # dfs(lc) # dfs(rc) # dfs(root) # 头插法 ini_node=TreeNode() def dfs(node): if not node: return dfs(node.right) dfs(node.left) nonlocal ini_node node.right=ini_node.right ini_node.right=node node.left=None dfs(root) what I learn:\n二叉树先序、中序、后续遍历转二叉树总结：中序-尾插法-LCR处理，后序-尾插法-LRC处理，先序-头插法-RLC处理\n原理：确保 pre的右子树的处理 不会影响后续结点的访问，确保 cur的左子树的处理 不会影响后续结点的访问。\nL(进入left-child) C(处理current) R(进入right-child)\n中序-尾插法-LCR，即搜索二叉树遍历。 1 2 3 4 5 dfs(node.left) pre.right=node node.left=None pre=node dfs(node.right) 后序-尾插法-LRC 1 2 3 4 5 dfs(node.left) dfs(node.right) pre.right=node node.left=None pre=node 先序-头插法-RLC 头插法实现将CLR转换为RLC，类后序，当前层处理不会影响后续 向父节点的 访问。 1 2 3 4 5 dfs(node.right) dfs(node.left) node.right=head.right head.right=node node.left=None ","date":"2025-04-26T00:00:00Z","permalink":"https://rooobeam.github.io/p/tree_search/","title":"Tree_search"},{"content":" 图片链接生成图片并控制大小 1 \u0026lt;img src=\u0026#34;https://assets.leetcode.com/uploads/2021/07/27/screenshot-2021-07-27-at-12-23-15-copy-of-diagram-drawio-diagrams-net.png?\u0026#34; style=\u0026#34;zoom:50%;\u0026#34; /\u0026gt; ","date":"2025-04-21T16:46:11+08:00","permalink":"https://rooobeam.github.io/p/typora_tricks/","title":"Typora_tricks"},{"content":"操作系统 1.1_1 操作系统的概念、功能和目标 作为用户和计算机硬件之间的接口\n提供的功能 命令接口 联机命令接口 脱机命令接口 程序接口 GUI（图形用户界面） Windows iOS Android 目标 方便用户使用 1.1_2 操作系统的特征 特征 定义 并发 多个事件交替发生（宏观同时发生、微观交替进行） 并行 多个事件同时发生 共享 两种资源共享方式：\n1. 互斥共享方式（如打印机）\n2. 同时共享方式（如文件） 虚拟 物理实体映射为多个逻辑实体：\n- 空分复用技术（如虚拟内存）\n- 时分复用技术（如CPU分时） 异步 进程执行走走停停，速度不可预知（需并发性支持） 1.1_3 操作系统的发展与分类 发展阶段 手工操作阶段 纸带机（用户独占全机、人机速度矛盾） 批处理阶段 单道批处理系统（外围机→磁带） 多道批处理系统（操作系统出现） 分时操作系统 轮流处理作业 无法处理紧急任务 实时操作系统 硬实时系统（严格时间限制） 软实时系统（允许偶尔犯错） 其他类型 网络操作系统 分布式操作系统 个人计算机操作系统 1.1_4 操作系统的运行机制与体系结构 运行机制 两种指令 特权指令（仅内核态可用） 非特权指令 两种处理器状态 核心态（root权限） 用户态 两种程序 内核程序（运行在核心态） 应用程序 操作系统内核功能 时钟管理 中断处理 原语（原子性操作） 资源管理 进程管理 存储器管理 设备管理 体系结构 类型 特点 大内核 主要功能模块运行在核心态（如Linux） 微内核 仅保留最基本功能（如Windows NT） 1.1_5 中断和异常 中断机制的作用：用户态→核心态的唯一途径 中断分类： 1 2 3 4 5 6 graph LR A[中断] --\u0026gt; B[内中断（异常）] A --\u0026gt; C[外中断] B --\u0026gt; D[陷阱（trap）] B --\u0026gt; E[故障（fault）] B --\u0026gt; F[中止（abort）] 1.1_6 系统调用 概念：应用程序通过系统调用请求OS服务 与库函数的区别： 系统调用 库函数 OS直接提供的接口 可能封装系统调用 需切换到核心态 运行在用户态 2.1_1 进程的定义、组成、组织方式、特征 定义 进程：程序的一次执行过程 组成 PCB（进程存在唯一标志） 程序段 数据段 组织方式 链接方式（队列指针） 索引方式（索引表） 特征 动态性、并发性、独立性、异步性、结构性 2.1_2 进程的状态与转换 进程状态 状态 描述 资源占用情况 运行态 占有CPU并执行指令（单核CPU同一时刻只能有一个进程处于运行态） CPU√，其他资源√ 就绪态 具备运行条件，但无空闲CPU（等待调度） CPU×，其他资源√ 阻塞态 等待某事件（如I/O完成） CPU×，其他资源× 创建态 正在分配PCB、程序段和数据段 - 终止态 资源回收中 - 状态转换 1 2 3 4 5 6 7 8 stateDiagram-v2 [*] --\u0026gt; 创建态 创建态 --\u0026gt; 就绪态 就绪态 --\u0026gt; 运行态 运行态 --\u0026gt; 就绪态: 时间片用完 运行态 --\u0026gt; 阻塞态: 主动等待资源 阻塞态 --\u0026gt; 就绪态: 事件发生 运行态 --\u0026gt; 终止态: 异常终止/完成 2.1_3 进程控制 进程控制 用原语实现进程控制\n原语操作 更新PCB信息 将PCB插入目标队列 资源分配/回收 关键原语 原语类型 触发事件 操作 创建原语 用户登录、作业调度、服务请求 申请空白PCB → 分配资源 → 初始化PCB → 加入就绪队列 终止原语 正常结束、异常终止、外界干预 回收内存 → 撤销PCB 阻塞原语 等待资源/其他进程 运行态 → 阻塞态（主动） 唤醒原语 等待事件发生 阻塞态 → 就绪态（被动） 切换原语 时间片耗尽、高优先级进程到达 保存当前进程上下文 → 恢复目标进程上下文 2.1_4 进程通信 通信方式对比 方式 实现原理 特点 共享存储 分配共享空间，通过PV操作互斥访问 - 基于数据结构（低级）\n- 基于存储区（高级） 消息传递 直接/间接发送消息（含消息头和消息体） - 直接通信：消息挂载到目标进程\n- 间接通信：通过信箱中转 管道通信 半双工通信，遵循“写满才能读”的互斥规则 适用于父子进程通信，容量固定 2.1_5 线程概念与多线程模型 线程 vs 进程 特性 线程 进程 单位 基本CPU执行（调度）单位 资源分配单位（不管系统中是否有线程） 系统开销 切换代价小（同进程内线程共享进程资源） 切换代价大（需保存整个上下文） 并发性 同一进程的线程可并发 进程间并发 通信方式 同进程内 线程 不通过内核 进程间通信 需通过内核 状态 只有三种状态转化：运行、就绪、阻塞 五种：运行、阻塞、就绪、创建、终止 独立运行 不能独立运行，依赖进程 独立 ✅ 一个进程可创建一个或多个线程 进程是资源分配单位，可包含多个执行流（线程） ✅ 一个线程可创建一个或多个线程 线程可派生同级线程（如pthread_create） ❌ 一个线程可创建一个或多个进程 线程共享进程资源，无权直接创建进程（需通过进程级API如fork） ✅ 一个进程可创建一个或多个进程 通过fork/spawn等系统调用实现 线程实现方式 对比维度 用户线程 (User-Level Thread) 内核线程 (Kernel-Level Thread) 组合方式 (Hybrid Model) 实现位置 用户空间 内核空间 用户空间 + 内核空间 OS感知性 内核不可感知 内核直接管理，设置了一个线程控制块（TCB） 用户线程动态绑定内核线程 线程映射模型 多对一（多个用户线程→1个内核线程） 一对一（1用户线程→1内核线程） 多对多（灵活绑定） 创建/销毁开销 ⚡ 极低（无需内核介入） ⚠️ 高（需系统调用） 🔄 中等（用户线程管理+内核线程绑定） 阻塞问题 🚫 单线程阻塞→整个进程阻塞 ✅ 单线程阻塞→可调度同进程其他线程 ✅ 通过内核线程避免完全阻塞 多核并行能力 ❌ 多个同进程用户线程只有一个运行（其实就是不能一个进程在多个cpu上） ✅ 支持多线程并行 ✅ 根据内核线程支持 调度单位 进程级调度 线程级调度 混合调度（用户线程池+内核线程调度） ✅ 若系统中只有用户级线程,则处理机调度单位是进程 用户线程内核不可感知关键问题解析 线程实现模型 1 2 3 4 5 graph LR A[用户级线程 ULT] --\u0026gt;|映射| B[内核级线程 KLT] C[多对一模型] --\u0026gt; D[并发度低] E[一对一模型] --\u0026gt; F[开销大] G[多对多模型] --\u0026gt; H[平衡并发与开销] 2.2_1 处理机调度的概念与层次 三级调度对比 调度层次 操作对象 频率 功能 高级调度 作业（外存→内存） 低 创建PCB，决定作业调入/调出 中级调度 挂起进程（内存↔外存） 中 提高内存利用率，管理挂起队列 低级调度 进程（分配CPU） 高（ms级） 最基本的调度，决定进程执行顺序 挂起状态 就绪挂起：进程在外存，可被调入内存执行 阻塞挂起：进程在外存等待事件 2.2_2 进程调度时机与方式 调度触发条件 场景 能否调度 原因 处理中断过程中 × 内核态不可抢占 内核程序临界区 × 访问就绪队列等关键数据结构 原子操作（原语） × 操作不可分割 进程主动阻塞/终止 √ 主动放弃CPU 时间片耗尽 √ 被动剥夺CPU 调度方式 类型 特点 适用场景 非抢占式 进程主动放弃CPU 批处理系统 抢占式 强制剥夺CPU（响应紧急任务） 实时/分时系统 ","date":"2025-04-05T00:00:00Z","permalink":"https://rooobeam.github.io/p/%E7%8E%8B%E9%81%93%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/","title":"王道操作系统笔记"},{"content":"文件链接：Release v1.0.3 · HKUDS/LightRAG\n主要分初始化、插入、提问三部分\n初始化 插入 插入：rag.insert()异步编程调用ainsert()\nainsert内的各步操作\n文章处理 文本块处理 实体关系抽取 更新各存储区 文章处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ====== 文章处理 ====== # 单个字符串也变成List(str) if isinstance(string_or_strings, str): string_or_strings = [string_or_strings] # {hash(\u0026#34;doc-\u0026#34;+txt_i的字符串):{\u0026#34;content\u0026#34;: txt_i.strip()}}，txt_i是第i个文章 new_docs = { compute_mdhash_id(c.strip(), prefix=\u0026#34;doc-\u0026#34;): {\u0026#34;content\u0026#34;: c.strip()} for c in string_or_strings } \u0026#39;\u0026#39;\u0026#39; n个 hash(\u0026#34;doc-\u0026#34;+txt_i的字符串) 组成的list 传入 self.full_docs.filter_keys self.full_docs.filter_keys 是 JsonKVStorage.filter_keys方法 返回set{str}(以字符串为元素的字典) 作用是：某文章 和历史数据中重复 或 和传入数据中其他文章重复 则排除。 通过比对hash值 \u0026#39;\u0026#39;\u0026#39; _add_doc_keys = await self.full_docs.filter_keys(list(new_docs.keys())) # key在_add_doc_keys里的kv对留下 new_docs = {k: v for k, v in new_docs.items() if k in _add_doc_keys} # 日志登记 if not len(new_docs): logger.warning(\u0026#34;All docs are already in the storage\u0026#34;) return # storage 是 要更新的flag update_storage = True logger.info(f\u0026#34;[New Docs] inserting {len(new_docs)} docs\u0026#34;) 文本块处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 # ====== 文本块处理 ====== # 一次ainsert中的多个文章的chunks字典汇总，ainsert只是事件循环中的一个事件 # {\u0026#34;chunk-\u0026#34;+chunk字符串哈希值: dict, 哈希值: dict,...} inserting_chunks = {} # 外循环 第i篇文章，内循环，第i篇文章第j个chunk for doc_key, doc in \\ tqdm_async(new_docs.items(), desc=\u0026#34;Chunking documents\u0026#34;, unit=\u0026#34;doc\u0026#34;): \u0026#39;\u0026#39;\u0026#39; inserting_chunks = { hash(\u0026#34;chunk-\u0026#34;+chunk_i的字符串): {\u0026#34;tokens\u0026#34;: chunk_i的token数, \u0026#34;content\u0026#34;: chunk_i具体内容, \u0026#34;chunk_order_index\u0026#34;: 是该文章的第i个chunk, \u0026#34;full_doc_id\u0026#34;: doc_key}, hash(\u0026#34;chunk-\u0026#34;+chunk_i+1的字符串): {\u0026#34;tokens\u0026#34;: chunk_i+1的token数, \u0026#34;content\u0026#34;: chunk_i+1具体内容, \u0026#34;chunk_order_index\u0026#34;: 是该文章的第i+1个chunk, \u0026#34;full_doc_id\u0026#34;: doc_key}, } chunks = {哈希值: dict, 哈希值: dict,...} \u0026#39;\u0026#39;\u0026#39; chunks = { # dp是 dict[str, Union[int, str]]，即是个字典，然后键为key，值为Union[int,str]即int 或 str # Union[int,str]具体来说，可以是 该chunk的token数，chunk具体内容，是该文章的第i个chunk # **dp表示解包字典（去掉大括号），并要求\u0026#34;full_doc_id\u0026#34;: doc_key满足dict[str, Union[int, str]] # chunking_by_token_size 根据 token 数量切分文本，返回List[dict]吧 compute_mdhash_id(dp[\u0026#34;content\u0026#34;], prefix=\u0026#34;chunk-\u0026#34;): {**dp, \u0026#34;full_doc_id\u0026#34;: doc_key,} for dp in chunking_by_token_size( doc[\u0026#34;content\u0026#34;], overlap_token_size=self.chunk_overlap_token_size, max_token_size=self.chunk_token_size, tiktoken_model=self.tiktoken_model_name, ) } # dict.update(dict)如果已存在相同的键，则对应的值会被覆盖；如果不存在，则添加新的键值对。 # dict1 = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} # dict2 = {\u0026#39;b\u0026#39;: 3, \u0026#39;c\u0026#39;: 4} # dict1.update(dict2) # print(dict1) # Output: {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 3, \u0026#39;c\u0026#39;: 4} # 因为用了hash内容包括chunk内容，所以不重复 inserting_chunks.update(chunks) \u0026#39;\u0026#39;\u0026#39; n个 hash(\u0026#34;chunk-\u0026#34;+chunk_i的字符串) 组成的list传入self.full_docs.filter_keys self.full_docs.filter_keys 即 JsonKVStorage.filter_keys 返回set{str}(以字符串为元素的字典)，作用是：某chunk 和历史数据中重复或和传入数据中其他chunk重复则排除。 通过比对hash值 \u0026#39;\u0026#39;\u0026#39; _add_chunk_keys = await self.text_chunks.filter_keys( list(inserting_chunks.keys()) ) # 根据key在_add_doc_keys里对inserting_chunks筛选合格的kv对 inserting_chunks = { k: v for k, v in inserting_chunks.items() if k in _add_chunk_keys } # 日志登记 if not len(inserting_chunks): logger.warning(\u0026#34;All chunks are already in the storage\u0026#34;) return logger.info(f\u0026#34;[New Chunks] inserting {len(inserting_chunks)} chunks\u0026#34;) # 将inserting_chunks(字典)存入json await self.chunks_vdb.upsert(inserting_chunks) 实体关系抽取 分为 外部 和 extract_entities函数内部\n外部 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ====== 实体抽取 ====== logger.info(\u0026#34;[Entity Extraction]...\u0026#34;) # asdict来自“from dataclasses import asdict“，能构建Lightrag类的属性字典 # maybe_new_kg为更新过后的knowledge_graph_inst，是NetworkXStorage类的实例 # maybe_new_kg最重要的属性为 _graph，其为nx.Graph() maybe_new_kg = await extract_entities( inserting_chunks, knowledge_graph_inst=self.chunk_entity_relation_graph, entity_vdb=self.entities_vdb, relationships_vdb=self.relationships_vdb, global_config=asdict(self), ) # operate.py中 if not len(all_entities_data) if not len(all_relationships_data)会return None if maybe_new_kg is None: logger.warning(\u0026#34;No new entities and relationships found\u0026#34;) return self.chunk_entity_relation_graph = maybe_new_kg extract_entities函数内部 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 async def extract_entities( chunks: dict[str, TextChunkSchema], knowledge_graph_inst: BaseGraphStorage, entity_vdb: BaseVectorStorage, relationships_vdb: BaseVectorStorage, global_config: dict, ) -\u0026gt; Union[BaseGraphStorage, None]: \u0026#39;\u0026#39;\u0026#39; global_config[\u0026#34;llm_model_func\u0026#34;] -\u0026gt; gpt_4o_mini_complete(prompt, system_prompt=None, history_messages=[], **kwargs) -\u0026gt; openai_complete_if_cache(model, prompt, system_prompt=None, history_messages=[], base_url=None, api_key=None, **kwargs) 后来的封装了，可以选择模型，不像这里函数名写明了4o_min 上一行三个参数没有传入和调用实际上 \u0026#39;\u0026#39;\u0026#39; use_llm_func: callable = global_config[\u0026#34;llm_model_func\u0026#34;] # 默认设置为1，貌似和多轮对话有关 entity_extract_max_gleaning = global_config[\u0026#34;entity_extract_max_gleaning\u0026#34;] \u0026#39;\u0026#39;\u0026#39; ordered_chunks = [ (hash(\u0026#34;chunk-\u0026#34;+chunk_i的字符串), {\u0026#34;tokens\u0026#34;: chunk_i的token数, \u0026#34;content\u0026#34;: chunk_i具体内容, \u0026#34;chunk_order_index\u0026#34;: 是该文章的第i个chunk, \u0026#34;full_doc_id\u0026#34;: doc_key}), (a,b),... ] 即可索引的chunks \u0026#39;\u0026#39;\u0026#39; ordered_chunks = list(chunks.items()) \u0026#39;\u0026#39;\u0026#39; add language and example number params to prompt additional parameter 包括 语言 和 例子数量 实例化Lightrag的时候 可以添加参数addon_params={\u0026#34;example_number\u0026#34;: 1, \u0026#34;language\u0026#34;: \u0026#34;Simplfied Chinese\u0026#34;} 默认英文（PROMPTS[\u0026#34;DEFAULT_LANGUAGE\u0026#34;]），None \u0026#39;\u0026#39;\u0026#39; language = global_config[\u0026#34;addon_params\u0026#34;].get( \u0026#34;language\u0026#34;, PROMPTS[\u0026#34;DEFAULT_LANGUAGE\u0026#34;] ) example_number = global_config[\u0026#34;addon_params\u0026#34;].get(\u0026#34;example_number\u0026#34;, None) # 如果example_number不为None，按设置的个数来，且不超范围， # 如果为none，设置为 PROMPTS[\u0026#34;entity_extraction_examples\u0026#34;] # examples=\u0026#34;example1\u0026#34;+\u0026#34;\\n\u0026#34;+\u0026#34;example2\u0026#34;+\u0026#34;\\n\u0026#34;+\u0026#34;example3\u0026#34; if example_number and example_number \u0026lt; len(PROMPTS[\u0026#34;entity_extraction_examples\u0026#34;]): examples = \u0026#34;\\n\u0026#34;.join( PROMPTS[\u0026#34;entity_extraction_examples\u0026#34;][: int(example_number)] ) else: examples = \u0026#34;\\n\u0026#34;.join(PROMPTS[\u0026#34;entity_extraction_examples\u0026#34;]) # tuple_delimiter=\u0026#34;\u0026lt;|\u0026gt;\u0026#34; record_delimiter=\u0026#34;##\u0026#34; completion_delimiter=\u0026#34;\u0026lt;|COMPLETE|\u0026gt;\u0026#34; # entity_types=[\u0026#34;organization\u0026#34;, \u0026#34;person\u0026#34;, \u0026#34;geo\u0026#34;, \u0026#34;event\u0026#34;] example_context_base = dict( tuple_delimiter=PROMPTS[\u0026#34;DEFAULT_TUPLE_DELIMITER\u0026#34;], record_delimiter=PROMPTS[\u0026#34;DEFAULT_RECORD_DELIMITER\u0026#34;], completion_delimiter=PROMPTS[\u0026#34;DEFAULT_COMPLETION_DELIMITER\u0026#34;], entity_types=\u0026#34;,\u0026#34;.join(PROMPTS[\u0026#34;DEFAULT_ENTITY_TYPES\u0026#34;]), language=language, ) \u0026#39;\u0026#39;\u0026#39; 添加exampel的格式 examples字符串部分内容如下： (\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;人物\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索有着共同的承诺，并与 Taylor 就设备进行了重要互动。\u0026#34;){record_delimiter} (\u0026#34;关系\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;Cruz\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索的承诺是对 Cruz 控制与秩序愿景的反抗。\u0026#34;{tuple_delimiter}\u0026#34;意识形态冲突, 反抗\u0026#34;{tuple_delimiter}5){record_delimiter} (\u0026#34;content_keywords\u0026#34;{tuple_delimiter}\u0026#34;power dynamics, ideological conflict, discovery, rebellion\u0026#34;){completion_delimiter} examples字符串部分内容说明： 每行是对chunk的实体抽取、关系抽取或整体内容关键词提取 开头必为实体、关系或关键词，然后用{tuple_delimiter}隔开，每行记录1个关系过实体，然后行末添加{record_delimiter} 元数据附加：为关系添加分类标签（如“权力动态”“意识形态冲突”）和强度评分（如 Taylor-Jordan 的关系强度为 8） examples.format(**dict)将类如{tuple_delimiter}的内容替换为dict中的值（ tuple_delimiter: 值） 最终examples是 {...} 被替换了的一个字符串 \u0026#39;\u0026#39;\u0026#39; examples = examples.format(**example_context_base) \u0026#39;\u0026#39;\u0026#39; entity_extract_prompt主要包括： -Goal- ... -Steps- ... -Examples- ... -Real Data- ... \u0026#39;\u0026#39;\u0026#39; entity_extract_prompt = PROMPTS[\u0026#34;entity_extraction\u0026#34;] context_base = dict( tuple_delimiter=PROMPTS[\u0026#34;DEFAULT_TUPLE_DELIMITER\u0026#34;], record_delimiter=PROMPTS[\u0026#34;DEFAULT_RECORD_DELIMITER\u0026#34;], completion_delimiter=PROMPTS[\u0026#34;DEFAULT_COMPLETION_DELIMITER\u0026#34;], entity_types=\u0026#34;,\u0026#34;.join(PROMPTS[\u0026#34;DEFAULT_ENTITY_TYPES\u0026#34;]), examples=examples, language=language, ) # 让大模型继续按上次的格式继续提取 # \u0026#34;\u0026#34;\u0026#34;MANY entities were missed in the last extraction. # Add them below using the same format:\u0026#34;\u0026#34;\u0026#34; continue_prompt = PROMPTS[\u0026#34;entiti_continue_extraction\u0026#34;] # 询问LLM是否遗漏许多 实体 ，回答 是/否 # \u0026#34;\u0026#34;\u0026#34;It appears some entities may have still been missed. # Answer YES | NO if there are still entities that need to be added.\u0026#34;\u0026#34;\u0026#34; if_loop_prompt = PROMPTS[\u0026#34;entiti_if_loop_extraction\u0026#34;] already_processed = 0 already_entities = 0 already_relations = 0 # return dict(maybe_nodes), dict(maybe_edges) # 即 返回一个 元组，包含两个字典：(nodes_dict, edges_dict) # nodes_dict = {str: dict...} # edges_dict = {(str, str): dict} async def _process_single_content(chunk_key_dp: tuple[str, TextChunkSchema]):... # =====提取出每个chunk的entity和relation===== # results = [chunk_1的(nodes_dict, edges_dict), chunk_2的(nodes_dict, edges_dict)...] # = [ # ( {str: list[dict]} , {(str, str): list[dict]} ), # ( {str: list[dict]} , {(str, str): list[dict]} ), # ... # ] # 调用_process_single_content 返回的二元组 即 result results = [] for result in tqdm_async( asyncio.as_completed([_process_single_content(c) for c in ordered_chunks]), total=len(ordered_chunks), desc=\u0026#34;Extracting entities from chunks\u0026#34;, unit=\u0026#34;chunk\u0026#34;, ): results.append(await result) maybe_nodes = defaultdict(list) maybe_edges = defaultdict(list) # m_nodes = {str: list[dict]}合并成{str: list[dict,dict,...]}，dict的数量大于等于 # m_edges = {(str, str): list[dict]}合并同理 # 将list[二元tuple] results 处理为结点和边 # 因为results中的各个(nodes, edges)元组是以chunk单位提取的，提取的实体和关系有蛮多重复的 # 所以这里{str: list[dict,dict,...]} 会对应多个dict for m_nodes, m_edges in results: # 不同chunk同样实体的dict放在一个list了 for k, v in m_nodes.items(): maybe_nodes[k].extend(v) # 同理 for k, v in m_edges.items(): maybe_edges[tuple(sorted(k))].extend(v) # =====添加实体（结点）到图数据结构===== logger.info(\u0026#34;Inserting entities into storage...\u0026#34;) all_entities_data = [] # knowledge_graph_inst为NetworkXStorage实例 # for result in 列表生成式: all_e....append(await result) # 列表生成式=[_merge_upsert.(k, v,...graph_inst...) for k,v in...] # 不同chunk提取的实体和关系有蛮多重复的，{str: list[dict,dict,...]}会对应多个dict # maybe_nodes：所有chunk同样实体的dict放在一个list了，{str: list[dict,dict,...]} # result = node_data = dict( # entity_name=entity_name # entity_type=entity_type, # description=description, # source_id=source_id, # ) # 这里的一个result是集成该实体在 所有的chunk和过往graph里 # 提取出的dscri、源文章id，出现次数最多的type for result in tqdm_async( asyncio.as_completed( [ _merge_nodes_then_upsert(k, v, knowledge_graph_inst, global_config) for k, v in maybe_nodes.items() ] ), total=len(maybe_nodes), desc=\u0026#34;Inserting entities\u0026#34;, unit=\u0026#34;entity\u0026#34;, ): all_entities_data.append(await result) # =====添加关系（边）到图数据结构===== logger.info(\u0026#34;Inserting relationships into storage...\u0026#34;) all_relationships_data = [] # all_relationships_data = List[dict] # result = edge_data = dict( # src_id=src_id, # tgt_id=tgt_id, # description=description, # keywords=keywords, # ) # 多个chunk提取出的dscri用\u0026lt;SEP\u0026gt;连接起来，keywords去重排序后用\u0026lt;SEP\u0026gt;连接 # k[0]是(node1-\u0026gt;str,node2-\u0026gt;str), k[1]是[dict, dict, ...]每个dict来自不同chunk for result in tqdm_async( asyncio.as_completed( [ _merge_edges_then_upsert( k[0], k[1], v, knowledge_graph_inst, global_config ) for k, v in maybe_edges.items() ] ), total=len(maybe_edges), desc=\u0026#34;Inserting relationships\u0026#34;, unit=\u0026#34;relationship\u0026#34;, ): all_relationships_data.append(await result) if not len(all_entities_data): logger.warning(\u0026#34;Didn\u0026#39;t extract any entities, maybe your LLM is not working\u0026#34;) return None if not len(all_relationships_data): logger.warning( \u0026#34;Didn\u0026#39;t extract any relationships, maybe your LLM is not working\u0026#34; ) return None # =====存实体向量数据===== if entity_vdb is not None: data_for_vdb = { compute_mdhash_id(dp[\u0026#34;entity_name\u0026#34;], prefix=\u0026#34;ent-\u0026#34;): { \u0026#34;content\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] + dp[\u0026#34;description\u0026#34;], \u0026#34;entity_name\u0026#34;: dp[\u0026#34;entity_name\u0026#34;], } for dp in all_entities_data } await entity_vdb.upsert(data_for_vdb) # =====存关系向量数据===== if relationships_vdb is not None: data_for_vdb = { compute_mdhash_id(dp[\u0026#34;src_id\u0026#34;] + dp[\u0026#34;tgt_id\u0026#34;], prefix=\u0026#34;rel-\u0026#34;): { \u0026#34;src_id\u0026#34;: dp[\u0026#34;src_id\u0026#34;], \u0026#34;tgt_id\u0026#34;: dp[\u0026#34;tgt_id\u0026#34;], \u0026#34;content\u0026#34;: dp[\u0026#34;keywords\u0026#34;] + dp[\u0026#34;src_id\u0026#34;] + dp[\u0026#34;tgt_id\u0026#34;] + dp[\u0026#34;description\u0026#34;], } for dp in all_relationships_data } await relationships_vdb.upsert(data_for_vdb) return knowledge_graph_inst _process_single_content函数内部 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 async def _process_single_content(chunk_key_dp: tuple[str, TextChunkSchema]): nonlocal already_processed, already_entities, already_relations # chunk_key = hash(\u0026#39;chunk-\u0026#39;+chunk_i具体内容) chunk_key = chunk_key_dp[0] # chunk_dp 见 lightrag.py中的 chunks变量前的 注释，是个字典 chunk_dp = chunk_key_dp[1] # content即chunk_i具体内容 content = chunk_dp[\u0026#34;content\u0026#34;] \u0026#34;\u0026#34;\u0026#34; 替换初始prompt模板里的{...} hint_prompt = entity_extract_prompt.format(**context_base, input_text=content) 两次.format是因为担心第一次.format后,字典context_base的值中会有{input_text} 故第一次.format中，用input_text=\u0026#34;{input_text}\u0026#34;保留input_text不变，第二次再全部替换 hint_prompt即终极版prompt \u0026#34;\u0026#34;\u0026#34; hint_prompt = entity_extract_prompt.format( **context_base, input_text=\u0026#34;{input_text}\u0026#34; ).format(**context_base, input_text=content) # llm抽取实体 \u0026#39;\u0026#39;\u0026#39; use_llm_func 即 gpt_4o_mini_complete(...) -\u0026gt; str use_llm_func: callable = global_config[\u0026#34;llm_model_func\u0026#34;] llm_model_func: callable = gpt_4o_mini_complete --- lightrag.py定义的类属性，global_config async def gpt_4o_mini_complete(...) --- llm.py gpt_4o_mini_complete 返回： return await openai_complete_if_cache( \u0026#34;gpt-4o-mini\u0026#34;, prompt, system_prompt=system_prompt, history_messages=history_messages, **kwargs, ) final_result是str \u0026#39;\u0026#39;\u0026#39; final_result = await use_llm_func(hint_prompt) \u0026#39;\u0026#39;\u0026#39; 一个列表 history = [ {\u0026#34;role\u0026#34;: \u0026#39;user\u0026#39;, \u0026#34;content\u0026#34;: hint_prompt} {\u0026#34;role\u0026#34;: \u0026#39;assistant\u0026#39;, \u0026#34;content\u0026#34;: final_result} ] \u0026#39;\u0026#39;\u0026#39; history = pack_user_ass_to_openai_messages(hint_prompt, final_result) # \u0026#34;拾穗\u0026#34; 即重复抽取，防止遗漏 # entity_extract_max_gleaning默认为1 for now_glean_index in range(entity_extract_max_gleaning): # 直接告诉它遗漏了实体，要继续提取 # \u0026#34;\u0026#34;\u0026#34;MANY entities were missed in the last extraction. # Add them below using the same format:\u0026#34;\u0026#34;\u0026#34; glean_result = await use_llm_func(continue_prompt, history_messages=history) \u0026#39;\u0026#39;\u0026#39; [ {\u0026#34;role\u0026#34;: \u0026#39;user\u0026#39;, \u0026#34;content\u0026#34;: hint_prompt} {\u0026#34;role\u0026#34;: \u0026#39;assistant\u0026#39;, \u0026#34;content\u0026#34;: final_result} {\u0026#34;role\u0026#34;: \u0026#39;user\u0026#39;, \u0026#34;content\u0026#34;: continue_prompt} {\u0026#34;role\u0026#34;: \u0026#39;assistant\u0026#39;, \u0026#34;content\u0026#34;: glean_result} ] \u0026#39;\u0026#39;\u0026#39; history += pack_user_ass_to_openai_messages(continue_prompt, glean_result) # str+str 字符串相连 final_result += glean_result # 达到设定的最大次数，跳出 if now_glean_index == entity_extract_max_gleaning - 1: break #未达到，让LLM判断是否需要再次 拾穗 if_loop_result: str = await use_llm_func( if_loop_prompt, history_messages=history ) if_loop_result = if_loop_result.strip().strip(\u0026#39;\u0026#34;\u0026#39;).strip(\u0026#34;\u0026#39;\u0026#34;).lower() # 不需要则break if if_loop_result != \u0026#34;yes\u0026#34;: break \u0026#39;\u0026#39;\u0026#39; 假如说final result (\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;人物\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索有着共同的承诺，并与 Taylor 就设备进行了重要互动。\u0026#34;){record_delimiter} (\u0026#34;关系\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;Cruz\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索的承诺是对 Cruz 控制与秩序愿景的反抗。\u0026#34;{tuple_delimiter}\u0026#34;意识形态冲突, 反抗\u0026#34;{tuple_delimiter}5){record_delimiter} (\u0026#34;content_keywords\u0026#34;{tuple_delimiter}\u0026#34;power dynamics, ideological conflict, discovery, rebellion\u0026#34;){completion_delimiter} (\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;人物\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索有着共同的承诺，并与 Taylor 就设备进行了重要互动。\u0026#34;){record_delimiter} glean补充(\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;J\u0026#34;{tuple_delimiter}\u0026#34;人物\u0026#34;{tuple_delimiter}\u0026#34;J 对探索有承诺，并与 T互动。\u0026#34;){record_delimiter} (\u0026#34;关系\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;{tuple_delimiter}\u0026#34;Cruz\u0026#34;{tuple_delimiter}\u0026#34;Jordan 对探索的承诺是对 Cruz 控制与秩序愿景的反抗。\u0026#34;{tuple_delimiter}\u0026#34;意识形态冲突, 反抗\u0026#34;{tuple_delimiter}5){record_delimiter} (\u0026#34;content_keywords\u0026#34;{tuple_delimiter}\u0026#34;power dynamics, ideological conflict, discovery, rebellion\u0026#34;){completion_delimiter} 就会变成 [\u0026#34;(\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;...\u0026#34;)\u0026#34;, \u0026#34;(\u0026#34;关系\u0026#34;{tuple_delimiter}\u0026#34;Jordan...)\u0026#34;, (\u0026#34;content_keywords\u0026#34;{tuple_delimiter}\u0026#34;power dynamics,...\u0026#34;)\u0026#34;,...] \u0026#39;\u0026#39;\u0026#39; records = split_string_by_multi_markers( final_result, [context_base[\u0026#34;record_delimiter\u0026#34;], context_base[\u0026#34;completion_delimiter\u0026#34;]], ) # from collections import defaultdict \u0026#34;\u0026#34;\u0026#34; maybe_nodes = { 实体1_name-\u0026gt;str: [dict( entity_name=entity_name, entity_type=entity_type, description=entity_description, 块id source_id=entity_source_id, ),...], 实体2_name-\u0026gt;str: [dict( entity_name=entity_name, entity_type=entity_type, description=entity_description, 块id source_id=entity_source_id, ),...] } maybe_edges = { (实施实体-\u0026gt;str, 接收实体-\u0026gt;str): [dict( 实施实体 src_id=source, 接收实体 tgt_id=target, weight=weight, description=edge_description, keywords=edge_keywords, source_id=edge_source_id, ),...] } 简记为 maybe_nodes = {str:list[dict]} mabybe_edges = {(str,str):list[dict]} \u0026#34;\u0026#34;\u0026#34; maybe_nodes = defaultdict(list) maybe_edges = defaultdict(list) for record in records: # 获取括号里内容\u0026#34;(\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;...\u0026#34;)\u0026#34;-\u0026gt;\u0026#34;\u0026#34;实体\u0026#34;{tuple_delimiter}\u0026#34;Jordan\u0026#34;...\u0026#34;\u0026#34; record = re.search(r\u0026#34;\\((.*)\\)\u0026#34;, record) if record is None: continue record = record.group(1) # record_attributes=List[str,str...] record_attributes = split_string_by_multi_markers( record, [context_base[\u0026#34;tuple_delimiter\u0026#34;]] ) \u0026#34;\u0026#34;\u0026#34; if_entities= dict( entity_name=entity_name, entity_type=entity_type, description=entity_description, 块id source_id=entity_source_id, ) \u0026#34;\u0026#34;\u0026#34; if_entities = await _handle_single_entity_extraction( record_attributes, chunk_key ) # maybe_nodes为默认 值 为空列表的 字典 # {JORDAN:[{e_name:..., e_type:.......}]} if if_entities is not None: maybe_nodes[if_entities[\u0026#34;entity_name\u0026#34;]].append(if_entities) continue \u0026#34;\u0026#34;\u0026#34; if_relation= dict( src_id=source, tgt_id=target, weight=weight, description=edge_description, keywords=edge_keywords, source_id=edge_source_id, ) 单条record处理出relation \u0026#34;\u0026#34;\u0026#34; if_relation = await _handle_single_relationship_extraction( record_attributes, chunk_key ) if if_relation is not None: # {(JORDAN,JENNY):[{src_id:..., tgt_id:..., }]} maybe_edges[(if_relation[\u0026#34;src_id\u0026#34;], if_relation[\u0026#34;tgt_id\u0026#34;])].append( if_relation ) # 下面三个already都是chunk级循环外的 already_processed += 1 # 累加每个chunk带来的实体数量和关系数量 already_entities += len(maybe_nodes) already_relations += len(maybe_edges) # PROMPTS[\u0026#34;process_tickers\u0026#34;] = [\u0026#34;⠋\u0026#34;, \u0026#34;⠙\u0026#34;, \u0026#34;⠹\u0026#34;, \u0026#34;⠸\u0026#34;, \u0026#34;⠼\u0026#34;, \u0026#34;⠴\u0026#34;, \u0026#34;⠦\u0026#34;, \u0026#34;⠧\u0026#34;, \u0026#34;⠇\u0026#34;, \u0026#34;⠏\u0026#34;] now_ticks = PROMPTS[\u0026#34;process_tickers\u0026#34;][ already_processed % len(PROMPTS[\u0026#34;process_tickers\u0026#34;]) ] # 打印处理了多少个chunks，已经处理了的实体和关系 print( f\u0026#34;{now_ticks} Processed {already_processed} chunks, {already_entities} entities(duplicated), {already_relations} relations(duplicated)\\r\u0026#34;, end=\u0026#34;\u0026#34;, flush=True, ) # 由defaultdict转回dict return dict(maybe_nodes), dict(maybe_edges) 更新各存储区 kv_store_doc_status.json\nkv_store_full_docs.json\nkv_store_Ilm_response_cache.json\nkv_store_text_chunks.json\nvdb_chunks.json\nvdb_entities.json\nvdb_relationships.json\nchunk_overlap_token_size\n1 chunk_overlap_token_size: int = 100 # vdb存储，以存实体数据为例\n1 2 3 4 5 6 7 8 9 10 11 # =====存实体向量数据===== if entity_vdb is not None: data_for_vdb = { compute_mdhash_id(dp[\u0026#34;entity_name\u0026#34;], prefix=\u0026#34;ent-\u0026#34;): { \u0026#34;content\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] + dp[\u0026#34;description\u0026#34;], \u0026#34;entity_name\u0026#34;: dp[\u0026#34;entity_name\u0026#34;], } for dp in all_entities_data } # data_for_vdb: dict[str, dict] await entity_vdb.upsert(data_for_vdb) entity_vdb 为 NanoVectorDBStorage类（storage.py） 的实例化\n其 .upsert方法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 async def upsert(self, data: dict[str, dict]): # 日志和长度处理 logger.info(f\u0026#34;Inserting {len(data)} vectors to {self.namespace}\u0026#34;) if not len(data): logger.warning(\u0026#34;You insert an empty data to vector DB\u0026#34;) return [] # k1, v1为dict中的键值对 str:str, 他们被解包出来，最终list_data=List[{str:str}] # 实体vdb中 list-data中每个字典元素为 # { # \u0026#34;__id__\u0026#34;: hash_id, # \u0026#34;content\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] + dp[\u0026#34;description\u0026#34;] # \u0026#34;entity_name\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] # } list_data = [ { \u0026#34;__id__\u0026#34;: k, **{k1: v1 for k1, v1 in v.items() if k1 in self.meta_fields}, } for k, v in data.items() ] # List[str] contents = [v[\u0026#34;content\u0026#34;] for v in data.values()] # List[List[32个str]] batches = [ contents[i : i + self._max_batch_size] for i in range(0, len(contents), self._max_batch_size) ] # 每批32个str输入embedding_func处理成np.array(32, dim)的向量数据 embedding_tasks = [self.embedding_func(batch) for batch in batches] embeddings_list = [] for f in tqdm_async( asyncio.as_completed(embedding_tasks), total=len(embedding_tasks), desc=\u0026#34;Generating embeddings\u0026#34;, unit=\u0026#34;batch\u0026#34;, ): embeddings = await f # embeddings_list: List[np.array(32,dim), np.array(32,dim)...] # (n,32,dim) embeddings_list.append(embeddings) # 将多个数组沿着指定的轴（默认是第0轴）连接 # (n,32,dim)-\u0026gt;(n*32,dim) 每行都是一个(实体名+描述)的vector embeddings = np.concatenate(embeddings_list) # { # \u0026#34;__id__\u0026#34;: hash_id, # \u0026#34;content\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] + dp[\u0026#34;description\u0026#34;] # \u0026#34;entity_name\u0026#34;: dp[\u0026#34;entity_name\u0026#34;] # \u0026#34;__vector__\u0026#34;: np.array(dim) # } for i, d in enumerate(list_data): d[\u0026#34;__vector__\u0026#34;] = embeddings[i] # from nano_vectordb import NanoVectorDB # NanoVectorDB 的 upsert方法，datas关键字传入List[dict] # 将List[dict]中内容写到.json文件中因为之前的创建，以它内置的方式。 results = self._client.upsert(datas=list_data) return results 提问（Query） rag.query-\u0026gt;self.aquery\naquery内 分四种模式，naive 和 local global hybrid\nnaive进入 naive_query 其他三种进入kg_query\n1 2 3 4 5 6 7 8 9 async def aquery(self, query: str, param: QueryParam = QueryParam()): if param.mode in [\u0026#34;local\u0026#34;, \u0026#34;global\u0026#34;, \u0026#34;hybrid\u0026#34;]: response = await kg_query(...) elif param.mode == \u0026#34;naive\u0026#34;: response = await naive_query(...) else: raise ValueError(f\u0026#34;Unknown mode {param.mode}\u0026#34;) await self._query_done() return response naive（朴素） 直接将query_vector和chunk_vector匹配。\n将提问str转为vector，然后再chunks_vdb中匹配到“cosine_better_than_threshold”的前60十个chunk_id（如果能匹配到超过60个低于阈值的） 然后根据 chunk_id去 text_chunks_db里找到strs 最后将strs嵌入prompt输入LLM 也就是直接将与问句相似的chunks作为辅助数据让ai回答问题，相似性通过NanoVectorDB提供的向量邻近，本质上还是由embedding决定 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 async def naive_query( query, chunks_vdb: BaseVectorStorage, text_chunks_db: BaseKVStorage[TextChunkSchema], query_param: QueryParam, global_config: dict, ): \u0026#34;\u0026#34;\u0026#34; query: str param=QueryParam(mode=\u0026#34;naive\u0026#34;) chunks_vdb: embedding后存入这里，也是字典中包含 chunk的embedding text_chunks_db: 原文字符串存入这里，字典结构 \u0026#34;\u0026#34;\u0026#34; use_model_func = global_config[\u0026#34;llm_model_func\u0026#34;] # 一、将提问str转为vector，然后再chunks_vdb中匹配到“cosine_better_than_threshold”的chunk_id # 获取排名前top_k个相关文本块 # top_k: int = 60 results = await chunks_vdb.query(query, top_k=query_param.top_k) if not len(results): return PROMPTS[\u0026#34;fail_response\u0026#34;] chunks_ids = [r[\u0026#34;id\u0026#34;] for r in results] # 二、然后根据 chunk_id去 text_chunks_db里找到strs # chunks: List[str] chunks = await text_chunks_db.get_by_ids(chunks_ids) maybe_trun_chunks = truncate_list_by_token_size( chunks, key=lambda x: x[\u0026#34;content\u0026#34;], max_token_size=query_param.max_token_for_text_unit, ) logger.info(f\u0026#34;Truncate {len(chunks)} to {len(maybe_trun_chunks)} chunks\u0026#34;) # section:str = （比如） # \u0026#34;机器学习是人工智能的核心... # --New Chunk-- # 深度神经网络通过多层非线性变换... # --New Chunk-- # Transformer架构在NLP领域...\u0026#34; section = \u0026#34;\\n--New Chunk--\\n\u0026#34;.join([c[\u0026#34;content\u0026#34;] for c in maybe_trun_chunks]) if query_param.only_need_context: return section # 三、最后将strs嵌入prompt输入LLM sys_prompt_temp = PROMPTS[\u0026#34;naive_rag_response\u0026#34;] sys_prompt = sys_prompt_temp.format( content_data=section, response_type=query_param.response_type ) if query_param.only_need_prompt: return sys_prompt response = await use_model_func( query, system_prompt=sys_prompt, ) if len(response) \u0026gt; len(sys_prompt): response = ( response[len(sys_prompt) :] .replace(sys_prompt, \u0026#34;\u0026#34;) .replace(\u0026#34;user\u0026#34;, \u0026#34;\u0026#34;) .replace(\u0026#34;model\u0026#34;, \u0026#34;\u0026#34;) .replace(query, \u0026#34;\u0026#34;) .replace(\u0026#34;\u0026lt;system\u0026gt;\u0026#34;, \u0026#34;\u0026#34;) .replace(\u0026#34;\u0026lt;/system\u0026gt;\u0026#34;, \u0026#34;\u0026#34;) .strip() ) return response local、global and hybrid （局部）（全局）（混合）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 async def kg_query( query, knowledge_graph_inst: BaseGraphStorage, entities_vdb: BaseVectorStorage, relationships_vdb: BaseVectorStorage, text_chunks_db: BaseKVStorage[TextChunkSchema], query_param: QueryParam, global_config: dict, ) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; query: str knowledge_graph_inst: NetworkXStorage \u0026#34;\u0026#34;\u0026#34; context = None example_number = global_config[\u0026#34;addon_params\u0026#34;].get(\u0026#34;example_number\u0026#34;, None) # 1/2/3 个 examples=多个str连接 if example_number and example_number \u0026lt; len(PROMPTS[\u0026#34;keywords_extraction_examples\u0026#34;]): examples = \u0026#34;\\n\u0026#34;.join( PROMPTS[\u0026#34;keywords_extraction_examples\u0026#34;][: int(example_number)] ) else: examples = \u0026#34;\\n\u0026#34;.join(PROMPTS[\u0026#34;keywords_extraction_examples\u0026#34;]) language = global_config[\u0026#34;addon_params\u0026#34;].get( \u0026#34;language\u0026#34;, PROMPTS[\u0026#34;DEFAULT_LANGUAGE\u0026#34;] ) # check mode if query_param.mode not in [\u0026#34;local\u0026#34;, \u0026#34;global\u0026#34;, \u0026#34;hybrid\u0026#34;]: logger.error(f\u0026#34;Unknown mode {query_param.mode} in kg_query\u0026#34;) return PROMPTS[\u0026#34;fail_response\u0026#34;] # LLM generate keywords use_model_func = global_config[\u0026#34;llm_model_func\u0026#34;] kw_prompt_temp = PROMPTS[\u0026#34;keywords_extraction\u0026#34;] kw_prompt = kw_prompt_temp.format(query=query, examples=examples, language=language) # Output: # {{ # \u0026#34;high_level_keywords\u0026#34;: [\u0026#34;Education\u0026#34;, \u0026#34;Poverty reduction\u0026#34;, \u0026#34;Socioeconomic development\u0026#34;], # \u0026#34;low_level_keywords\u0026#34;: [\u0026#34;School access\u0026#34;, \u0026#34;Literacy rates\u0026#34;, \u0026#34;Job training\u0026#34;, \u0026#34;Income inequality\u0026#34;] # }} result = await use_model_func(kw_prompt, keyword_extraction=True) logger.info(\u0026#34;kw_prompt result:\u0026#34;) print(result) try: # json_text = locate_json_string_body_from_string(result) # handled in use_model_func keywords_data = json.loads(result) # List[str] hl_keywords = keywords_data.get(\u0026#34;high_level_keywords\u0026#34;, []) ll_keywords = keywords_data.get(\u0026#34;low_level_keywords\u0026#34;, []) # Handle parsing error except json.JSONDecodeError as e: print(f\u0026#34;JSON parsing error: {e} {result}\u0026#34;) return PROMPTS[\u0026#34;fail_response\u0026#34;] # Handdle keywords missing # 如果local，ll_keywords必为\u0026#34;kw1, kw2, ...\u0026#34; # 如果global，hl_keywords必为\u0026#34;kw1, kw2, ...\u0026#34; # 如果hybrid，二者都必为\u0026#34;kw1, kw2, ...\u0026#34; if hl_keywords == [] and ll_keywords == []: logger.warning(\u0026#34;low_level_keywords and high_level_keywords is empty\u0026#34;) return PROMPTS[\u0026#34;fail_response\u0026#34;] if ll_keywords == [] and query_param.mode in [\u0026#34;local\u0026#34;, \u0026#34;hybrid\u0026#34;]: logger.warning(\u0026#34;low_level_keywords is empty\u0026#34;) return PROMPTS[\u0026#34;fail_response\u0026#34;] else: ll_keywords = \u0026#34;, \u0026#34;.join(ll_keywords) if hl_keywords == [] and query_param.mode in [\u0026#34;global\u0026#34;, \u0026#34;hybrid\u0026#34;]: logger.warning(\u0026#34;high_level_keywords is empty\u0026#34;) return PROMPTS[\u0026#34;fail_response\u0026#34;] else: hl_keywords = \u0026#34;, \u0026#34;.join(hl_keywords) # Build context # [\u0026#34;kw1, kw2, ...\u0026#34;, \u0026#34;kw1, kw2, ...\u0026#34;] keywords = [ll_keywords, hl_keywords] # query_param.mode是不一样的，会选择不同模式，返回的context不一样 # 貌似需要关键字对应图中结点，万一同义不同词咋办，学校/院校，就对应不上了 # context:str = \u0026#34;\u0026#34;\u0026#34; -----Entities----- ```csv {entities_context} -----Relationships----- ```csv {relations_context} ``` -----Sources----- ```csv {text_units_context} ``` \u0026quot;\u0026quot;\u0026quot; # 包含了实体、关系、相关chunks context = await _build_query_context( keywords, knowledge_graph_inst, entities_vdb, relationships_vdb, text_chunks_db, query_param, ) if query_param.only_need_context: return context if context is None: return PROMPTS[\u0026quot;fail_response\u0026quot;] sys_prompt_temp = PROMPTS[\u0026quot;rag_response\u0026quot;] sys_prompt = sys_prompt_temp.format( context_data=context, response_type=query_param.response_type ) if query_param.only_need_prompt: return sys_prompt response = await use_model_func( query, system_prompt=sys_prompt, ) if len(response) \u0026gt; len(sys_prompt): response = ( response.replace(sys_prompt, \u0026quot;\u0026quot;) .replace(\u0026quot;user\u0026quot;, \u0026quot;\u0026quot;) .replace(\u0026quot;model\u0026quot;, \u0026quot;\u0026quot;) .replace(query, \u0026quot;\u0026quot;) .replace(\u0026quot;\u0026lt;system\u0026gt;\u0026quot;, \u0026quot;\u0026quot;) .replace(\u0026quot;\u0026lt;/system\u0026gt;\u0026quot;, \u0026quot;\u0026quot;) .strip() ) return response ","date":"2025-04-01T00:00:00Z","permalink":"https://rooobeam.github.io/p/lightrag1.0.3%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/","title":"Lightrag1.0.3代码解读"},{"content":"networkx.Graph 类常见方法和属性 目录 1. 初始化图 2. 添加节点 3. 添加边 4. 删除节点/边 5. 检查存在性 6. 基本属性 7. 节点与边的属性 8. 图的操作 9. 节点邻居与度数 10. 示例代码 1. 初始化图 1 2 import networkx as nx G = nx.Graph() # 创建空的无向图 2. 添加节点 1 2 3 4 5 # 添加单个节点（带属性） G.add_node(1, color=\u0026#39;red\u0026#39;, size=10) # 批量添加节点 节点2、3共用属性 G.add_nodes_from([2, 3], category=\u0026#39;A\u0026#39;) 3. 添加边 1 2 3 4 5 6 7 8 # 添加单条边（带权重） G.add_edge(1, 2, weight=4.7) # 批量添加边 G.add_edges_from([(1, 3), (2, 3)], type=\u0026#39;friendship\u0026#39;) # 批量添加带权重的边 G.add_weighted_edges_from([(1, 2, 0.5), (2, 3, 0.8)]) 4. 删除节点/边 1 2 3 4 5 6 7 # 删除节点 G.remove_node(1) G.remove_nodes_from([2, 3]) # 删除边 G.remove_edge(1, 2) G.remove_edges_from([(1, 2), (2, 3)]) 5. 检查存在性 1 2 G.has_node(1) # 返回布尔值 G.has_edge(1,2) # 返回布尔值 6. 基本属性 1 2 3 4 5 6 7 8 9 10 11 12 13 # 节点和边视图 list(G.nodes) # [1, 2, 3] list(G.edges(data=\u0026#39;weight\u0026#39;)) # 边及属性 # 邻接字典 G.adj[1] # 输出: {2: {\u0026#39;weight\u0026#39;: 0.5}} # 全局属性 G.graph[\u0026#39;name\u0026#39;] = \u0026#39;My Graph\u0026#39; # 统计方法 G.number_of_nodes() # 节点总数 G.number_of_edges() # 边总数 7. 节点与边的属性 1 2 3 4 5 6 7 8 9 10 # 节点属性操作，先要保证 1 结点存在 G.nodes[1][\u0026#39;color\u0026#39;] = \u0026#39;blue\u0026#39; G.nodes.add(2, \u0026#39;color\u0026#39; = \u0026#39;blue\u0026#39;) color = G.nodes[1].get(\u0026#39;color\u0026#39;, \u0026#39;default\u0026#39;) color = G.nodes.get(1, \u0026#39;color\u0026#39;, \u0026#39;default\u0026#39;) # 边属性操作 G.edges[1, 2][\u0026#39;weight\u0026#39;] = 5.0 weight = G.edges[1, 2].get(\u0026#39;weight\u0026#39;, 1.0) 注意点：\n语法等效性：属性名 color（关键字参数）和 'color'（字典键）本质是同一个属性。\n安全操作：用 G.nodes.get(2, {}) 可避免异常。\n1 2 3 4 5 6 7 8 9 import networkx as nx # 创建图并添加节点（两种等效方式） G = nx.Graph() G.add_node(2, color=\u0026#39;blue\u0026#39;) # 访问属性（需确保节点和属性名正确），用\u0026#39;color\u0026#39;访问 print(G.nodes[2][\u0026#39;color\u0026#39;]) # \u0026#39;blue\u0026#39; print(G.nodes.get(2,\u0026#39;color\u0026#39;) # \u0026#39;blue\u0026#39; 8. 图的操作 1 2 3 G.clear() # 清空图（保留属性） G.copy() # 深拷贝图 subG = G.subgraph([1, 2]) # 生成子图 9. 节点邻居与度数 1 2 list(G.neighbors(1)) # 返回邻居列表 G.degree(1) # 返回节点度数 10. 示例代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import networkx as nx # 创建图 G = nx.Graph(name=\u0026#34;示例图\u0026#34;) G.add_nodes_from([1, 2, 3], category=\u0026#39;sample\u0026#39;) G.add_edges_from([(1, 2), (2, 3)], weight=1.0) # 设置属性 G.nodes[1][\u0026#39;color\u0026#39;] = \u0026#39;red\u0026#39; G.edges[1, 2][\u0026#39;weight\u0026#39;] = 2.5 # 输出信息 print(\u0026#34;节点列表:\u0026#34;, list(G.nodes)) print(\u0026#34;边列表:\u0026#34;, list(G.edges(data=True))) print(\u0026#34;节点1的邻居:\u0026#34;, list(G.neighbors(1))) print(\u0026#34;节点1的度数:\u0026#34;, G.degree(1)) 注意事项\n边操作会自动添加不存在的节点 节点支持任意可哈希对象（如元组、字符串） 批量操作比逐条操作更高效 ","date":"2025-03-28T20:03:22+08:00","permalink":"https://rooobeam.github.io/p/networkx.graph%E7%B1%BB/","title":"Networkx.Graph类"},{"content":".pop(self,index)方法 1 2 3 a=[1,2,3] a.pop(1) print(a)\t# [1,3] 函数传实参还是形参问题 在 Python 中，参数传递始终是 引用传递（传地址的）。但根据对象类型（可变/不可变）的不同，会产生类似「值传递」或「引用传递」的表象：\n结论：看对象类型\n不可变对象（字符串、数字、元组等）作为参数时： 形参接收到的是对象的引用 若在函数内修改形参，会创建新对象，实参不受影响（类似值传递） nonlocal声明实现访问外部变量？ 可变对象（列表、字典、集合等）作为参数时： 形参接收到的也是对象的引用 若在函数内 原地修改 形参（如 append、+= 等操作），实参会同步变化（类似引用传递） 1 2 3 4 5 6 7 8 9 10 11 12 13 def f(obj): # 修改形参 obj += obj # 不可变对象（字符串） obj1 = \u0026#34;123456\u0026#34; demo(obj1) print(\u0026#34;函数调用后obj1:\u0026#34; + obj1) # 123456（未变） # 可变对象（列表） obj2 = [1,2,3] demo(obj2) print(\u0026#34;函数调用后obj2:\u0026#34; + str(obj2)) # [1,2,3,1,2,3]（已变） pychram 来回查看代码 pycharm会用ctrl+鼠标左键点击函数来进入函数体查看函数具体实现部分。但是我常常点击后就回不来了，不同文件的函数调用来回找让人头大。\n可以来回的方法是：\nctrl+alt+左方向键(←) 后退(回退回原来位置, 不行就多摁几次，因为光标点击的地方好像也会记录)\nctrl+alt+右方向键(→) 前进(即回到刚才点击的函数位置)\n参考链接：https://blog.csdn.net/shmily_ke/article/details/136975710\nfor _ in range(len(queue)) 下划线 \u0026lsquo;_\u0026rsquo;：_ 是一个占位符，表示“我不关心这个索引值”\nlen(queue)忽略循环中queue本身的变化\n特性 for _ in range(len(queue)) for _ in queue 遍历方式 基于索引，范围固定 动态跟踪变化 q 增加元素 不会遍历到新添加的元素 可能会遍历到新添加的元素 **q 删除元素 ** 可能导致索引越界 可能导致跳过元素或提前结束 103. 二叉树的锯齿形层序遍历 - 力扣（LeetCode）\n对比我的代码和题解代码如下：\n我的还要用cnt记录下一层的结点个数，它只需要for _ in range(len(queue))中的len(queue)就能保留一层的值然后循环。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Solution: def zigzagLevelOrder(self, root: Optional[TreeNode]) -\u0026gt; List[List[int]]: if not root: return [] res, queue = [], collections.deque() queue.append(root) while queue: tmp = [] for _ in range(len(queue)): node = queue.popleft() tmp.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) res.append(tmp[::-1] if len(res) % 2 else tmp) return res 链接：https://leetcode.cn/problems/binary-tree-zigzag-level-order-traversal/solutions/2361613/103-er-cha-shu-de-ju-chi-xing-ceng-xu-bi-qz2q/ 部分 可迭代型数据 逆序 list.reverse() reversed(iterable) list[::-1]——需要对象有__getitem__，最好用 特性 reverse() reversed() [::-1] ‌功能‌ 原地反转列表 返回反转后的迭代器 返回反转后的新对象 ‌适用对象‌ 仅列表（list） 所有可迭代对象（列表、元组、字符串等） 所有支持切片的有序序列（列表、字符串、元组等） ‌返回值‌ None 迭代器 反转后的新对象 ‌内存效率‌ 高（原地操作，不生成新对象） 高（返回迭代器，不生成完整副本） 低（生成完整副本，占用额外内存） ‌时间复杂度‌ O(n)（直接交换元素） O(1)（延迟计算，实际遍历时 O(n)） O(n)（复制所有元素） ‌修改原数据‌ ✅ 是 ❌ 否 ❌ 否 ‌支持链式操作‌ ❌ 否（返回 None） ✅ 是（可与 list()、join() 等结合） ✅ 是（直接生成新对象） for key in dic_1 if key in dic_2 1 2 3 4 5 6 dic_1={\u0026#39;a\u0026#39;:1,\u0026#39;b\u0026#39;:2,\u0026#39;c\u0026#39;:3} dic_2={\u0026#39;b\u0026#39;:2} dic_3 = { key: dic_1[key] for key in dic_1 if key in dic_2 } print(dic_3)\t# {\u0026#39;b\u0026#39;: 2} 声明多个全局变量 逗号 隔开，“ \\ ”连接下一行\n1 2 3 4 5 6 7 8 9 10 global \\ _manager, \\ is_multiprocess, \\ _storage_lock, \\ _internal_lock, \\ _pipeline_status_lock, \\ _shared_dicts, \\ _init_flags, \\ _initialized, \\ _update_flags 字典 .join方法 1 2 3 4 5 content = \u0026#34;数据1|数据2#数据3@需要保留的+符号+数据4\u0026#34; markers = [\u0026#34;|\u0026#34;, \u0026#34;#\u0026#34;, \u0026#34;@\u0026#34;, \u0026#34;+\u0026#34;] results = re.split(\u0026#34;|\u0026#34;.join(re.escape(marker) for marker in markers), content) print(results) dataclasses dataclasses 的 dataclass, field\npycharm书签功能 按 F11 对光标那行生成书签\npycharm关警告 右上角有 黄色三角形警告图标⚠ 直接鼠标放置⚠处 会自动显示 如 “ 25个警告，3个弱警告 高亮显示：所有问题 ” 点击 高亮显示：所有问题 弹出“无 语法 所有问题”，点击 无 即可。 func(*args,**kwargs) 函数定义中，可以有一个 *args 和 一个 **kwargs 参数，args 和 kwargs 是约定俗成的参数命名。也就是说可以func(*a,**b)\n我的理解：\nargs是一个元组，*args是解包，即 未知元组(a,b\u0026hellip;) 解包成 a,b\u0026hellip; 放到func的括号里，变成 func(a,b\u0026hellip;) kwargs是一个字典未知字典{a: b, c: d\u0026hellip;}，解包放func里，变成 func(a=b, c=d\u0026hellip;) 使用式理解：\n*func(fixed_arg, args, obvious_kwarg=123, **kwargs)中\nfixed_arg 传递：它是固定位置参数，没有默认值。 *args 接收所有多余的位置参数：所有未被 fixed_arg 接收的位置参数都会被打包到 *args。 obvious_kwarg 是仅限关键字参数：它只能通过关键字传递，不能通过位置传递。 **kwargs 接收所有多余的关键字参数：所有未被 fixed_arg、*args 和 obvious 接收的关键字参数都会被打包到 **kwargs。 1 2 3 4 5 6 7 def func(fixed_arg, *args, obvious_kwarg=123, **kwargs): print(f\u0026#34;位置参数: {fixed_arg}\u0026#34;)\t# 10 print(f\u0026#34;多余的位置参数: {args}\u0026#34;)\t# (20, 30) print(f\u0026#34;显式传递的关键字参数: {obvious_kwarg}\u0026#34;)\t# 60 print(f\u0026#34;可变关键字参数: {kwargs}\u0026#34;)\t# {\u0026#39;x\u0026#39;: 40, \u0026#39;y\u0026#39;: 50} func(10, 20, 30, x=40, y=50, obvious_kwarg=60) [a:b]不包含第b个元素 [a:b]不包含第b个元素，没了\n题目：填空，s是个str，长度\u0026gt;1，获取其前缀，如\u0026quot;123 -\u0026gt; 1 12 123\u0026quot;\ns_arr=[s[ __ ] for i in range( ___ )]\n1 2 3 4 s=\u0026#34;123\u0026#34; # :i 表示 0:i，不包含元素[i]，所以若要包括元素[len(s)-1]，i 范围为 1~len(s)，range要产生1~len(s)，则range(1,len(s)+1) s_arr=[s[:i] for i in range(1, len(s)+1)] print(s_arr) from collections import defaultdict 直译 —— 有默认的 值 的字典\n1 2 3 4 5 6 7 8 9 10 11 from collections import defaultdict maybe_nodes = defaultdict(list) # 访问不存在的键 \u0026#34;A\u0026#34;，会自动创建一个空列表 maybe_nodes[\u0026#34;A\u0026#34;].append(1) maybe_nodes[\u0026#34;A\u0026#34;].append(2) # 访问不存在的键 \u0026#34;B\u0026#34;，同样会自动创建一个空列表 maybe_nodes[\u0026#34;B\u0026#34;].append(3) print(maybe_nodes) # defaultdict(\u0026lt;class \u0026#39;list\u0026#39;\u0026gt;, {\u0026#39;A\u0026#39;: [1, 2], \u0026#39;B\u0026#39;: [3]}) .extend 对比.extend和.append\n1 2 3 4 5 6 7 8 9 10 11 base_list = [1, 2, 3] to_add = [4, 5] # 使用 append base_list.append(to_add) print(base_list) # 输出 [1, 2, 3, [4, 5]] → 整个列表被当作一个元素添加 # 使用 extend base_list = [1, 2, 3] base_list.extend(to_add) print(base_list) # 输出 [1, 2, 3, 4, 5] → 逐个元素合并 pycharm折叠、展开 折叠所有代码\tCtrl Shift -\n展开所有代码\tCtrl Shift +\n折叠光标所在层所有可折叠代码(truncate)\tCtrl Alt -\n展开光标所在层所有可折叠代码(truncate)\tCtrl Alt +\n折叠光标所在层\tCtrl -\n开光标所在层\tCtrl +\n提示词工程代码例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 async def _handle_entity_relation_summary( entity_or_relation_name: str, description: str, global_config: dict, ) -\u0026gt; str: use_llm_func: callable = global_config[\u0026#34;llm_model_func\u0026#34;] llm_max_tokens = global_config[\u0026#34;llm_model_max_token_size\u0026#34;] tiktoken_model_name = global_config[\u0026#34;tiktoken_model_name\u0026#34;] summary_max_tokens = global_config[\u0026#34;entity_summary_to_max_tokens\u0026#34;] language = global_config[\u0026#34;addon_params\u0026#34;].get( \u0026#34;language\u0026#34;, PROMPTS[\u0026#34;DEFAULT_LANGUAGE\u0026#34;] ) # description=dsri_1\u0026lt;SEP\u0026gt;dsri_2\u0026lt;SEP\u0026gt;... # 获取描述的tokens并判断是否要总结 tokens = encode_string_by_tiktoken(description, model_name=tiktoken_model_name) if len(tokens) \u0026lt; summary_max_tokens: # No need for summary return description # 将多个dsri 总结成一个综合的 prompt_template = PROMPTS[\u0026#34;summarize_entity_descriptions\u0026#34;] # 保证在llm最大tokens限制下 use_description = decode_tokens_by_tiktoken( tokens[:llm_max_tokens], model_name=tiktoken_model_name ) # description_list: dsri_1\u0026lt;SEP\u0026gt;dsri_2\u0026lt;SEP\u0026gt; 被\u0026lt;SEP\u0026gt;分割 context_base = dict( entity_name=entity_or_relation_name, description_list=use_description.split(GRAPH_FIELD_SEP), language=language, ) use_prompt = prompt_template.format(**context_base) logger.debug(f\u0026#34;Trigger summary: {entity_or_relation_name}\u0026#34;) summary = await use_llm_func(use_prompt, max_tokens=summary_max_tokens) return summary pycharm一直显示正在关闭项目 pycharm关闭后一直显示正在关闭项目的解决方法-CSDN博客\n生成当前环境配置的txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # deepseek-r1生成后删减得来 import sys import platform import subprocess from importlib.metadata import distributions def get_environment_info(): env_info = { # 系统信息 \u0026#34;操作系统\u0026#34;: f\u0026#34;{platform.system()} {platform.release()} {platform.version()}\u0026#34;, \u0026#34;系统架构\u0026#34;: platform.architecture()[0], \u0026#34;主机名\u0026#34;: platform.node(), # Python环境 \u0026#34;Python版本\u0026#34;: sys.version.replace(\u0026#39;\\n\u0026#39;, \u0026#39; \u0026#39;), \u0026#34;虚拟环境\u0026#34;: \u0026#34;是\u0026#34; if hasattr(sys, \u0026#39;real_prefix\u0026#39;) or sys.prefix != sys.base_prefix else \u0026#34;否\u0026#34;, # 包管理信息 \u0026#34;已安装包\u0026#34;: [f\u0026#34;{dist.metadata[\u0026#39;Name\u0026#39;]}=={dist.version}\u0026#34; for dist in distributions()], } # 获取conda信息（如果可用） try: result = subprocess.run([\u0026#39;conda\u0026#39;, \u0026#39;list\u0026#39;], capture_output=True, text=True, check=True) env_info[\u0026#34;Conda包列表\u0026#34;] = result.stdout.splitlines() except: env_info[\u0026#34;Conda包列表\u0026#34;] = \u0026#39;conda list fail\u0026#39; pass return env_info if __name__ == \u0026#34;__main__\u0026#34;: info = get_environment_info() # 打印摘要信息 print(\u0026#34;=\u0026#34; * 50 + \u0026#34;\\n环境配置摘要:\\n\u0026#34; + \u0026#34;=\u0026#34; * 50) print(f\u0026#34;操作系统: {info[\u0026#39;操作系统\u0026#39;]}\u0026#34;) print(f\u0026#34;Python版本: {info[\u0026#39;Python版本\u0026#39;].split(\u0026#39; [\u0026#39;)[0]}\u0026#34;) print(f\u0026#34;虚拟环境: {info[\u0026#39;虚拟环境\u0026#39;]}\u0026#34;) print(f\u0026#34;已安装包数量: {len(info[\u0026#39;已安装包\u0026#39;])}\u0026#34;) # 保存完整信息到文件 with open(\u0026#34;environment_report.txt\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: for key, value in info.items(): f.write(f\u0026#34;\\n=== {key} ===\\n\u0026#34;) if isinstance(value, list): f.write(\u0026#39;\\n\u0026#39;.join(value)) elif isinstance(value, dict): for k, v in value.items(): f.write(f\u0026#34;{k}: {v}\\n\u0026#34;) else: f.write(str(value)) print(\u0026#34;\\n完整环境报告已保存到 environment_report.txt\u0026#34;) ","date":"2025-03-24T00:00:00Z","permalink":"https://rooobeam.github.io/p/py_tricks/","title":"Py_tricks"},{"content":"目录 目录结构 - - - - abs dict help min、max setattr、getattr all_any dir hex、oct next slice divmod id object sorted ascii enumerate input staticmethod bin open eval int str bool exec isinstance ord、chr sum bytes bytearray filter issubclass pow super float iter print tuple callable format、f-string len property type set frozenset list range classmethod repr zip map reversed import_module complex hasattr - abs abs(x) 返回数字的绝对值。 x 可以是整数，浮点数，复数；如果是复数，则返回它的大小。\n1 2 3 4 a=abs(-50) print(a) b=abs(3 + 4j ) print(b) dict class dict(**kwarg) 等号模式 class dict(mapping, **kwarg) zip模式 class dict(iterable, **kwarg) 二元组列表 主要是zip模式和二元元组模式\n1 2 3 4 5 6 7 8 9 x = dict() # 创建空字典{} y = dict(a=\u0026#39;a\u0026#39;, b=\u0026#39;b\u0026#39;, t=\u0026#39;t\u0026#39;) # 传入关键字，等于号模式 z = dict(zip([\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;], [1, 2, 3])) # 映射函数方式，zip模式 u = dict([(\u0026#39;one\u0026#39;, 1), (\u0026#39;two\u0026#39;, 2), (\u0026#39;three\u0026#39;, 3)]) # 可迭代对象方式，二元元组代替等号模式，二元列表元素会警告 print(x, y, z, u) # 也可直接用{}、:创建字典 v = {123: \u0026#39;123\u0026#39;, 456: \u0026#39;456\u0026#39;} print(v, type(v)) help help([object])\tobject \u0026ndash; 对象；\n返回对象帮助信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 help(list) # 输出： # # Help on class list in module builtins: # class list(object) # | list(iterable=(), /) # | # | Built-in mutable sequence. # | # | If no argument is given, the constructor creates a new empty list. # | The argument must be an iterable if specified. # | # | Methods defined here: # | # ...... min_max 返回可迭代参数中的最小、最大元素。\n1 2 print (\u0026#34;min(80, 100, 1000) : \u0026#34;, min(80, 100, 1000)) print (\u0026#34;min(80, 100, 1000) : \u0026#34;, max(80, 100, 1000)) setattr、getattr (attr——attribute)\nsetattr用于设置对象的属性值，getattr用于获取对象的属性值。相比于 \u0026ldquo;.\u0026rdquo; 功能更丰富。\n当实例a有属性bar时，当使用setattr(a, \u0026lsquo;bar\u0026rsquo;, 5)时，会将实例a属性bar设置为5; 当实例a无属性bar时，会为实例a创建一个实例属性bar，赋值为5，而类属性不变。 getattr当属性不存在时避免抛出AttributeError，若设置默认值，则不会报错。例如，getattr(a, \u0026lsquo;baz\u0026rsquo;, \u0026lsquo;default\u0026rsquo;)会返回\u0026rsquo;default\u0026rsquo;，而a.baz则会引发异常。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class A(object): bar = 1 a = A() print(getattr(a, \u0026#39;bar\u0026#39;)) # 获取属性 bar 值 setattr(a, \u0026#39;bar\u0026#39;, 5) setattr(a, \u0026#39;weight\u0026#39;, 5) # 设置属性 weight 值，不存在会为该对象创建，但类不变 print(a.bar, a.weight) b=A() try: print(getattr(b, \u0026#39;weight\u0026#39;)) except AttributeError as e: print(f\u0026#34;属性访问错误: {e}\u0026#34;)\t# 为对象创建，但类不变，b无weight属性 print(getattr(b, \u0026#39;weight\u0026#39;，-1))\t# 设置默认值，返回-1不报错 all 、any all：是否都为True\tany：是否存在True\nall(iterable, /)\n判断给定的可迭代参数 iterable 中的所有元素是否都为 TRUE，如果是返回 True，否则返回 False。 元素除了是 0、空、None、False 外都算 True。 空元组、空列表返回值为True，这里要特别注意。 不会进入内层。 1 2 3 print(all([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;])) # 元素都不为空或0，True print(all([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;d\u0026#39;])) # 存在一个为空的元素，False print(all([[\u0026#39;\u0026#39;],[\u0026#39;\u0026#39;]]))\t# 不会进入内层，首层元素[\u0026#39;\u0026#39;]不为0、空、None、False any(iterable, /) “是否存在 True”的意思，True代表的是 非空类数据。 dir dir() 函数不带参数时，返回当前范围内的变量、方法和定义的类型列表 带参数时——dir([object])，返回参数的属性、方法列表。 如果参数包含方法__dir__()，该方法将被调用。如果参数不包含__dir__()，该方法将最大限度地收集参数信息。 1 2 3 4 5 6 7 8 9 10 class MyClass: def __init__(self): self.public_attr = 10 self.__private_attr=20 def normal_method(self): pass obj = MyClass()\t# 实例化对象 print(dir(obj)) 输出包含 \u0026lsquo;_MyClass__private_attr\u0026rsquo;, \u0026rsquo;normal_method\u0026rsquo;, \u0026lsquo;public_attr\u0026rsquo;\n[ \u0026lsquo;_MyClass__private_attr\u0026rsquo;, \u0026lsquo;__class__\u0026rsquo;, \u0026lsquo;__delattr__\u0026rsquo;, \u0026lsquo;__dict__\u0026rsquo;, \u0026lsquo;__dir__\u0026rsquo;, \u0026lsquo;__doc__\u0026rsquo;, \u0026hellip;\u0026hellip; \u0026lsquo;normal_method\u0026rsquo;, \u0026lsquo;public_attr\u0026rsquo; ]\n实际应用场景\n快速查看对象内容 动态检查对象功能 限制暴露的接口（设置接口） 1 2 # 快速查看对象内容 print(dir()) # 查看字典的方法，如 keys, values, items 1 2 3 4 # 动态检查对象功能 obj = SomeClass() if \u0026#34;__iter__\u0026#34; in dir(my_object): print(\u0026#34;对象是可迭代的\u0026#34;) 1 2 3 4 5 6 7 8 9 10 # 限制暴露的接口（设置接口） class SecureAPI: def __init__(self): self._internal_data = 100 def __dir__(self): return [\u0026#34;public_method\u0026#34;] # 隐藏内部实现 def public_method(self): return \u0026#34;Safe data\u0026#34; 拓展：属性名以双下划线 __ 开头且不以双下划线结尾 —— 名称修饰，避免子类与父类的私有属性命名冲突，Python会自动将其转换为：_类名__属性名\t(如刚才的_MyClass__private_attr)\n1 2 3 4 5 6 7 8 class A: def __init__(self): self.__x = 1 # _A__x class B(A): def __init__(self): super().__init__() self.__x = 2 # _B__x hex 、oct hex(x)：将10进制int转为16进制且为字符串，0x为前缀。\n1 2 3 4 5 a=16 print(type(a))\t# \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; b=hex(a) print(b)\t# 0x10 print(type(b))\t# \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; hex(x)：将10进制int转为8进制且为字符串，0o为前缀。\n1 2 3 4 a=16 b=hex(a) print(b)\t# 0o20 print(type(b))\t# \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; next next()返回迭代器的的下一个项目；要和生成迭代器函数 iter() 配合使用。 1 next(iterable[, default]) 一个参数是iter()生成的迭代器实例，另一个是默认值，如果指针超出范围就输出默认。\n常见应用\n1 2 with open(file_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: # 强制使用UTF-8编码读取 lines = [next(f) for _ in range(5)] # 读取前5行到列表 我理解的next()是python 内置的__next__方法，因为iter类有__next__方法，而其他的如生成器也有，自定义一个类并定义__next__方法，该类弄出的实例也可以用next() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 自定义迭代器 class MyClass: # 迭代相关 __iter__(self) # 迭代：for i in obj __next__(self) # 下一个：next(obj) # 生成器（本身就是迭代器） # \u0026lt;class \u0026#39;generator\u0026#39;\u0026gt; 不是 \u0026lt;class \u0026#39;list\u0026#39;\u0026gt;，用括号的 gen = (x for x in range(3))\tprint(next(gen)) # 0 print(next(gen)) # 1 # 文件对象（本身就是迭代器） with open(\u0026#39;data.txt\u0026#39;) as f: print(next(f)) # 直接读取第一行 print(next(f)) # 读取第二行 拓展 这样有双下划线的方法和无双下划线的有什么区别？如__getitem__(self)。 —— Python 的特殊方法（魔术方法）是由 Python 语言规范定义的。这些方法与 Python 的内置操作直接关联： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class MyClass: # 基本操作 __init__(self) # 实例化：obj = MyClass() __str__(self) # 字符串转换：str(obj) __len__(self) # 长度：len(obj) # 迭代相关 __iter__(self) # 迭代：for i in obj __next__(self) # 下一个：next(obj) # 运算符 __add__(self) # 加法：obj + other __sub__(self) # 减法：obj - other # 容器操作 __getitem__(self) # 索引访问：obj[key] __setitem__(self) # 索引赋值：obj[key] = value # 使用这些特殊方法 lst = MyList() len(lst) # 调用 __len__ 3 in lst # 调用 __contains__ 判断是否contain for x in lst: ... # 调用 __iter__ # 查看所有特殊方法 # 方法1：查看内置文档 help(object) # 方法2：dir() 函数 print([m for m in dir(object) if m.startswith(\u0026#39;__\u0026#39;)]) slice slice()返回一个切片对象。\nslice(stop) slice(start, stop[, step])，(起点，终点，步长)\n直接使用 创建slice [:5] slice(None, 5) / slice(None, 5) [3::2] slice(3, None, 2) [::-1] slice(None, None, -1) 类似于a​:b:c\n1 2 3 4 5 a=list(range(10)) print(lst[2:7:2]) print(slice(2, 7, 2)) assert lst[2:7:2] == lst[slice(2, 7, 2)] 但是要保存为对象的话:\n1 2 x=2:7:2\t# ❌ 非法写法 x=slice(2, 7, 2)\t# ✅ 正确写法\t对于 lst[slice(95, 105, 2)]，为什么不用 lst[95:105:2] ? —— 定义slice的优势\n动态参数配置\n1 2 3 4 5 6 7 def dynamic_slicer(config): \u0026#34;\u0026#34;\u0026#34;根据外部配置生成切片\u0026#34;\u0026#34;\u0026#34; return data[slice(*config)] # 从配置文件读取参数 config = json.loads(\u0026#39;{\u0026#34;start\u0026#34;: 95, \u0026#34;stop\u0026#34;: 105, \u0026#34;step\u0026#34;: 2}\u0026#39;) print(dynamic_slicer(config.values())) # 动态应用切片参数 切片对象复用\n1 2 3 4 5 6 # 定义标准切片规则 DOWNSAMPLE_SLICE = slice(None, None, 4) # 每4个元素取1个 # 复用切片 video_frames = raw_frames[DOWNSAMPLE_SLICE] audio_samples = raw_audio[DOWNSAMPLE_SLICE] 多维切片基础\n1 2 3 4 5 6 7 8 9 10 11 12 13 import numpy as np arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) print(arr[0:2, 1:3]) # 输出 [[2 3], [5 6]] # 定义行和列的切片对象 row_slice = slice(0, 2) # 第0行到第1行（不含2） col_slice = slice(1, 3) # 第1列到第2列（不含3） print(arr[row_slice, col_slice]) # 输出 [[2 3], [5 6]] divmod divmod() 函数接受两个参数 x y（通常是两个数字），返回二元组，第一个值是 x 除以 y 的商（即整数部分），第二个值是余数。\n对于3.x，参数不能是复数， x 可以为整数/浮点数，y 也如此\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 a=13 b=3 x,y=divmod(a,b) print(x,y) # 4 1 a=13.6 b=3 x,y=divmod(a,b) print(x,y)\t# 4.0 1.5999999999999996 print(x,round(y,1))\t# 4.0 1.6 a=13.6 b=3.1 x,y=divmod(a,b) print(x,y)\t# 4.0 1.1999999999999993 应用场景\n进制转换\n1 2 3 4 5 6 7 8 def int_to_base(n, base): digits = [] while n \u0026gt; 0: n, rem = divmod(n, base)\t# 除留余数法 digits.append(rem)\t# 余数先存进去，是低位 return digits[::-1]\t# 逆序 print(int_to_base(42, 16)) # [2, 10] 表示 0x2A 时间单位转换\n1 2 3 4 total_seconds = 7541 hours, rem = divmod(total_seconds, 3600) minutes, seconds = divmod(rem, 60) print(f\u0026#34;{hours}:{minutes}:{seconds}\u0026#34;) # 2:5:41 循环缓冲区处理，类似哈希表的“线性法直接mod”\n1 2 3 4 5 6 buffer_size = 1024 write_pos = 1500 # 计算实际写入位置 chunk, offset = divmod(write_pos, buffer_size) print(f\u0026#34;写入第 {chunk} 个缓冲区的 {offset} 位置\u0026#34;) id id()函数返回对象的唯一标识符，标识符是一个整数。\nCPython 中 id() 函数获取的是对象的内存地址。（python3.9——CPython3.9）\n1 2 3 4 5 a=13 b=3 print(id(a)) # 3054276471472 print(id(b))\t# 3054276471152 print(type(id(a)))\t# \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 拓展：不同的python\n需要最佳兼容性 → CPython （主，兼容性最好，标准）\n与 Java 生态整合 → Jython\n需要 .NET 互操作 → IronPython\n追求高性能 → PyPy\n嵌入式开发 → MicroPython\nobject object()：不接收任何参数，返回一个空对象 1 2 3 4 5 6 x = object() print(dir(x)) # [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, # \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, # \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, # \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;] object() 的核心价值：\n所有类的基类：提供默认行为\n轻量级对象：用于简单场景\n方法继承：提供默认的 __str__、__eq__ 等方法\nsorted sorted() 对 所有可迭代的对象 进行排序操作。\nsort 与 sorted 区别：\nsort 是 list 的方法，sorted 可对所有可迭代的对象应用。\nlist 的 sort 方法返回的是对已经存在的列表进行操作，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。\nsorted(iterable, key=None, reverse=False)，三个参数，依次是 可迭代变量、选择内层元素的函数方法、升序or降序。\n1 2 3 4 ls=[(3,2),(1,4),(5,3),(2,6)] new_ls=sorted(ls,key=lambda x:x[0],reverse=True)\t# 对象为列表 ls，方法是 通过首层元素的第0个元素排序，True-\u0026gt;降序 print(ls)\t# [(3, 2), (1, 4), (5, 3), (2, 6)] print(new_ls)\t# [(5, 3), (3, 2), (2, 6), (1, 4)]\t得到 5 3 2 1 降序 sorted\u0026lt;-\u0026gt;sort reversed\u0026lt;-\u0026gt;reverse\nascii ascii(object) ，返回object的字符串，对于字符串中的非 ASCII 字符则通过 repr() 函数使用 \\x, \\u 或 \\U 编码。\n1 2 3 4 a=[[1,2,3],[3,4,5]] b=ascii(a) print(type(b)) # \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; print(b.split(\u0026#39;,\u0026#39;)) # [\u0026#39;[[1\u0026#39;, \u0026#39; 2\u0026#39;, \u0026#39; 3]\u0026#39;, \u0026#39; [3\u0026#39;, \u0026#39; 4\u0026#39;, \u0026#39; 5]]\u0026#39;] enumerate enumerate(seq, [start=0])\n将seq的元素挨个取出和0,1,2,3\u0026hellip;.组成二元组，各个二元组组成enumerate类型，enumerate不可索引。\n1 2 3 4 5 6 7 8 seasons=[[1,2,3],[4,5,6]] print(type(enumerate(seasons)))\t# \u0026lt;class \u0026#39;enumerate\u0026#39;\u0026gt; for i, element in enumerate(seasons): print(i, element)\t# 0 [1, 2, 3]\t1 [4, 5, 6] for j in enumerate(seasons): print(type(j))\t# \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; print(j[0],j[1])\t# 0 [1, 2, 3] break （主）同时获取索引 i，和元素本身element：\n1 2 for i, element in enumerate(seasons): print(i, element) input input([prompt]) ：在命令行提示prompt，然后接收命令行输入的信息为字符串。\n1 2 a = input(\u0026#34;input:\u0026#34;) type(a) # \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 和strip、map结合\n1 2 3 4 5 6 7 # strip() 去掉文末空格 a=input(\u0026#39;输入：\u0026#39;).strip()\t# 输入“123 ”\t去掉文末空字符 print(len(a))\t# 3 a=input(\u0026#39;输入：\u0026#39;)\t# 输入“123 ”\t不去掉文末空字符 print(len(a))\t# 4 b=list(map(int, input(\u0026#39;输入：\u0026#39;).split())) # 输入“1 2 3”\t输出[1,2,3] 标准空白字符 字符名称 转义序列 空格 \\x20 水平制表符（Tab） \\t 换行符（LF） \\n 回车符（CR）（Mac 换行) \\r 垂直制表符 \\v 换页符 \\f staticmethod @staticmethod 用于定义静态方法的装饰器，返回函数的静态方法。\n1 2 3 4 class C(object): @staticmethod def add(a, b): return a + b 特点：\n代码中的add函数不能有“self”（实例引用）和“cls”类引用 是类命名空间中的函数，不需要实例便可调用 不能直接访问实例属性或类属性，因为无self/cls 静态方法与普通方法对比\n特征 普通方法 静态方法 第一个参数 self（实例引用） 非self非类 调用方式 实例调用 类/实例均可调用 访问权限 可访问实例属性 仅能访问传入参数 1 2 3 4 5 6 7 class MyClass: def normal_method(self): print(f\u0026#34;实例方法：{self}\u0026#34;) # 依赖实例 @staticmethod def static_method(): print(\u0026#34;静态方法\u0026#34;) # 无依赖 bin bin() 输入：一个整数 int 或者长整数 long int。返回：二进制的字符串。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 a=3 print(bin(a))\t# 0b11 print(type(bin(a)))\t# \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; for i in bin(a): print(i)\t# 0\\nb\\n1\\n1\\n help(bin) # bin(number, /) # Return the binary representation of an integer. # # \u0026gt;\u0026gt;\u0026gt; bin(2796202) # \u0026#39;0b1010101010101010101010\u0026#39; open open(name[, mode[, buffering]])\n常与with联用\n1 2 3 4 5 # 例子 with open(\u0026#39;_20_data.txt\u0026#39;, \u0026#39;r\u0026#39;) as file: # 读取数据 N\\n1 2 3 n = int(file.readline().strip()) data = list(map(int, file.read().split())) w从头写 r只读 a追加\n读写方式 是否为 二进制 是否为 可读可写 r 空 空 w b + a 共\t3*2*2=12种\n模式对照表 和 f.seek(n)\n模式 描述 文件存在 文件不存在 指针位置 r+ 读写（文件必须存在） 不清空，从指针位置“覆盖写” 报错 开头 w+ 写读（清空后读写） 必定清空，从指针位置写 创建 开头 a+ 追加读写 必定从末尾写 创建 末尾 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 创建文件 with open(\u0026#39;test_r+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;旧内容\u0026#39;) # r+ try:\t# 不存在改文件会报错 with open(\u0026#39;test_r+.txt\u0026#39;, \u0026#39;r+\u0026#39;) as f: print(f.read()) # 输出: 旧内容^ （^指针位置） f.seek(0)\t# ^旧内容\t（移动指针位置到开头） f.write(\u0026#39;新\u0026#39;) # 新^内容\t（从指针位置覆盖写入） f.seek(0)\t# ^新内容 print(f.read()) # 输出: 新内容 except FileNotFoundError: print(\u0026#34;文件不存在\u0026#34;) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 创建文件 with open(\u0026#39;test_w+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;原始内容\u0026#39;) # w+ with open(\u0026#39;test_w+.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;全新内容\u0026#39;) # 清空后写入 全新内容^ f.seek(0)\t# 移动指针到开头\t^全新内容 print(f.read()) # 输出: 全新内容 # 文件不存在时 import os with open(\u0026#39;new_w+.txt\u0026#39;, \u0026#39;w+\u0026#39;) as f: f.write(\u0026#39;创建内容\u0026#39;)\tf.seek(0) print(os.path.abspath(\u0026#39;new_w+.txt\u0026#39;)) # 输出: 创建的文件的绝对路径 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建文件 with open(\u0026#39;test_a+.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;初始行\\n\u0026#39;) # a+ with open(\u0026#39;test_a+.txt\u0026#39;, \u0026#39;a+\u0026#39;) as f: f.write(\u0026#39;追加行\\n\u0026#39;) # 追加行\\n^ f.seek(0) # ^初始行\\n追加行\\n print(f.read()) # 输出: 初始行\\n追加行\\n # 验证指针特性 f.seek(5) # 初始行\\n追^加行\\n f.write(\u0026#39;中间插入\u0026#39;) # 仍然追加到文件末尾！ f.seek(0) print(f.read()) # 输出: 初始行\\n追加行\\n中间插入 eval eval(表达式的字符串[, globals[, locals]])，执行一个字符串表达式，并返回表达式的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 简单表达式 result = eval(\u0026#34;2 + 3 * 4\u0026#34;) print(result) # 输出: 14 # 变量引用 x = 10 result = eval(\u0026#34;x + 5\u0026#34;) print(result) # 输出: 15 # 指定变量空间 namespace = {\u0026#39;a\u0026#39;: 2, \u0026#39;b\u0026#39;: 3}\t# 必须是字典 result = eval(\u0026#34;a + b\u0026#34;, namespace) print(result) # 输出: 5 eval() 执行代码有安全风险，可能导致代码注入漏洞，并确保仅执行可信任的字符串表达式。 设置命名空间的内置函数和类型 —— __builtins__\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 安全沙箱环境配置 safe_globals = { \u0026#39;__builtins__\u0026#39;: { \u0026#39;abs\u0026#39;: abs, \u0026#39;max\u0026#39;: max, \u0026#39;min\u0026#39;: min, \u0026#39;pow\u0026#39;: pow, \u0026#39;round\u0026#39;: round } } # 安全计算示例 result = eval(\u0026#34;pow(2, 3) + abs(-5)\u0026#34;, safe_globals) # 输出: 13 # 危险操作示例（将被阻止） try: eval(\u0026#34;open(\u0026#39;test.txt\u0026#39;)\u0026#34;, safe_globals) except NameError as e: print(f\u0026#34;安全拦截: {e}\u0026#34;) # 输出: name \u0026#39;open\u0026#39; is not defined 拓展: __builtins__\n1 2 3 4 5 6 7 # 查看内置函数列表 print(dir(__builtins__)) # 输出: [\u0026#39;ArithmeticError\u0026#39;, \u0026#39;AssertionError\u0026#39;, ...,\u0026#39; iter\u0026#39;, \u0026#39;len\u0026#39;, \u0026#39;license\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;locals\u0026#39;, \u0026#39;map\u0026#39;, \u0026#39;max\u0026#39;, \u0026#39;memoryview\u0026#39;, \u0026#39;min\u0026#39;, \u0026#39;next\u0026#39;, \u0026#39;object\u0026#39;, \u0026#39;oct\u0026#39;, \u0026#39;open\u0026#39;, ...] # 调用内置函数 print(__builtins__.len([1,2,3])) # 输出: 3 print(len([1,2,3])) # 等价 int int(x, base=10) -\u0026gt; integer，将一个数字或字符串转为一个int类型数据（10进制）, 如果没有参数返回0。 如果带参数base的话，第一个参数一定要是字符串\n1 2 3 4 5 6 7 8 9 #小数点后直接删了 print(int(3.6))\t# 3 # 如果带参数base的话，第一个参数一定要是字符串。1a为 16进制。 print(int(\u0026#39;1a\u0026#39;,16)) # 26 # int被print时都是10进制，int其他进制字符串转为10进制表示的int print(int(\u0026#39;0xaa\u0026#39;,16))\t# 16 * 10 + 1 * 10 = 70 print(int(\u0026#39;0b110\u0026#39;,2))\t# 4+2=6 int([x]) -\u0026gt; integer，[x]可以是str, bytes, or bytearray 且符合该进制（由base确定）的字面量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 with open(\u0026#39;test.txt\u0026#39;,\u0026#39;wb+\u0026#39;) as f: # 写入bytes类型内容 f.write(b\u0026#39;12\u0026#39;)\tf.seek(0) # 读取bytes byte_ls=f.readline()\tprint(byte_ls)\t# b\u0026#39;12\u0026#39; print(type(byte_ls))\t# \u0026lt;class \u0026#39;bytes\u0026#39;\u0026gt; # 默认10进制转换 int_ls=int(byte_ls)\tprint(int_ls)\t# 12 print(type(int_ls))\t# \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; # 设置为8进制 int_ls=int(byte_ls, 8)\tprint(int_ls)\t# 10 str str(object=\u0026rsquo;\u0026rsquo;)，返回一个对象的字符串。\n1 print(type(str(123)))\t# \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 对比str()和ascii()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dict = {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;} # 转换一些数据结构是一样的 print(str(dict))\t# {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;} print(ascii(dict))\t# {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;} # 对于字符串数据，str不会将\u0026#39;转字符串里，ascii严格转 s = \u0026#39;rooobeam\u0026#39; print(str(s))\t# RUNOOB print(ascii(s))\t# \u0026#39;RUNOOB\u0026#39; # 对于非ASCII字符，str没事，转义为Unicode码点 ss = \u0026#39;阿道夫\u0026#39; print(str(ss))\t# 阿道夫 print(ascii(ss))\t# \u0026#39;\\u963f\\u9053\\u592b\u0026#39; 输出目标 非ASCII字符处理 字符处理 特殊字符转义 主要用途 str 人类可读的字符串 原样 无 仅转义控制字符如\\n 用户友好 ascii Python可解析str Unicode码点(如\\u4e2d) 始终用单引号包裹 转义所有非ASCII字符 调试和安全 bool bool(x) 将给定参数转换为布尔类型，如果没有参数，返回 False。\n1 2 3 print(bool(0))\t# False print(bool(1))\t# Ture print(bool(2))\t# True （bool是int的子类，然并卵。）\nReturns True when the argument x is true, False otherwise.\nexec exec(object[, globals[, locals]])，执行储存在字符串或文件中的 Python 语句，可执行更复杂的 Python 代码。\n1 2 3 4 exec(\u0026#39;\u0026#39;\u0026#39; print(\u0026#34;where you are\u0026#34;) print(\u0026#34;where is love\u0026#34;) \u0026#39;\u0026#39;\u0026#39;) globals，locals类似 eval。\n非常不安全，永远不要执行没有检验过的代码。\n可用__builtins__限制命名空间。\nisinstance isinstance(object, classinfo)——isinstance(实例a, 类A)，判断实例a 是不是 A 或 A的子类 的实例化。\n1 2 3 4 a = 2 isinstance(a,int)\t# True a是int类型 isinstance(a,str)\t# False\ta不是str类型 isinstance(a,(str,int,list)) # True 元组里有a的类型 isinstance() 与 type() 区别：\ntype() 不会认为子类是一种父类类型，不考虑继承关系。 isinstance() 会认为子类是一种父类类型，考虑继承关系。 如果要判断两个类型是否相同推荐使用 isinstance()。\n1 2 3 4 5 6 7 8 a = bool() print(type(a)==int)\t# False # 子类是父类的一种，a是子类则a是父类 print(isinstance(a,int))\t# True # 反之不成立 b = int() print(isinstance(b,bool))\t# False ord、chr ord(c)，c为字符，返回 Unicode 码点 (十进制int) for a one-character string.\n1 2 3 4 print(ord(\u0026#39;a\u0026#39;))\t# 97 print(ord(\u0026#34;a\u0026#34;))\t# 97 print(ord(\u0026#39;€\u0026#39;)) # 8364 print(type(ord(\u0026#39;a\u0026#39;)))\t# int chr(i) ，ord的反向操作 返回一个one-character string 对应输入的unicode码点(十进制int)， 0 \u0026lt;= i \u0026lt;= 0x10ffff (unicode的最大码点).\n1 2 3 print(chr(65)) # \u0026#39;A\u0026#39;（65对应\u0026#39;A\u0026#39;） print(chr(9731)) # \u0026#39;☃\u0026#39;（9731对应雪人符号） print(type(chr(9731)))\t# str sum 对iterable的元素求和\n1 2 3 print(sum([1,2,3]),sum((1,2,3)),sum({1,2,3})) # 6 6 6 print(sum(1,2,3),1)\t# 7\t组计算总和后再加 1 bytes、bytearray 初始化空bytearray、bytes bytearray() -\u0026gt; empty bytes array bytes() -\u0026gt; empty bytes object 1 print(bytearray())\t# bytearray(b\u0026#39;\u0026#39;) 初始化n个 \\x00 bytearray(int) -\u0026gt; bytes array of size given by the parameter initialized with null bytes bytes() -\u0026gt; empty bytes object 1 2 print(bytearray(2))\t# bytearray(b\u0026#39;\\x00\\x00\u0026#39;) print(bytes(2))\t# b\u0026#39;\\x00\\x00\u0026#39; 转换int的可迭代类型（[1,2,3], (1,2,3), {1,2,3}等） bytearray(iterable_of_ints) -\u0026gt; bytearray bytes(iterable_of_ints) -\u0026gt; bytes 1 2 3 # 每个int范围 in range(256) print(bytearray([1,2,3,4]))\t# bytearray(b\u0026#39;\\x01\\x02\\x03\\x04\u0026#39;) print(bytes([1,2,3,4]))\t转换字符串类型 1 2 a=bytearray(\u0026#39;八寸\u0026#39;, \u0026#39;utf-8\u0026#39;) print(a)\t# bytearray(b\u0026#39;\\xe5\\x85\\xab\\xe5\\xaf\\xb8\u0026#39;) bytes、bytearray、memoryview 和其他自定义的缓冲区对象间相互转换 bytearray(bytes_or_buffer) -\u0026gt; mutable copy of bytes_or_buffer bytes(bytes_or_buffer) -\u0026gt; immutable copy of bytes_or_buffer 1 2 3 a=b\u0026#34;abc\u0026#34;\t# bytes类型 b=bytearray(a) print(b)\t# bytearray(b\u0026#39;abc\u0026#39;)\tbytearray类型 对比。\n不同：\n是否可修改\n使用 b\u0026rsquo;\u0026rsquo; 或 bytes() 创建还是使用 bytearray() 创建\nfile.read()得出的是bytes\n相同：\n存储内容：都存储字节数据（0到255之间的整数，\\x00~\\xff）。\n二进制数据：都适合处理二进制数据，如文件、网络通信等。\n索引和切片：都支持通过索引和切片访问数据。\n1 2 3 4 5 6 7 8 9 10 11 4ea=bytearray(\u0026#39;abc\u0026#39;, \u0026#39;utf-8\u0026#39;) b=bytes(\u0026#34;ABC\u0026#34;,\u0026#39;utf-8\u0026#39;) print(a[0])\t# 97 a[0]=65 print(a[0])\t# 65 try: b[0]=97 except Exception as e: print(f\u0026#34;{e}\u0026#34;)\t# \u0026#39;bytes\u0026#39; object does not support item assignment filter filter(function or None, iterable) \u0026ndash;\u0026gt; filter object filter 函数用于过滤序列，过滤掉不符合条件的元素，返回一个filter对象。接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判断，函数需返回 True 或 False，最后将返回 True 的元素放到filter中。 1 2 3 4 5 6 def is_odd(n): return n % 2 == 1 a = filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) b = list(a) print(b)\t# [1, 3, 5, 7, 9] 如果function那里填了None，则返回非空元素。 1 2 3 a = filter(None ,[1, 2, 0, 4, \u0026#39;\u0026#39;, 6]) b = list(a) print(b)\t# [1, 2, 4, 6] filter 对象是惰性求值的，这点类似于生成器。\n一旦迭代过 filter 对象，其内容就会被消耗，无法再次使用。\n如果需要多次访问，可转换为列表或其他可迭代对象。\n1 2 3 4 5 6 7 8 def is_odd(n): return n % 2 == 1 a = filter(is_odd, [1, 2, 3]) for i in a: print(i)\t# 1\\n3\\n b=list(a) print(b)\t# [] issubclass issubclass(class1, class2)，判断 class1 是否为 class2 的子类。 1 2 3 4 5 6 class A: pass class B(A): pass print(issubclass(B,A)) # True pow pow(base, exp, mod=None)\tpow(底数，指数，模数=None)\n两个参数时，得到 base**exp，三个参数时，得到 base**exp % mod\n对于一些类型的参数如int型参数它能算得更快。\n1 2 3 4 5 6 7 # 两个参数 print(pow(2,3))\t# 8 print(pow(2.5,2))\t# 6.25 print(pow(2,2.5))\t# 5.656854249492381 # 三个参数 print(pow(2,34,13))\t# 10 super 一句话概括：调用父类方法，改变传入实例。\nsuper(class, obj )，class——指定从哪个类开始查找父类方法，obj——传入的对象\n译为 创建一个 传入了对象obj的 可调用class的父类的方法的 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Parent: def greet(self): print(\u0026#39;Parent\u0026#39;) class Child(Parent): def greet(self): print(\u0026#39;Child\u0026#39;) def react(self): print(\u0026#39;c\u0026#39;) # 在类外部调用父类方法 c = Child() super(Child, c).greet() # Parent 在一个类里，super()=super(当前类, self)，会自动绑定当前类和实例(self)，适用于类方法中。\n译为 创建一个 传入了self的 可调用当前类的父类的方法的 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Parent(object): def __init__(self): # 定义传入的对象的属性 self.parent = \u0026#39;I\\\u0026#39;m the parent.\u0026#39;\t# 证明执行__init__方法的语句 print (\u0026#39;Parent\u0026#39;) def bar(self, message): # 证明可调用其他方法如bar print (\u0026#34;%s from Parent\u0026#34; % message) class Child(Parent): def __init__(self): # 调用parent的初始化函数，如继承父类属性 super().__init__() print (\u0026#39;Child\u0026#39;) def bar(self, message): super(Child, self).bar(message) print (\u0026#39;Child bar fuction\u0026#39;) print (self.parent) if __name__ == \u0026#39;__main__\u0026#39;: Child = Child() Child.bar(\u0026#39;HelloWorld\u0026#39;) # 输出 # Parent # Child # HelloWorld from Parent # Child bar fuction # I\u0026#39;m the parent. 可不可以理解为 super(Child,self) 首先找到 Child 的父类（Parent），然后把类 Child 的对象转换为类 Parent 的对象？ —— False\n可能会发生死循环吗？ —— True\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Parent: def __init__(self): # Parent 对象必有a属性 self.a=123\tdef react(self): self.react() class Child(Parent): def react(self): super().react() # 证明不是Parent的对象 try: print(b.a) except Exception as e: print(f\u0026#34;{e}\u0026#34;)\t# \u0026#39;super\u0026#39; object has no attribute \u0026#39;a\u0026#39; # 证明死循环 c = Child() b=super(Child, c) try: super(Child, c).react() except Exception as e: print(f\u0026#34;{e}\u0026#34;)\t# maximum recursion depth exceeded 多重继承问AI float 将一个字符串或整数转为浮点数\n1 2 3 float(123)\t# 123.0 float(\u0026#39;123\u0026#39;)\t# 123.0 float(\u0026#39;123.123\u0026#39;)\t# 123.123 iter iter() 用于获取可迭代对象的迭代器，两种传参：(iterable) 、(callable, sentinel)\niter(iterable) -\u0026gt; iterator\t传入可迭代对象，如列表、字符串，转为iter.\n（“给对象生成__iter__() 和 __next__()”）\n1 2 3 4 5 6 7 8 9 10 11 12 # 配合 next() 逐步获取元素时应用 a=iter(\u0026#34;123\u0026#34;) print(next(a))\t# 1 print(next(a))\t# 2 print(next(a))\t# 3 # iterator 惰性计算 print(list(a))\t# [] # 在for循环中隐式调用 a=iter(\u0026#34;123\u0026#34;) for i in a: print(i) iter(callable, sentinel) -\u0026gt; iterator，重复调用无参函数callable，直到其返回值等于sentinel（哨兵值）时停止 1 2 3 4 5 6 7 8 import random def get_random(): return random.randint(1, 10) it = iter(get_random, 7) for num in it: print(num) # 持续输出随机数，直到出现7时停止 拓展（__iter__）\nPython 的迭代器：实现 __iter__() 和 __next__() 方法的对象被视为迭代器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Counter: def __init__(self, low, high): self.current = low self.high = high def __iter__(self): return self def __next__(self): if self.current \u0026gt; self.high: raise StopIteration else: self.current += 1 return self.current - 1 # 使用 counter = Counter(1, 3) for num in counter: print(num) # 输出1, 2, 3 以后遇到了再补充了 print print(value, \u0026hellip;, sep=\u0026rsquo; \u0026lsquo;, end=\u0026rsquo;\\n\u0026rsquo;, file=sys.stdout, flush=False)\nsep间隔 默认一个空格，print完成后补充内容 默认一个换行符，输出文件 默认控制台，是否刷新缓存默认否。\n1 2 3 4 5 6 # sep print(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, sep=\u0026#34;, \u0026#34;)\t# apple, banana, cherry # end for i in range(3): print(i, end=\u0026#34; | \u0026#34;) # 0 | 1 | 2 | （同一行） tuple tuple(iterable=(), /)，将可迭代对象转为元组类型，元组数据不可修改。 1 2 a=tuple([1,2,3]) print(a)\t# (1,2,3) 判断是否为可迭代对象 1 2 a=[1,2,3] print(\u0026#39;__iter__\u0026#39; in dir(a))\t# True callable callable（可调用对象）是指任何可以通过 () 运算符调用的对象。例如：函数、方法、类，或者实现了 call 方法的对象，是否具有__call__ 1 2 3 4 5 6 7 8 # 用 def 或 lambda 定义的函数是callable def greet(): print(\u0026#34;Hello!\u0026#34;) add = lambda x, y: x + y print(callable(greet))\t# True print(callable(add))\t# True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 类本身是 callable （类可被调用来创建实例，但对象未必） class A: pass a=A() print(callable(A))\t# True print(callable(a))\t# False # 类里定义了__call__，这样得到的对象是callable （能实现b()） class B: def __call__(self): return 0 b=B() print(callable(b))\t# True print(b())\t# 0 1 2 3 4 5 6 7 8 9 # 对象的方法是 callable class A: def react(self): print(\u0026#34;great!\u0026#34;) a = A() print(callable(a.react))\t# True\t# a.react()不是callable，方法react没有返回一个有__call__的对象 print(callable(a.react())\t# False\t拓展：类装饰器（通过 __call__ 实现） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class countcalls: def __init__(self, func): self.func = func self.count = 0 def __call__(self, *args, **kwargs): # 类实例成为 Callable self.count += 1 print(f\u0026#34;函数已被调用 {self.count} 次\u0026#34;) return self.func(*args, **kwargs) @CountCalls # 装饰器相当于：say_hello=countcalls(say_hello) def say_hello(): print(\u0026#34;Hello!\u0026#34;) say_hello() # 输出：函数已被调用 1 次 → Hello! say_hello() # 输出：函数已被调用 2 次 → Hello! format、f-string 基础用法：基本替换、位置索引、传递变量值 1 2 3 4 5 6 7 8 9 10 11 12 13 # format text = \u0026#34;{} is {}\u0026#34;.format(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;) print(text) # a is b text=\u0026#34;{1} is {0}\u0026#34;.format(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;) print(text) # b is a c=123 text=\u0026#34;hi,{}\u0026#34;.format(c)\t# hi,123 ls=[\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;] text=\u0026#34;{0[0]} {0[1]}\u0026#34;.format(ls) print(text)\t# 1 2 1 2 3 # f-string name=八寸 text=f\u0026#34;i love {name}\u0026#34; 常用控制格式：小数位数、进制转换、小数转百分比\n特别是\tf\u0026quot;{num:2f}\u0026quot;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 小数位数控制 decimal=123.125 a=\u0026#34;2位：{decimal:.2f}\u0026#34; b=\u0026#34;3位：{:3f}\u0026#34;.format(decimal) # 进制 n = 255 print(\u0026#34;二进制: {:b}\u0026#34;.format(n)) # 二进制: 11111111 print(\u0026#34;十六进制: {n:x}\u0026#34;) # 十六进制: ff print(\u0026#34;十进制: {n:d}\u0026#34;) # 十进制: 255 print(\u0026#34;八进制: {:o}\u0026#34;.format(n)) # 八进制: 377 # 小数转百分比，百分号要放大括号{}里 rate = 0.8523 a = \u0026#34;完成度: {rate:.2%}\u0026#34; # 取整百分比 b= \u0026#34;完成度: {:.2}%\u0026#34;.format(rate) print(a) # 输出：完成度: 85.23% print(b) # 输出：完成度: 0.85% format或f-string下大括号用{{}}(双重大括号) 1 2 text = \u0026#34;格式占位符: {{}}\u0026#34;.format() print(text) # 格式占位符: {} 其他对齐、填充啥的要用再查就好了，太没用了 len 求各种序列的长度\n数据类型 len() 结果 字符串 字符个数（包括空格 \u0026quot; \u0026ldquo;、 \\t、\\n 等） 列表/元组 元素数量 字典 键值对数量 集合 元素数量 字节/字节数组 字节数量 自定义对象 取决于 __len__() 方法的实现 1 2 3 4 5 text = \u0026#34;Hello, 世界!\\n\u0026#34; # 包含英文、中文、符号、换行符 print(len(text)) # 11 ls=[[],[]] print(len(ls)) # 2 property property 的核心用途是将类的方法转换为“虚拟属性”，1 将方法伪装成\u0026quot;属性\u0026rdquo;， 优雅地控制\u0026quot;属性\u0026quot;。\n@property\t@ method.setter\t@method.deleter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Circle: def __init__(self, radius): self._radius = radius # 私有变量 self._pi = 3.141592653589793 @property # 通过方法返回变量，起到保护_radius作用（只读） def radius(self): return self._radius @property # 实时计算面积area def area(self): return self._pi*(self._radius**2) @radius.setter # 控制radius的修改 def radius(self, value): if value \u0026lt; 0: raise ValueError(\u0026#34;半径不能为负\u0026#34;) self._radius = value # 合法时存储 @radius.deleter # 控制radius的删除 def radius(self): print(\u0026#34;禁止删除半径！\u0026#34;) c = Circle(5) print(c.radius) # 5 print(c.area)\t# 78.53981633974483 对比 \u0026ldquo;.\u0026rdquo; 访问属性 和 使用property 场景 直接访问属性 使用 property 优势对比说明 数据校验 ❌ 无法验证 ✅ 通过 setter 控制 避免非法值赋值（如负半径） 动态计算属性值 ❌ 需手动计算 ✅ 实时计算（如 面积 = πr²） 属性值随依赖变量自动更新，无需额外调用方法 隐藏内部实现 ❌ 暴露变量名 ✅ 封装私有变量（如 _radius） 保护内部数据命名，外部仅通过属性接口访问 接口兼容性 ❌ 修改变量名会破坏外部调用 ✅ 外部仍用 obj.x，内部可自由修改 内部变量名可重构（如 _radius → _r），不影响外部调用，减少代码耦合性 type type(object) -\u0026gt; the object\u0026rsquo;s type\t返回对象的type，打印type会显示\u0026lt;\u0026hellip;.\u0026gt; 1 2 print(type(5)) # \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; print(type(\u0026#34;hello\u0026#34;)) # \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 是否考虑继承关系：type不承认，isinstance() 会认为子类是一种父类类型。\n即“a是A的实例，a是A的父类的实例吗”\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class A: pass class B(A): pass a=A() b=B() # 是子类 则 是父类 print( isinstance(B(), A) ) # True # 不承认 是子类则是父类 print( type(a) == type(b) ) # False # 是父类 不能判定 是子类 print( isinstance(A(), B) ) # False type(name, bases, dict, **kwds) -\u0026gt; a new type，了解，遇到了再补充 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 定义方法 def __init__(self, name): self.name = name def bark(self): return \u0026#34;Woof!\u0026#34; # 动态创建类 Dog = type( \u0026#39;Dog\u0026#39;, (), # 基类为空（默认继承 object） { \u0026#39;__init__\u0026#39;: __init__, \u0026#39;species\u0026#39;: \u0026#34;Canis familiaris\u0026#34;, \u0026#39;bark\u0026#39;: bark } ) set 集合 set() -\u0026gt; new empty set object 创建空集合，注意A={}创建的是空字典 1 2 3 4 a=set() b={} print(type(a),type(b))\t# \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; print(a,b)\t# set() {} set(iterable) -\u0026gt; new set object\t将可迭代数据变为集合，能起到去重效果 1 2 3 4 5 6 7 ls=[1,2,3,2] ns=set(ls) print(ns)\t# {1, 2, 3} s=\u0026#34;rooobeam\u0026#34; ns=set(s) print(ns)\t# {\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;m\u0026#39;} 集合推导式 和 直接初始化 1 2 3 4 5 a={x for x in range(5)} print(a)\t# {0, 1, 2, 3, 4} b={1,2,3} print(b)\t# {1, 2, 3} 集合对象的方法 方法 作用 返回值/行为 add(element) 添加单个元素 原地修改集合，无返回值 remove(element) 删除指定元素（元素不存在时报错） 原地修改集合，元素不存在时抛 KeyError discard(element) 删除指定元素（元素不存在时不报错） 原地修改集合，无返回值 clear() 清空集合 原地清空集合，无返回值 s.update({4, 5}) → s 包含新元素 合并多个集合（原地修改） 原地修改集合，无返回值 s1.intersection_update(s2) 原地保留交集（仅保留共同元素） 原地修改集合，无返回值 s1.difference_update(s2) 原地保留差集（移除其他集合的元素） 原地修改集合，无返回值 s1.isdisjoint(s2) → True/False 判断两个集合是否无交集 返回 True/False s2 = s1.copy() → 生成独立副本 浅拷贝集合 返回新集合的浅拷贝（与原集合独立） frozenset 直译为 冻结集合\nfrozenset() -\u0026gt; empty frozenset object\n（ 空 frozenset 最重要的作用是 作为安全的不可变默认值，避免使用可变空集合如 set()时，因意外修改导致的程序逻辑错误 ）\n1 print(frozenset())\t# frozenset() frozenset(iterable) -\u0026gt; frozenset object\nBuild an immutable unordered collection of unique elements.\n创建一个 不可修改的 无序的 元素collection，元素有唯一性。\n将 可迭代数据 变成一个 冻结的集合\n1 2 3 4 5 6 7 ls=[1,2,3,2] fs=frozenset(ls) print(fs)\t# frozenset({1,2,3}) s=\u0026#34;hello\u0026#34; fs=frozenset(s) print(fs)\t# frozenset({\u0026#39;e\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;l\u0026#39;}) frozenset({A, B})类似一个“组合值”，可以作为字典的键或集合的元素（可哈希性） 1 2 3 4 5 6 7 fs = frozenset({1, 2}) dict = {fs: \u0026#34;1, 2\u0026#34;} print(dict[fs])\t# 1, 2 fs_set={fs,1} print(fs_set)\t# {1, frozenset({1, 2})} 支持集合操作 作用 方法 返回并集 fs1.union(fs2) → 同 `fs1 返回交集 fs1.intersection(fs2) → 同 fs1 \u0026amp; fs2 返回差集（A - B） fs1.difference(fs2) → 同 fs1 - fs2 判断是否为子集 fs1.issubset(fs2) → False 返回副本（与原对象相同） fs2=fs.copy() → 新 frozenset list list(iterable=(), /), 函数/操作 作用 示例 定义列表 创建列表 my_list = [1, \u0026quot;a\u0026quot;, True] 索引 访问单个元素（支持正负索引） my_list[0]，my_list[-1] 切片 截取子列表 my_list[1:3] 直接赋值 修改单个元素 my_list[0] = 100 切片赋值 修改或替换子列表 my_list[1:2] = [200, 300] append(x) 在末尾添加单个元素 list = [1,2]; list.append(3) extend(iterable) 合并可迭代对象到末尾 list = [1,2]; list.extend([3,4]) → [1,2,3,4] del list[0:2] 删除元素 list = [1,2,3]; del list[1] → [1,3] 列表推导式 生成列表 y=[x if x\u0026gt;1 else -1 for x in [1,2,3] ] sort() 原地排序 list = [3,1,2]; list.sort() reverse() 原地反转列表顺序 list = [1,2,3]; list.reverse() copy() 创建浅拷贝列表 new_list = list.copy() count(x) 统计元素 x 的出现次数 list = [1,2,2,3]; list.count(2) -\u0026gt; 2 index(x) 返回 x 第一次出现的索引 list = [1,2,2,3]; list.index(2) -\u0026gt; 1 浅拷贝 复制外层对象（嵌套共享引用） a = [[1,2],3]; b = a.copy() len(list) 返回列表长度 len([1,2,3]) max(list) 返回最大值 max([1,3,2]) min(list) 返回最小值 min([1,3,2]) sum(list) 对数值列表求和 sum([1,2,3]) any(list) 检查是否存在为 True 的元素 any([0, False, 1]) all(list) 检查是否所有元素为 True all([1, True, 0]) enumerate(list) 返回索引-值对的迭代器 list(enumerate([\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;])) 列表推导式 enumerate 同时获取 索引和元素 1 2 3 ls=[\u0026#34;i\u0026#34;,\u0026#34;love\u0026#34;,\u0026#34;you\u0026#34;] for i,elem in enumerate(ls): print(i,elem,end=\u0026#39; \u0026#39;)\t# 0 is i 1 is love 2 is you range range(end) -\u0026gt; [0, end,1) “从0开始，到end之前，包括0不包括end，步长为1” 1 2 for number in range(6): print(number,end=\u0026#39; \u0026#39;)\t# 0 1 2 3 4 5 range(start, end, step) -\u0026gt; [start, end, step) “从start开始，到end之前，包括start不包括end，步长为step” 1 2 for number in range(1, 6, 2): print(number,end=\u0026#39; \u0026#39;)\t# 1 3 5 range(start, end, -1) -\u0026gt; [start, end, -1) 从大到小的range，step为负值，start必须\u0026gt;=end 1 2 for number in range(6, 1, -2): print(number,end=\u0026#39; \u0026#39;)\t# 6 4 2 classmethod classmethod是一种装饰器，用于**@classmethod定义类方法**。 方法类型 装饰器 首个参数 访问权限 典型场景 实例方法 无 self 实例属性、类属性 操作实例数据 类方法 @classmethod cls 类属性、其他类方法 工厂方法、操作类状态 静态方法 @staticmethod 无 无法访问类属性、实例属性 工具函数，与类逻辑相关但不依赖数据 用于需要访问或修改类状态。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class A(object): bar = 1 def func1(self): print (\u0026#39;hi\u0026#39;) @classmethod def func2(cls): print (\u0026#39;func2\u0026#39;) # 访问类属性 print (cls.bar) # 调用 类中的普通方法 cls().func1() A.func2() # 不需要实例化 实现工厂模式 —— 类方法创建对象，比如，根据文件扩展名（如.json、.xml、.csv）创建相应的解析器对象，封装了 所支持的格式 的 类属性、获取特定格式对象 的 类方法。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Parser: _supported_formats = [\u0026#34;.json\u0026#34;, \u0026#34;.xml\u0026#34;, \u0026#34;.csv\u0026#34;] @classmethod def create_parser(cls, file_path): # 访问类属性获取支持格式 for fmt in cls._supported_formats: if file_path.endswith(fmt): return cls._get_parser_by_format(fmt) raise ValueError(\u0026#34;Unsupported format\u0026#34;) @classmethod def _get_parser_by_format(cls, fmt): # 调用其他类方法 if fmt == \u0026#34;.json\u0026#34;: return JsonParser() elif fmt == \u0026#34;.xml\u0026#34;: return XmlParser() elif fmt == \u0026#34;.csv\u0026#34;: return CsvParser() # 调用 parser = Parser.create_parser(\u0026#34;data.json\u0026#34;) repr repr(obj, /)\t返回对象的规范字符串，用于明确描述对象状态。\n始终为自定义类定义__repr__，避免默认的\u0026lt;ClassName object at 0x...\u0026gt;输出。优先使用\nf-string生成返回值。\nprint()时 或 交互式环境中输入对象名时（如\u0026gt;\u0026gt;\u0026gt; obj） 调用obj的__repr__输出相关信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class A: def __init__(self, x): self.x = x def __repr__(self): return f\u0026#34;x={self.x}\u0026#34; # 明确且可还原的表示 a = A(3) print(a) # x=3 print(repr(a)) # x=3 class B: def __init__(self, x): self.x = x b=B(7) print(b)\t# \u0026lt;__main__.B object at 0x000001893F4A6E80\u0026gt; zip zip(*iterables) ，*iterables表名可有多个可迭代对象，返回一个元素为元组的 zip 对象，以最短的可迭代对象为终点。 1 2 3 4 5 6 7 8 9 10 a = [1,2,3] b = [4,5,6] c = [4,5,6,7,8] zip_ab = zip(a,b) print(list(zip_ab)) # [(1, 4), (2, 5), (3, 6)] # 元素个数与最短的列表一致 zip_ac = zip(a,c) print(list(zip_ac)) # [(1, 4), (2, 5), (3, 6)] 其他： N个iterable的则N元组， 惰性计算类似生成器、iter()，过一遍就没了 zip(*) 解压 1 2 3 4 5 6 7 8 9 10 11 12 13 14 a=[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;] b=[1,2,3,4] c=[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;,\u0026#39;D\u0026#39;] # a,b,c -\u0026gt; 三元组 zip_abc=zip(a,b,c) print(list(zip_abc))\t# [(\u0026#39;a\u0026#39;, 1, \u0026#39;A\u0026#39;), (\u0026#39;b\u0026#39;, 2, \u0026#39;B\u0026#39;), (\u0026#39;c\u0026#39;, 3, \u0026#39;C\u0026#39;)] # 过一遍就没了，要重生成 print(list(zip_abc))\t# [] # 与 zip 相反，zip(*) 可理解为解压， aa, bb, cc = zip(*zip_abc) print(aa,bb,cc)\t# (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;) (1, 2, 3) (\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;) 把各个迭代对象压缩在一起，可以一起遍历，且惰性计算。（占空间小） map map(func, *iterables)\t创建一个迭代器(map)，存有各可迭代对象的参数依次执行函数计算的结果，当最短的可迭代对象耗尽时终止。 数据值处理 1 2 3 4 5 a=[1,2,3,4] b=[10,20,30,40] map_ab=map(lambda x,y:x+y,a,b) for i in map_ab: print(i,end=\u0026#39; \u0026#39;)\t# 11 22 33 44 数据类型处理，用上各种内置函数如int list str，但不括号 1 2 3 4 5 6 7 # 输入1 2，输出1 2，输入小数也会转为int类型 a,b = map(int, input().split()) print(a,b) # 字母大写 m = map(str.upper, [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;]) print(list(m)) # [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;] reversed reversed(sequence, /) Return a reverse iterator over the values of the given sequence. 迭代器类型，占用空间没那么大，惰性计算，过一遍就没了\u0026hellip; 注意要加\u0026rsquo;d\u0026rsquo; reversed 1 2 3 a=[1,2,3] b=reversed(a) print([e for e in b])\t# [3,2,1] -更常用的方式：[::-1]。但得是可切片型数据，即要有__getitem__方法\n1 2 3 ls = [1,2,3] new_ls=ls[::-1] print(new_ls)\t# [3,2,1] import_module 动态导入模块，尤其是在需要根据运行时条件（如配置文件、用户输入、插件系统等）决定加载哪些模块。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from importlib import import_module # 根据配置(字典)选择模块 config = {\u0026#34;DATABASE\u0026#34;: \u0026#34;mysql\u0026#34;} # 可能的值: \u0026#34;mysql\u0026#34;, \u0026#34;postgresql\u0026#34;, \u0026#34;sqlite\u0026#34; db_module = import_module(f\u0026#34;database.{config[\u0026#39;DATABASE\u0026#39;]}\u0026#34;) # main.py 中动态导入 utils # 目录结构 # mypackage / # |_ __init__.py # |_ utils.py # |_ main.py utils = import_module(\u0026#34;.utils\u0026#34;, package=\u0026#34;mypackage\u0026#34;) # package 参数指定了相对导入的基准包（即 . 的起点），package=\u0026#34;mypackage\u0026#34;， # 则 .utils 表示 mypackage.utils # 加载 plugins 目录下的所有插件 plugin_names = [\u0026#34;plugin1\u0026#34;, \u0026#34;plugin2\u0026#34;] # 可动态扫描目录获取 plugins = [] for name in plugin_names: plugin = import_module(f\u0026#34;plugins.{name}\u0026#34;) complex complex([real[, imag]])，返回复数 1 2 3 4 5 6 7 8 9 10 11 12 a=complex(1, 2)\tprint(a)\t# (1 + 2j) a=complex(1) print(a) # (1 + 0j) a=complex(\u0026#34;1\u0026#34;) print(a)\t# (1 + 0j) # 注意：这个地方在\u0026#34;+\u0026#34;号两边不能有空格，也就是不能写成\u0026#34;1 + 2j\u0026#34;，应该是\u0026#34;1+2j\u0026#34;，否则会报错 a=complex(\u0026#34;1+2j\u0026#34;) print(a)\t# (1 + 2j) hasattr hasattr(obj, name, /) Return whether the object has an attribute with the given name.\nhasattr(检查对象, 名字)\n检查对象（类实例、类、模块等）是否有 指定的 属性/方法，返回True/False\n属性/方法：字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 检查属性是否存在 class A: def __init__(self, name): self.name = name a = A(\u0026#34;Alice\u0026#34;) print(hasattr(a, \u0026#34;name\u0026#34;)) # 输出: True print(hasattr(a, \u0026#34;age\u0026#34;)) # 输出: False # 检查方法是否存在 class B: def add(self, a, b): return a + b print(hasattr(B, \u0026#34;add\u0026#34;)) # 输出: True print(hasattr(B, \u0026#34;multiply\u0026#34;)) # 输出: False 复习getattr、setattr rooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\nrooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\nrooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\trooobeam • 著\n10000词！\n","date":"2025-03-24T00:00:00Z","image":"https://rooobeam.github.io/p/python3%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/rz0sefu53fe_hu_359b55b65c1f5167.webp","permalink":"https://rooobeam.github.io/p/python3%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/","title":"Python3内置函数"},{"content":"项目 目的 极简版 得到 文本块，处理为 实体 和 关系\na. 文本块（chunks） 文本内容：\u0026ldquo;Alice and Bob are collaborating on quantum computing research.\u0026rdquo; 来源id：doc-1 b. 实体（entities） 实体名称 类型 描述 来源 Alice person 量子物理领域的研究员 doc-1 Bob person 数学家 doc-1 Quantum Computing technology 利用量子力学现象进行计算的技术 doc-1 c. 关系（relationships） 关系编号 起点（src_id） 终点（tgt_id） 描述 关键词 权重 来源 1 Alice Bob Alice和Bob是研究伙伴 collaboration, research 1.0 doc-1 2 Alice Quantum Computing Alice从事量子计算研究 research, expertise 1.0 doc-1 3 Bob Quantum Computing Bob研究量子计算的应用 research, application 1.0 doc-1 项目结构 边看边更新\nLightRAG-main |__examples |\t|__lightrag_ollama_demo.py | |__lightrag |\t|__ kg |\t|\t|__ json_kv_impl.py |\t| |\t|__ __init__.py |\t|__ base.py |\t|__ lightrag.py |\t|__ utils.py | | |__setup.py | |\nmain()开始\t（lightrag_ollama_demo.py）\nmain()内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def main(): # Initialize RAG instance rag = asyncio.run(initialize_rag()) # Insert example text with open(\u0026#34;./book.txt\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: rag.insert(f.read()) # Test different query modes print(\u0026#34;\\nNaive Search:\u0026#34;) print( rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=\u0026#34;naive\u0026#34;) ) ) print(\u0026#34;\\nLocal Search:\u0026#34;) print( rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=\u0026#34;local\u0026#34;) ) ) print(\u0026#34;\\nGlobal Search:\u0026#34;) print( rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=\u0026#34;global\u0026#34;) ) ) print(\u0026#34;\\nHybrid Search:\u0026#34;) print( rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=\u0026#34;hybrid\u0026#34;) ) ) # stream response resp = rag.query( \u0026#34;What are the top themes in this story?\u0026#34;, param=QueryParam(mode=\u0026#34;hybrid\u0026#34;, stream=True), ) if inspect.isasyncgen(resp): asyncio.run(print_stream(resp)) else: print(resp) 初始化: rag = asyncio.run(initialize_rag()) 进入initialize_rag()，\t（lightrag_ollama_demo.py）\n1 2 3 4 5 async def initialize_rag(): rag = LightRAG(...........)\tawait rag.initialize_storages() await initialize_pipeline_status() return rag rag = LightRAG(\u0026hellip;\u0026hellip;\u0026hellip;..) （lightrag_ollama_demo.py）\n初始化 LightRAG的对象 各个属性，主要是llm_model_X和embedding_func，两个模型均由本例ollama提供\n显式传入的参数是__init__里的，它还有__post_init__。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 rag = LightRAG(\t# lightrag_ollama_demo.py - line 22 working_dir=WORKING_DIR, llm_model_func=ollama_model_complete, llm_model_name=\u0026#34;deepseek-r1:7b\u0026#34;, llm_model_max_async=4, llm_model_max_token_size=32768, llm_model_kwargs={ \u0026#34;host\u0026#34;: \u0026#34;http://localhost:6006\u0026#34;,\t# 本地ollama提供服务的端口为6006 \u0026#34;options\u0026#34;: {\u0026#34;num_ctx\u0026#34;: 32768}, }, embedding_func=EmbeddingFunc( embedding_dim=768, max_token_size=8192, func=lambda texts: ollama_embed( texts, embed_model=\u0026#34;nomic-embed-text\u0026#34;, host=\u0026#34;http://localhost:6006\u0026#34; ), ), ) await rag.initialize_storages() （lightrag_ollama_demo.py）\n每个storages的初始化都类似，其父类都时base里的Base\u0026hellip;Storage\nkg文件夹里的 各种_impl里定义具体的子类（如JsonDocStatusStorage） 继承了父类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 async def initialize_storages(self):\t# lightrag.py - line 456 \u0026#34;\u0026#34;\u0026#34;Asynchronously initialize the storages\u0026#34;\u0026#34;\u0026#34; # StoragesStatus.CREATED即\u0026#39;created\u0026#39; str # self._storages_status什么时候定义的？默认值？ # 答：__post_init__里定义的。 # __post_init__ 是 @dataclass 提供的一个特殊方法 # \u0026#34;第二初始化\u0026#34;，在自动__init__后执行 # 用于在对象初始化完成后执行额外的操作。 # post 是拉丁语前缀，表示“在……之后” if self._storages_status == StoragesStatus.CREATED: tasks = [] # ====== 此时跳到下一个三级标题查看__post_init__的内容 ====== for storage in ( self.full_docs, self.text_chunks, self.entities_vdb, self.relationships_vdb, self.chunks_vdb, self.chunk_entity_relation_graph, self.llm_response_cache, self.doc_status, ): if storage: # 每个存储模块的初始化 tasks.append(storage.initialize()) await asyncio.gather(*tasks) # 修改self._storages_status self._storages_status = StoragesStatus.INITIALIZED logger.debug(\u0026#34;Initialized Storages\u0026#34;) __post_init__ （lightrag.py）\n由于使用了@dataclass，故__init__自动实现了，而要内部再init则用__post_init__\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def __post_init__(self): from lightrag.kg.shared_storage import ( initialize_share_data, ) ... # Initialize all storages self.key_string_value_json_storage_cls: type[BaseKVStorage] = self._get_storage_class(self.kv_storage) # type: ignore self.vector_db_storage_cls: type[BaseVectorStorage] = self._get_storage_class( self.vector_storage ) # type: ignore self.graph_storage_cls: type[BaseGraphStorage] = self._get_storage_class( self.graph_storage ) # type: ignore self.key_string_value_json_storage_cls = partial( # type: ignore self.key_string_value_json_storage_cls, global_config=global_config ) ... # line 429 self._storages_status = StoragesStatus.CREATED 这里初始化了各个组件的，调用各种模块\n就拿self.full_docs举例而言，它是 BaseKVStorage的实例化，该实例的初始化，由key_string_value_json_storage_cls 类 传入 namespace和embedding_func返回\ninitialize_pipeline_status() （shared_storage.py）\n初始化pipeline的各种状态值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async def initialize_pipeline_status(): \u0026#34;\u0026#34;\u0026#34; Initialize pipeline namespace with default values. This function is called during FASTAPI lifespan for each worker. \u0026#34;\u0026#34;\u0026#34; pipeline_namespace = await get_namespace_data(\u0026#34;pipeline_status\u0026#34;) # _manager.list() async with get_internal_lock(): # 通过检查必要字段，判断是否已经初始化 if \u0026#34;busy\u0026#34; in pipeline_namespace: return # Create a shared list object for history_messages history_messages = _manager.list() if is_multiprocess else [] pipeline_namespace.update( { \u0026#34;busy\u0026#34;: False, # Control concurrent processes \u0026#34;job_name\u0026#34;: \u0026#34;Default Job\u0026#34;, # Current job name (indexing files/indexing texts) \u0026#34;job_start\u0026#34;: None, # Job start time \u0026#34;docs\u0026#34;: 0, # Total number of documents to be indexed \u0026#34;batchs\u0026#34;: 0, # Number of batches for processing documents \u0026#34;cur_batch\u0026#34;: 0, # Current processing batch \u0026#34;request_pending\u0026#34;: False, # Flag for pending request for processing \u0026#34;latest_message\u0026#34;: \u0026#34;\u0026#34;, # Latest message from pipeline processing \u0026#34;history_messages\u0026#34;: history_messages, # 使用共享列表对象 } ) direct_log(f\u0026#34;Process {os.getpid()} Pipeline namespace initialized\u0026#34;) 插入: rag.insert(f.read()) rag.insert(f.read())\n​\t-\u0026gt; self.ainsert(input)\n​\t-\u0026gt; self.apipeline_enqueue_documents\n​\t-\u0026gt; self.apipeline_process_enqueue_documents\n进入rag.insert内 rag.insert(f.read()) -\u0026gt; 转到 self.ainsert(input)，input即 f.read()（字符串），\n1 2 3 4 5 6 7 8 9 10 11 12 13 def insert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, ) -\u0026gt; None: # 创建事件循环，然后把self.ainsert加入循环，执行时传入input，其他参数都默认 loop = always_get_an_event_loop() loop.run_until_complete( self.ainsert(input, split_by_character, split_by_character_only, ids) ) 进入self.ainsert内 两个内容，一个是 添加 文档状态信息，另一个是 处理文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 async def ainsert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, ) -\u0026gt; None: # 将input，即文档或list of 文档 的status信息加入doc_status数据库 await self.apipeline_enqueue_documents(input, ids) # 处理文档，创建知识库的主要部分 await self.apipeline_process_enqueue_documents( split_by_character, split_by_character_only ) self.apipeline_enqueue_documents ","date":"2025-03-20T00:00:00Z","permalink":"https://rooobeam.github.io/p/lightrag1.2.6%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/","title":"Lightrag1.2.6代码解读"},{"content":"Window系统和安全 实验平台为win2008，部分比对win11。\nWindows 账户、账户口令、文件系统、审核、日志、数据加密EFS、安全模板\n账户 计算机 右键 —— 管理 —— 配置 —— 本地用户和组 —— 用户 —— 点击具体用户 右键 —— 属性\n可勾选 “用户不能更改密码”“密码永不过期”“账户已禁用”\n账户策略 开始 |_管理工具 |_本地安全策略 |_账户策略 |_密码策略 |_账户锁定策略 |_本地策略 |_安全选项\n账户策略-密码策略 ​\t对每个策略右键 —— 属性 —— 可选启用or禁用，可查看 说明 选项卡\n​\t策略有：密码复杂性要求、长度要求、最短使用期限（防修改）、最长使用期限（防长期密码不更新）、强制密码历史（记录个数控制）、加密存储。\n账户策略-账户锁定策略 ​\t对每个策略右键 —— 属性 —— 可选启用or禁用，可查看 说明 选项卡\n​\t账户锁定时间（上锁后多久解锁）、锁定阈值（几次错误后上锁）、重置锁定计数器（多久后错误数变回0）\n本地策略-安全选项 不自动显示上次登录的账户\n​\t启用策略中： “交互式登录：不显示最后的用户名”\n禁止枚举账户名\n​\t禁止远程用户通过空连接枚举处所有本地账户名\n​\t启用策略中：“网络访问：不允许SAM账户和共享的匿名枚举”\n文件系统安全设置 加密数据 ​\tNTFS磁盘中文件，administrator用户下，新建文件夹，新建txt并写点。\n​\t文件夹右键 —— 常规 —— 高级 —— 勾选“加密内容以便保护数据”\n​\t用新建用户进入，发现无法打开文件夹\n命令行操作：\n1 2 cipher test1 /e cipher test1 /d EFS证书 开始 |_运行 |_mmc |_文件 |_t添加/删除管理单元 |_证书\nadministrator生成证书 ​\t回到administrator用户下，按照树流程找到证书，添加，勾选“我的用户账户”（生成当前用户的证书）\n​\t在控制台界面，按照以下树找到，注意！要先用了EFS加密了数据才会有，当然了如果用了其他软件加密也可能会有，因为这样加密后才会在 个人 下 生成证书。\n控制台根节点 |_证书 |_个人 |_证书 对界面中仅有的证书（因为没用其他软件加密过）,右键 —— 所有任务 —— 导出\n​\t勾选导出私钥，输入密码123123，选择D盘根目录下，文件名123123\ntest导入证书 ​\t换test用户，运行-mmc 打开控制台，添加/删除管理单元，添加证书。\n​\t到 控制台根节点-证书-个人，空白处右键，所有任务-导入，选择administrator导出保存的证书，输入密码123123，一直默认到完成，发现可以打开文件了。\n","date":"2025-03-20T00:00:00Z","permalink":"https://rooobeam.github.io/p/windows%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/","title":"Windows操作系统安全"},{"content":"自动git提交 .bat文件准备 新建txt，写入一下内容 1 2 3 4 5 6 7 8 9 10 11 12 @echo off REM 切换到 仓库所在目录 cd /d \u0026#34;D:\\github_blog\\\u0026#34; REM 执行 Git 命令 git add . git commit -m \u0026#34;update\u0026#34; git push REM 响应一下啦！ echo gooo_job! pause 另存为“所有文件(*)”，编码类型选择ANSI，命名为auto_git_commit.bat，放在如 D:/script 下。\n注意事项\ncd \\d \u0026ldquo;D:/\u0026rdquo; 一定要有双引号，否则找不到。\n如何记住哪个是转义字符的斜杠，哪个是目录的斜杠 tips: \\n\\t已记住，所以\\是转义，所以/是目录的\n命名文件夹、文件 不要有 空格 或 . . 开头会导致以为是 ‌**“点文件”（Dot Files）（隐藏文件）**如.bat\necho 后面的内容不要有空格，要连续\n编码格式要为ANSI，utf-8不行\n任务计划程序内创建基本任务 win+r 输入指令 taskschd.msc\t任务计划程序（Task Scheduler —— taskschd）\n打开(O):taskschd.msc\n最右侧一栏 找到 创建基本任务\n输入名称、描述\n希望该任务何时开始?\t——\t每天(D)\n填1，每隔1天发生一次\n希望该任务执行什么操作?\t——\t启动程序(T）\n程序或脚本(P):\t——\t点击浏览(R)，找到auto_git_commit.bat，如在 D:/script 下。\n完成\n创建新blog的 .bat文件 除了内容，其他和前者创建.bat文件一样\n用到hugo框架，故用hugo new content创建目录、文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @echo off setlocal enabledelayedexpansion :input_blog_name cls echo 请输入博客名称（不含空格，不要 . 开头）： set /p \u0026#34;blog_name=\u0026gt;\u0026gt; \u0026#34; REM 检查输入是否为空 if \u0026#34;%blog_name%\u0026#34;==\u0026#34;\u0026#34; ( echo 错误：博客名称不能为空！ timeout /t 2 /nobreak \u0026gt;nul goto input_blog_name ) REM 执行操作 cd /d \u0026#34;D:\\github_blog\\\u0026#34; hugo new content post/%blog_name%/index.md REM 结果反馈 if exist \u0026#34;D:\\github_blog\\\u0026#34; ( echo D:\\github_blog\\content\\post\\%blog_name%\\index.md 现已存在 ) pause ","date":"2025-03-14T00:00:00Z","permalink":"https://rooobeam.github.io/p/bat%E6%96%87%E4%BB%B6%E5%AE%9E%E9%AA%8C/","title":"bat文件实验"},{"content":"较全面的教程参考：Linux Vim最全面的教程-阿里云开发者社区\n","date":"2025-03-14T00:00:00Z","permalink":"https://rooobeam.github.io/p/vim%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","title":"Vim常用操作"},{"content":"python调试 参考Linux 下如何调试 Python？ - hoxis - 博客园\n在命令行，将程序作为参数传递来调试，“\u0026hellip; -m pdb \u0026hellip;py”，—— 命令行传pdb方式\npython3 -m pdb test1.py\n1 2 3 4 root@autodl-container-c00844b981-267cf857:~/autodl-tmp/test_script# python3 -m pdb test1.py \u0026gt; /root/autodl-tmp/test_script/test1.py(3)\u0026lt;module\u0026gt;() -\u0026gt; def add(a, b): (Pdb) _\u0026lt;-光标在此处 在代码中import pdb，写pdb.set_trace()代码 —— import pdb 方式\nimport pdb\npdb.set_trace()\npython3 test1.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # -*- coding: utf-8 -*- import pdb def add(a, b): return a + b if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#34;===start===\u0026#34;) pdb.set_trace() c = add(1, 3) print(\u0026#34;===end===\u0026#34;) ======= 命令行情况如下 ======== root@autodl-container-c00844b981-267cf857:~/autodl-tmp/test_script# python3 test1.py ===start=== \u0026gt; /root/autodl-tmp/test_script/test1.py(9)\u0026lt;module\u0026gt;() -\u0026gt; c = add(1, 3) (Pdb) 进入调试后常用指令\n(Pdb) l\t（“小写L指令”：查看）（若连续输入两次，则第二次返回[EOF]）\n(Pdb) p 变量名\t（查看当前可查变量）\n(Pdb)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ===========\t命令行传pdb root@autodl-container-c00844b981-267cf857:~/autodl-tmp/test_script# python3 -m pdb test1.py \u0026gt; /root/autodl-tmp/test_script/test1.py(3)\u0026lt;module\u0026gt;() -\u0026gt; def add(a, b): (Pdb) 1 1 # -*- coding: utf-8 -*- 2 3 -\u0026gt; def add(a, b): 4 return a + b 5 6 if __name == \u0026#39;__main__\u0026#39;: 7 print(\u0026#34;==start==\u0026#34;) 8 c = add(1, 3) 9 print(\u0026#34;==end==\u0026#34;) [EOF] (Pdb) b 8 Breakpoint 1 at /root/autodl-tmp/test_script/test1.py:8 (Pdb) b 9 Breakpoint 2 at /root/autodl-tmp/test_script/test1.py:9 (Pdb) b Num Type Disp Enb Where 1 breakpoint keep yes at /root/autodl-tmp/test_script/test1.py:8 2 breakpoint keep yes at /root/autodl-tmp/test_script/test1.py:9 (Pdb) c ===start=== \u0026gt; /root/autodl-tmp/test_script/test1.py(8)\u0026lt;module\u0026gt;() -\u0026gt; c = add(1, 3) (Pdb) c \u0026gt; /root/autodl-tmp/test_script/test1.py(9)\u0026lt;module\u0026gt;() -\u0026gt; print(\u0026#34;===end==\u0026#34;) (Pdb) p c 4 (Pdb) p a *** NameError: name \u0026#39;a\u0026#39; is not defined (Pdb) p b *** NameError: name \u0026#39;b\u0026#39; is not defined (Pdb) s ===end=== --Return- \u0026gt; /root/autodl-tmp/test_script/test1.py(9)\u0026lt;module\u0026gt;()-\u0026gt;None -\u0026gt; print(\u0026#34;===end==\u0026#34;) (Pdb) s --Return- \u0026gt; \u0026lt;string\u0026gt;(1)\u0026lt;module\u0026gt;()-\u0026gt;None (Pdb) s \u0026gt; /root/miniconda3/lib/python3.12/bdb.py(604)run() -\u0026gt; self.guitting = True (Pdb) s The program finished and will be restarted C编译调试 gcc -g test.c -o test 将 test.c 编译为可调式、可执行文件 test(.exe) Vim乱记 x删除光标所在处的字符\nu撤销一次操作（除u以外）\nyy复制光标所在行\np新增一行并写入剪贴板内容\n","date":"2025-03-11T00:00:00Z","permalink":"https://rooobeam.github.io/p/linux%E5%91%BD%E4%BB%A4/","title":"Linux命令"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-02-19T00:00:00Z","image":"https://rooobeam.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"https://rooobeam.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"�践' +++\n正文 设备：win2000VM虚拟机，win11宿主机\nwin11上：如何搭建FTP：https://zhuanlan.zhihu.com/p/36070173\nwin2000上：\n调为NAT模式； 我的电脑-\u0026gt;网上邻居-\u0026gt;地址栏输入ftp://宿主机wlan地址 搞定。\n？？？\n","date":"2025-02-12T00:00:00Z","permalink":"https://rooobeam.github.io/p/ftp%E5%AE%9E%E8%B7%B5/","title":"Ftp实践"},{"content":"","date":"2025-01-18T00:00:00Z","permalink":"https://rooobeam.github.io/p/newblog/","title":"Newblog"},{"content":"","date":"2025-01-18T00:00:00Z","permalink":"https://rooobeam.github.io/p/newtest/","title":"Newtest"},{"content":"hello hi fine 测试简体中文能否显示\n","date":"2025-01-17T00:00:00Z","permalink":"https://rooobeam.github.io/p/firstblog/","title":"FirstBlog"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2025-01-17T00:00:00Z","image":"https://rooobeam.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu_c1ca39d792aee4ab.jpg","permalink":"https://rooobeam.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://rooobeam.github.io/p/math-typesetting/","title":"Math Typesetting"}]