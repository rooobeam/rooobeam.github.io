+++
date = '2025-10-18T22:12:20+08:00'
draft = true
title = '语言模型发展论文集'
+++

## NNLM

2003 《A Neural Probabilistic Language Model》

统计语言建模目的是学习 **单词序列的联合概率函数**（叫大模型解释）。由于维度灾难：测试集的单词序列可能出现训练集中从未出现的单词序列。传统n-gram词袋模型成功实现 泛化能力 通过马尔可夫链。文章提出学习词语的 分布式表示 ，该模型会同时学习：（1）每个词的**分布式表示**（2）一个以这些表示为基础的词**序列概率函数**。

<img src="2003.png" alt="2003" style="zoom:50%;" />

### 任务与目标

训练一个语言模型，根据上下文 预测下一个词。

### 模型简化设定

从图中底到顶：

- 当前遇到的训练句子是 "a cat sat on a mat"
- **上下文长度 (n-1)**: 只看前面 **2** 个词（主观），也就是最底下绿色方块只有俩，w_t-2, w_t-1。
- **词向量维度 (m)**: 把每个词表示成一个 **3** 维的向量（主观），从绿色方块变成3个红色点。
- **隐藏层大小 (h)**: 我们的隐藏层有 **2** 个神经元（主观），到中间红点这里会乘以一个矩阵，矩阵的规模和2个神经元有关。
- **词汇表 (V)**: 我们的整个语言只有 6 个词(客观)：`{a, cat, mat, on, sat, the}`。它们的索引分别是 `{0, 1, 2, 3, 4, 5}`。

### 正向传播

从图中底部流向顶部：

- **输入与查表**：从最底绿点到倒二红点，w是词，绿块是w的索引, 倒二行红点是w的词向量 C(w)。   

  训练句子 "a cat sat on a mat" 截取出(a, cat, sat), (cat, sat, on)..., 第一条为(a, cat, sat)。     

  输入: 上下文是 "a cat"。它们的索引分别是 `0` 和 `1`。      

  查表 (C): 我们有一个 `6x3` 的词向量矩阵 `C` (6个词，每个3维)，它刚被随机初始化：    

  | 词 (索引) | 词向量 `C(word)`  |
  | :-------- | :---------------- |
  | **a (0)** | `[0.1, 0.2, 0.3]` |
  | cat (1)   | `[0.4, 0.5, 0.6]` |
  | mat (2)   | `[0.7, 0.8, 0.9]` |
  | on (3)    | `[1.0, 1.1, 1.2]` |
  | sat (4)   | `[1.3, 1.4, 1.5]` |
  | the (5)   | `[1.6, 1.7, 1.8]` |
  
  我们从这个表里查出输入词的向量：
  
  - `C(a)` = `[0.1, 0.2, 0.3]` C(w_t-2)
  - `C(cat )` = `[0.4, 0.5, 0.6]` C(w_t-1)

- **拼接输入向量**

  把上一步得到的两个词向量拼接成一个大向量 `x`，形成 tanh 下的长红点。   
  `x = [ C(sat), C(on) ] = [1.3, 1.4, 1.5, 1.0, 1.1, 1.2] `  
  这个 `x` 的维度是 `(n-1) * m = 2 * 3 = 6`（看了前两个词，每个词向量长度为3）。   

- **计算隐藏层** (tanh)   

  现在信息流向了中间的 `tanh` 隐藏层。计算公式是 `tanh(d + Hx)`。      

  - `x`: 就是我们上一步得到的 `[1.3, 1.4, 1.5, 1.0, 1.1, 1.2]`。   
  - `H`: 是一个权重矩阵，它的维度是 `h x (n-1)m` = `2 x 6`，6 对应于大向量`x`长度为6，2是人为设置的，即神经元个数（复杂的矩阵能解决复杂的问题）。   
  - `d`: 是隐藏层的偏置向量。它的维度是 `h = 2`，对应神经元个数。    

  初始时刻， `H` 和 `d` 也被随机初始化了：   
  `H = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6], [0.7, 0.8, 0.9, 1.0, 1.1, 1.2]]`    

  `d = [0.1, 0.2]`        

  现在计算 `d + Hx`:    
  `H x^T = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]·[1.3, 1.4, 1.5, 1.0, 1.1, 1.2]^T, [0.7, 0.8, 0.9, 1.0, 1.1, 1.2]·[1.3, 1.4, 1.5, 1.0, 1.1, 1.2]^T]` (矩阵乘法) = `[4.81, 11.23] `  
  `d + Hx = [0.1, 0.2] + [4.81, 11.23] = [4.91, 11.43]`   

  然后应用 `tanh` 函数，得到隐藏层的输出 `h_out`: `h_out = tanh([4.91, 11.43]) ≈ [0.999, 1.0]`

- **计算输出层**   

  现在信息将形成最顶层的红点，即一个6维向量，表示所**有词的出现概率**。计算公式是    

  ​                        `y = b + Wx + U * h_out` = `b + Wx + U * tanh(d + Hx)`。    
  
  - `b`: 输出层的偏置，维度是 `|V| = 6` （因为词的个数是6）。    
  - `W`: 从输入层到输出层的直连权重，维度是 `|V| x (n-1)m` = `6 x 6`，（W虽然乘的是x，但其实相当于W可选，可设置为0）。
  - `U`: 从隐藏层到输出层的权重，维度是 `|V| x h` = `6 x 2`。
  - （PS：说白了 Wx 是 输入-输出，U * h_out 是 输入-隐藏-输出，这里加和作为一个"并行融合"）    
  
  假设它们也被随机初始化了：   
  `U * h_out`: `6x2` 矩阵乘以 `2x1` 向量 `[0.999, 1.0]`，得到一个 `6x1` 的向量。   
  `W * x`: `6x6` 矩阵乘以 `6x1` 向量 `[0.3, ..., 0.2]`，得到一个 `6x1` 的向量。
  
  最后把这三者加起来，我们得到一个 `6x1` 的向量 `y`，它代表了词汇表中**每个词的“原始分数”（logits）**：   
  `y = [score_a, score_cat, score_mat, score_on, score_sat, score_the] `  
  假设算出来 `y = [0.5, 0.2, 0.9, -1.2, 0.1, 0.8]`


- **Softmax**    

  `Softmax` 函数把这些原始分数转换成和为1的概率分布。   
  `P(word) = e^(score_word) / ∑ e^(all_scores)`   

  `P("a") = e^0.5 / (e^0.5 + e^0.2 + ... + e^0.8) ≈ 0.17`   
  `P("cat") ≈ 0.12 `  
  `P("mat") ≈ 0.25 `  
  ... 等等，所有概率加起来等于1。

- **正向传播完成！** 

### 反向传播

我们的模型预测“mat”的概率最高，但正确答案是“sat”。现根据这个**错误**，从图的**顶部反向传播**回去，微调参数 (可能的参数：`C`, `H`, `d`, `U`, `b`, `W`)。

自己找个简单例子推反向传播，不展示了，损失函数计算损失，然后偏导为原理，优化器优化deta.... 注意的是，**最后会调整 C 从而实现词向量的训练**。

## CBOW与Skip-gram

《Efficient Estimation of Word Representations in Vector Space》

### 链接与要点

**必看链接**: [深入浅出：用中学数学理解 CBOW与Skip-gram](https://www.bilibili.com/video/BV1uF4m1P7HS/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)

**要点**: 在理解NNLM的基础上，理解 多层softmax、CBOW、Skip-gram

### NNLM计算复杂度

*   **模型结构**: 输入层 -> 投影层 (查找词向量) -> 非线性隐藏层  -> 输出层 (Softmax)。
*   **计算复杂度**: `Q = N × D + N × D × H + H × V`
    *   `N × D`: 词向量查找。
    *   **`N × D × H`**: 从投影层到**隐藏层**的矩阵乘法。`N × D`是词向量拼接后的向量长度，而每个神经元里都有1个 `N × D` 长度的向量与之相乘变为一个值，共有`H`个神经元，所以是`H`次`(1, N×D)·(N×D, 1)`，即`(1, N×D)·(N×D, H)`，两个数值的乘法次数就有`N × D × H`次。
    *   **`H × V`**: 从隐藏层到**输出层**的矩阵乘法。`V`是词汇表大小，也是输出层的神经元个数，`(1, H)·(H, V)`得到`V`个值。

###  分层Softmax的NNLM

- 对原始NNLM的输出层的优化。

   *   **模型结构**: 输入层 -> 投影层 -> 非线性隐藏层  -> 输出层 (**分层Softmax**)。

   *   **计算复杂度**: `Q = N × D + N × D × H + H × log₂(V)`，**`H × log₂(V)为输出层的计算量被指数级优化。


- 分层Softmax

   *   **传统Softmax**：一个巨大的、`H × V` 大小的权重矩阵，`H`维向量跟表里的每一列（共V列）都做一次内积运算，完成 `H × V` 的计算。


   *   **分层Softmax**：建立了一棵**“二叉导航树”**。
       *   **树的叶子节点 **：词汇表中的 V 个单词，每个单词都作为一个叶子节点。
       *   **树的内部节点**：这些是路径上的“岔路口”，总共有 V-1 个。
       *   **关键点**：我们不再为V个单词存储`H`维向量，而是为 **V-1 个内部节点（岔路口）**各自分配一个`H`维的辅助向量。

   - 正向传播：

     - 回顾任务，已知前N个词，预测第N+1个词，构造的训练数据中知道第N+1个词是哪个词，假设为"cat"。

     - 在我们的二叉树中，从根节点到 "cat" 有一条唯一的路径，比如这条路径是 [左, 右, 左]，这个**路径的长度大约是 `log₂(V)`**。

     - 隐藏层输出的向量 `h` (维度为 H)，从根节点出发。第一个岔路口向左，计算“向左走”的概率，默认神经元输出的是向左的概率，`score₁ = h · v'_1` ，于是`P(向左 | Node 1) = σ(score₁)`；第二个岔路口 (Node 2) `score₂ = h · v'_2`，`P(向右 | Node 2) = 1 - σ(score₂)`； `score₃ = h · v'_3`， `P(向左 | Node 3) = σ(score₃)`；计算最终概率`P("cat") = P(向左|Node 1) × P(向右|Node 2) × P(向左|Node 3)`。

     - 叶子节点有`V`个，也就是词汇总数，`2^n = V`，所以**路径**的平均长度约为 `log₂(V)`；在路径上的**每一个节点上的计算量**为向量 `h` 和节点向量 `v'_j` 的点积 ，两个 H 维向量的点积，需要 H 次乘法 和 `H-1` 次加法。所以计算复杂度是 `O(H)`。**总计算量 = (路径上的节点数) × (每个节点的计算量)** ≈ log₂(V) × H。

     - 反向传播只调整路径上的节点，概率精度要求极高的任务上可能会略逊于标准Softmax。（我的经验主义想法：每次反向传播调整的节点变少，在数据量不够多的情况下效果没那么好，但是速度快了许多而且是自训练所以，牛掰。）



### CBOW 

连续词袋模型，革命性简化。

*   **模型结构**: 输入层 -> 投影层 (**查找并平均化上下文词向量**) -> 输出层 (分层Softmax)。
*   **计算复杂度**: `Q = N × D + D × log₂(V)`
    *   `N × D`: 将上下文词向量求平均的操作。
    *   `D × log₂(V)`: 直接用平均后的向量（维度为D）去通过分层Softmax做预测。
 *   **关键变化**:
     - **移除隐藏层**：`H × D` 的计算瓶颈消失
     - **输入变为平均向量**: 输入的维度从 `(N-1)×D` 降维到 `D`。

### Skip-gram

这是 Word2Vec 的第二个模型，思路与 CBOW 相反。

*   **模型结构**: 输入层 (单个词) -> 投影层 -> 输出层 (**分层Softmax**)。
*   **核心任务**: 根据一个**中心词**，来预测它周围的**上下文词**。
*   **计算复杂度**: `Q = C × (D + D × log₂(V))`
    *   `D`: 输入词向量查找。
    *   `D × log₂(V)`: 预测**一个**上下文单词的计算量。
    *   `C`: 平均每个中心词需要预测的上下文单词数量，其大小跟刚才N类似
    *   对于一个中心词，需要进行 `C` 次独立的正向、反向传播。

| 特性                 | **CBOW **                                                   | **Skip-gram**    |
| :------------------- | :---------------------------------------------------------- | :--------------- |
| **反向传播更新对象** | 上下文词向量                                                | 中心词向量       |
| **更新特点**         | 一次更新，梯度被**均摊**，`梯度 = “∂L/∂h  除以 上下文词数”` | 梯度**完整作用** |
| **训练速度**         | 较快                                                        | 较慢             |

---

### 总结

| 模型          | 隐藏层  | 输出层          | 任务             | 复杂度概览          | 计算复杂度                        |
| :------------ | :------ | :-------------- | :--------------- | :------------------ | --------------------------------- |
| **NNLM**      | **有 ** | **标准Softmax** | 预测下一个词     | **非常高**          | `N × D + N × D × H + H × V`       |
| **NNLM + HS** | **有**  | 分层Softmax     | 预测下一个词     | **高**              | `N × D + N × D × H + H × log₂(V)` |
| **CBOW**      | **无**  | 分层Softmax     | 上下文 -> 中心词 | **非常低**          | `N × D + D × log₂(V)`             |
| **Skip-gram** | **无**  | 分层Softmax     | 中心词 -> 上下文 | **低** (比CBOW略高) | `C × (D + D × log₂(V))`           |

**核心演进路径**:

1.  **优化输出层**: 用 **分层Softmax** 替换标准 Softmax。
2.  **优化隐藏层**: 直接**移除隐藏层**，对于学习词向量这个目标而言，复杂的非线性组合可能是“杀鸡用牛刀”。
3.  **改变任务**: 放弃构建精确语言模型，设计出更简单、更专注的“伪任务”，其唯一目的就是训练出高质量的词向量。
4.  **思想：当数据量足够大时，模型的简单性带来的训练效率优势，往往能胜过复杂模型带来的精度优势。一个在万亿级语料上训练的简单模型 (CBOW)，其产出的词向量质量，远超一个只能在十亿级语料上训练的复杂模型 (NNLM)**

## GloVe

### 链接与要点

链接（拓展）：[单词向量空间_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Fr4y1w7mE?spm_id_from=333.788.videopod.episodes&vd_source=3e32a51d0489203920eb4337d8de4c31&p=2)

要点：在理解bag-of-word的基础上，先知道模型是如何设计的，再深究 怎么得到模型的、为什么这样有道理。

PS：原论文是完整的思路，从启发点开始一步步推导；我的话让gemini一句一句翻译论文并解析看的，没看懂也硬着头皮继续看，然后柳暗花明。

### GloVe模型组件

GloVe模型的核心是一个**加权最小二乘回归模型**。它的目标是最小化一个**代价函数 (Cost Function)** `J`。（先记下来：权重f()，词向量w，偏置b，共现次数X_ij）

$J = Σ f(X_{ij}) * (w_iᵀ * ~w_j + b_i + ~b_j - log(X_{ij}))²$

1. **输入数据 - 共现矩阵 `X`**:

   - 这是模型训练前需要**提前准备好**的唯一数据。
   - `X_ij` 代表在整个语料库中，单词 `j` 出现在单词 `i` 上下文窗口中的次数。
   - **举例**：
     - 语料库(Corpus):"I like deep learning."，"I like NLP."，"I enjoy learning."
       
     - **词汇表**: { I, like, deep, learning, NLP, enjoy }

     - **上下文窗口大小**: 1
     - 共现矩阵如下：

   | `X`          |  I   | like | deep | learning | NLP  | enjoy |
   | :----------- | :--: | :--: | :--: | :------: | :--: | :---: |
   | **I**        |  0   |  2   |  0   |    0     |  0   |   1   |
   | **like**     |  2   |  0   |  1   |    0     |  1   |   0   |
   | **deep**     |  0   |  1   |  0   |    1     |  0   |   0   |
   | **learning** |  0   |  0   |  1   |    0     |  0   |   1   |
   | **NLP**      |  0   |  1   |  0   |    0     |  0   |   0   |
   | **enjoy**    |  1   |  0   |  0   |    1     |  0   |   0   |

2. **待学习的参数**:

   - $w_i$: 目标词 `i` 的**中心词向量**。
   - $~w_j$: 上下文词 `j` 的**上下文词向量**。
   - $b_i$ 和 $~b_j$: 分别是中心词和上下文词的**偏置项**，用于捕捉词本身的一些独立于上下文的特性（比如词频）。
   - **最终我们需要的词向量就是 `w` 或者 `w` 和 `~w` 的和/平均值。**

3. **核心方程**:

   - $w_iᵀ * ~w_j + b_i + ~b_j$：这是模型的**预测部分**。它用两个向量的点积和两个偏置项，来预测词 `i` 和 `j` 之间的关联度。
   - $log(X_{ij})$：这是模型的**目标部分**。它代表了我们希望预测值逼近的“真实”关联度，直接来源于全局的共现统计。

4. **权重函数 $f(X_{ij})$**:

   - 它是一个权重函数，根据共现次数`X_ij`的大小来决定某个词对在训练中的重要性，它会影响 损失的大小 从而影响 一次反向传播 对参数的 调整程度：

     - **`f(0) = 0`**: 对于从未共现的词对（$X_{ij}=0$），权重为0，完全不参与训练，极大降低计算复杂度。
     - **非递减**: 共现次数越多的词对，权重越大（但不是无限大），因为它们包含更可靠的信息。
     - **设置上限**: 对于共现次数极高的词对（如 "the", "is"），权重被限制在一个上限（比如1），防止这些高频停用词主导整个训练过程。
   - 文章给出分段函数如下图，$x_{max}$ 取100，`α` 取 3/4，满足上面的三个条件 f(0)=0, 非递减, 设置上限。
   
   <img src=".\glove_weight_func.png" alt="glove_weight_func" style="zoom:38%;" />


### GloVe训练过程

**第1步：构建共现矩阵**

1. **确定词汇表**：扫描整个语料库，统计词频，筛选出最高频的N个单词作为词汇表。

2. **确定上下文窗口**：设定一个窗口大小，比如左右各5个词。

3. **统计共现次数**: 遍历整个语料库，对于词汇表中的每一个词 `i`，查看其上下文窗口中出现了哪些词 `j`，并累加到 `X_ij` 上。

**第2步：权重和初始化参数**

1. 为词汇表中的每个词，随机初始化它的中心词向量 `w`、上下文词向量 `~w`、以及偏置项 `b` 和 `~b`。这些通常都是一些很小的随机数。
2. 根据权重函数和共现矩阵得到`f(X_ij)`。

**第3步：迭代优化**

1. **核心目标**：通过调整 `w`, `~w`, `b`, `~b` 这些参数，来让代价函数 $J = Σ f(X_{ij}) * (w_iᵀ * ~w_j + b_i + ~b_j - log(X_{ij}))²$ 的值变得尽可能小，**人话就是**：**加权后的 【行词向量和列词向量的内积 + 偏置】 接近 【相应行列共现矩阵中的值】，达到整体误差最小的地步**。
2. **优化算法**：通常使用随机梯度下降 (SGD) 的变种，如 **AdaGrad** 算法。
3. 具体流程:
   - 从共现矩阵 `X` 中随机抽取一个非零的词对 `(i, j)` 及其共现次数 $X_{ij}$。
   - 计算这对词的预测误差: $error = (w_iᵀ * ~w_j + b_i + ~b_j) - log(X_{ij})$。
   - 根据 $X_{ij}$ 计算权重: $weight = f(X_{ij})$。
   - 计算这个样本的**加权损失**: `loss = weight * error²`。
   - 根据这个损失，计算它对涉及到的参数 ($w_i, ~w_j, b_i, ~b_j$) 的**梯度**（即每个参数应该调整的方向）。
   - 沿着梯度的反方向，**微小地更新**这些参数，使得下次计算这对词时，误差会变小一点。
4. **重复**: 不断重复第3步，遍历所有非零的词对，进行多轮（epochs）训练，直到代价函数 `J` 的值收敛（不再显著下降）。

**第4步：获得最终词向量**

1. 训练结束后，我们就得到两套词向量矩阵 `W` (所有 `w` 的集合) 和 `~W` (所有 `~w` 的集合)。
2. 最终的词向量通常是这两套向量的**和**或**平均值**，即 $W_{final} = W + ~W$。这样做可以融合两方面的信息，使得到的词向量更加鲁棒。

### 哲学思想

- 原论文提到的共现率比例体现哪里？$J = Σ f(X_{ij}) * (w_iᵀ * ~w_j + b_i + ~b_j - log(X_{ij}))²$这个式子只涉及i j，压根没有k！        

  答曰：要区分“**模型的思想起点**”和“**最终的数学形式**”。比率是 GloVe 模型的**设计哲学和推导工具**，而不是它在训练时直接优化的目标。（ps：具体的问大模型去吧）

- 那glove和LSA有什么关系？没有是什么矩阵分解啊？      

  答曰：`J = Σ f(X_ij) * (w_iᵀ * ~w_j + b_i + ~b_j - log(X_ij))²` 这个公式看起来不是常见的矩阵分解形式，如 `X ≈ W * Hᵀ`，**但它本质上是一种“加权的矩阵分解”**。

  1. **简化问题**：

     - 暂时忽略权重 $f(X_{ij})$ 和偏置项 $b_i$, $~b_j$。
   - 那么损失函数就变成了 $J = Σ (w_iᵀ * ~w_j - log(X_{ij}))²$。
  
  2. **理解$w_iᵀ * ~w_j$的矩阵形式**：

     - $w_i$ 是词向量矩阵 $W$ 的第 `i` 行。
   - $~w_j$ 是词向量矩阵 $~W$ 的第 `j` 行。
     - 那么 $w_iᵀ * ~w_j$ 就是矩阵乘积 $W * ~Wᵀ$ 之后得到的那个大矩阵中，处在第 `i` 行、第 `j` 列的那个元素。
  
  3. **重新表述损失函数**：

     - 我们上面简化的损失函数 $J = Σ (w_iᵀ * ~w_j - log(X_{ij}))²$，其实就是在说：

       > “找到两个低维矩阵 `W` 和 `~W`，使得它们的乘积 `W * ~Wᵀ` 尽可能地接近目标矩阵 `log(X)`。”

     - 用矩阵的范数来表示，这就是在最小化 `|| W * ~Wᵀ - log(X) ||_F²` (弗罗贝尼乌斯范数的平方)。

- PS：6666666666666666666

## Seq2seq

### 前置知识、链接与要点

前置知识 由高到低：deep LSTMs -> LSTM -> 传统RNN -> MLP，MLP是零基础可以直接学的。

**必看链接**：[RNN大白话讲解](https://www.bilibili.com/video/BV1e5411K7oW/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)、[LSTM大白话讲解 ](https://www.bilibili.com/video/BV1qM4y1M7Nv/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)、[序列到序列学习【动手学深度学习v2】](https://www.bilibili.com/video/BV16g411L7FG/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)

要点：

- 理解RNN里的“时间步上的展开”
- 理解LSTM通过**细胞状态C**进行“遗忘和更新”
- 理解**encoder-decoder**架构
- 其他注意点：多层LSTM，encoder-decoder架构在训练和实际预测时的不同、让大模型进行矩阵计算过程模拟，反向传播涉及矩阵微积分（我投降，我用维度分析法），梯度爆炸（我再投降，你能拿我咋滴）



**下文遵循 "MLP(究极粗糙版) -> MLP(滑窗版) -> 传统RNN  -> LSTM -> deep LSTMs ->encoder-decoder" 的顺序**



### MLP

场景设定为：对于一个序列/向量 比如 a cat sat on a ___ 这里要预测个词

对于**MLP(究极粗糙版)**，需要将a cat sat on a转成5个词嵌入 5*(1, 300)，然后拼接形成(1, 1500)，然后经过隐藏层 (1, 1500) × (1500, 128) = (1, 128)，最后输出层 (1, 128) × (128, 10000) ，这里假定10000个词，然后softmax看哪个词。

这里问题在于， 这里定长了，于是有**MLP(滑窗版)**，假设窗口长度为3。若训练数据为“a cat sat on a mat”  则滑窗出 a cat sat (on)、cat sat on (a)、sat on a (mat) 来训练。预测时，只能利用最后三个词“sat on a”去预测 mat。

公式：$â = tanh(W_{ax} × x+b_{a})$	$ŷ = softmax(W_{ya} × â + b_y)$

### 传统RNN

先看 [RNN大白话讲解](https://www.bilibili.com/video/BV1e5411K7oW/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)

场景依旧 “a cat sat on a ___”，传统RNN初始参数有：词嵌入表（冻结）（1e4, 300），隐藏层权重（428, 128），隐藏层偏置 (1, 128)，输出层权重（128, 1e4），输出层偏置 (1, 1e4)，其中 1e4 为“假设词汇表共个1e4个词”，128 是隐藏层神经元个数，300是词向量维度。

先将 a 转成词嵌入 (1, 300)，与上个隐藏层结果（h_0设定为全0 (1, 128)）拼接得到 (1, 428)，经过隐藏层 (1, 428) × (428, 128) = (1, 128)  = h1；cat转为词嵌入 (1, 300)，与上个隐藏层结果得到 (1, 428)，经过隐藏层 (1, 428) × (428, 128) = (1, 128)  = h2 ；sat、on、a 类似；经过 a 后有 h5 = (1, 128)，经过输出层 (128, 1e4)，然后softmax后知道是哪个词。

训练时，h1~h5都会经过输出层得出L1~L5（语言建模） 或者 只在最后一个时间步产生一个输出和损失（情感分类），前者 总损失 通过**求和** $L = L_1 + L_2 + L_3$ (或取平均)，后者 总梯度(如对矩阵W_hh)通过**传递**: $∂L/∂W_{hh} = (∂L/∂W_{hh})_{t=1} + (∂L/∂W_{hh})_{t=2} + (∂L/∂W_{hh})_{t=3}$

公式：	$h_{i} = tanh(W_{hx} × (x_i+h_{i-1})+b_{h})$   

​		  $ŷ_i = softmax(W_{yh} × h_i + b_{y})$

### LSTM

一句话就是，LSTM平时多传个变量“细胞状态$C_t$”然后多弄几个参数矩阵相应地处理它。

理解传统RNN后看 [LSTM大白话讲解  ](https://www.bilibili.com/video/BV1qM4y1M7Nv/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930) 就能理解，不理解就再看RNN

公式记忆 ：一个 隐状态 ，一个 细胞状态，细胞遗忘 `× σ`，细胞更新 `+ (σ × tanh)`，新隐状态生成 $h_t = tanh(C_t) × σ$ 

视频里的公式讲解图如下

<img src=".\lstm_equations.png" alt="lstm_equations" style="zoom:38%;" />

### deep LSTMs

```
                               o_t ---> ...   (最终输出)
                                ^
                                |
      h3_t-1 ---> h3_t ---> h3_t+1  (第3层 - 最高层抽象)
         ^         ^          ^
         |         |          |
      h2_t-1 ---> h2_t ---> h2_t+1  (第2层 - 中间层抽象)
         ^         ^          ^
         |         |          |
      h1_t-1 ---> h1_t ---> h1_t+1  (第1层 - 底层特征)
         ^         ^          ^
         |         |          |
        x_t-1     x_t        x_t+1      (原始输入序列)
```

假设维度大小 —— 词向量(1,300) 隐藏状态(1,128)，则第一层的某个权重矩阵大小为(300+128, 128)，其他层(128+128, 128)。

### encoder-decoder(Seq2seq)

先看 [序列到序列学习【动手学深度学习v2】](https://www.bilibili.com/video/BV16g411L7FG/?share_source=copy_web&vd_source=33a3d9253f3eaae8520547ba343f9930)

<img src=".\seq2seq.png" alt="seq2seq" style="zoom:40%;" />

- 蓝色部分为encoder即一个LSTM，白色部分为decoder也是一个LSTM。
- encoder的隐状态作为decoder的$h_0$，（预测时）给decoder一个“开始记号”为$<bos>$，第一个时间步里输出的词作为第二个时间步输入词，如果输出的词为$<eos>$，则结束
- 图中hello world .如果反着输入会有更好效果 —— “这点上我觉得是，解码器它（除t=1）后面的RNN层输入的词是 t-1 输出的词，而hello 最后进入，t=1 当然更容易是hello 相关，这样t=2也更正确，后续亦如此”
- Seq2seq论文中使用4层深度的 deep LSTMs，也就是$h4_t$作为输出
- 训练时，在decoder这里会保证每个时间步输入的都是对的词，以调整参数

## Bahdanau Attention

Bahdanau /bɑːdˈɑːnaʊ/



